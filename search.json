[{"title":"一个IT事故引起的思考","url":"%2F2018%2F09%2F07%2F%E4%B8%80%E4%B8%AAIT%E4%BA%8B%E6%95%85%E5%BC%95%E8%B5%B7%E7%9A%84%E6%80%9D%E8%80%83%2F","content":"\n#### 事件案例\n\n在一个周五的傍晚，一家ISP技术支持中心的接线员不断地接到来自不同客户的质询：有些客户收不到电子邮件；有些客户却收到一些发给其他人的邮件；还有的客户无法发送任何邮件。总之，一切都乱套了，愤怒的客户开始抱怨！显然，ISP的系统出了问题。 问题究竟出在哪里？是系统遭到电脑黑客的破坏吗？公司的安全部门开始仔细地调查。结果发现，问题是由另一个业务部门当天安装的一个Java程序引起的，安装这一程序的原意是让客户能够更容易地通过网络收发电子邮件，但不幸的是，这段Java程序存在错误，而且这段Java程序的开发人员并没有把这一变化及时地通知IT部门的最高主管。在被问及此事时，他称这是一次“心血来潮”的做法。 更糟糕的是，没有人将这一变化通知技术支持中心，从而使接线员可以告诉客户，或者在企业网站上发布详细的业务中断信息。虽然这种情况不明的业务中断只持续了几个小时，但却在客户中产生了非常不良的影响。 对那些在夜晚负责管理IT系统的管理员来说，以上情况是每天都可能遇到的紧急情况。\n\n\n#### 案例思考\n\n如果公司有一套经过测试和验证的常识准则，并要求每一个环节的员工都遵守这一准则，这种情况是完全可以避免的。这就是信息技术基础设施库（ITIL）要解决的问题。","tags":["itsm"]},{"title":"网络攻击的常见手段","url":"%2F2018%2F09%2F07%2F%E7%BD%91%E7%BB%9C%E6%94%BB%E5%87%BB%E7%9A%84%E5%B8%B8%E8%A7%81%E6%89%8B%E6%AE%B5%2F","content":"\n#### 扫描类攻击\n\n\t1、端口扫描\n\t顾名思义，通过扫描系统端口漏洞，实现攻击或控制。因此建议系统SSH、TELNET不要使用默认的端口。黑客通常会用NMAP软件扫描漏洞。\n\t2、漏洞利用\n\t黑客常用手段。通过没有权限或低级权限的用户漏洞，通过技术手段，直接获取root权限；或者通过硬件漏洞进行ARP攻击；亦或者远程控制机器，达到控制肉机的目的，因此像3389端口一定要控制好。\n\n#### web攻击类\n\t1、网站暴力破解\n\t通过软件保利破解网站，常用工具：DVWA。\n\t2、XSS攻击\n\t常见工具：BruteXSS\n\t3、SQL注入攻击\n\t常用工具，sqlmap。","tags":["攻击"]},{"title":"常见网站攻击手段原理与防御","url":"%2F2018%2F09%2F07%2F%E5%B8%B8%E8%A7%81%E7%BD%91%E7%AB%99%E6%94%BB%E5%87%BB%E6%89%8B%E6%AE%B5%E5%8E%9F%E7%90%86%E4%B8%8E%E9%98%B2%E5%BE%A1%2F","content":"\n#### DDOS攻击分类：\n\t网络层攻击：\n\t\tSYN-flood：利用TCP建立连接时3次握手的“漏洞”，发送源地址虚假的提交，永远无法完成三次握手。占满系统的协议栈队列资源得不到释放，进而拒绝服务。\n\t\t防御方式：调整内核参数方法，减少等待及重试时间，加速资源释放\n    \tsyn proxy\n    \tsyn cookies\n    \t手包丢弃\n\t\tAck-flood：虚假Ack包，远不如syn-flood。\n\t\tUDP-flood：使用虚假源地址UDP包，以DNS协议为主。\n\t\tICMP-flood：Ping洪水攻击。\n\t应用层攻击：\n\t\tCC：通过控制傀儡主机或者寻找匿名代理服务器向目标发起大量真实的HTTP请求，最终消耗掉大量的并发资源，拖慢整个网站甚至彻底拒绝服务。\n\t\tDNS-flood：发送海量的DNS查询报文导致网络带宽耗尽而无法传送正常DNS查询请求。\n\t\t防御方法：将UPD查询强制转为TCP，要求溯源，如果是假地址就不再回应。\n\t\t慢速连接攻击：针对HTTP协议，先建立起HTTP连接，设置一个较大的Conetnt-Length，每次只发送很少的字节，让服务器一直以为HTTP头部没有传输完成，这样连接一多就很快会出现连接耗尽。\n<!--more-->\n#### DDOS攻击方式分类:\n\t混合型：大量的攻击中，通常并不是以上述一种数据类型来攻击，往往是TCP和UDP，网络层和应用层攻击同时进行。\n\t反射型：“质询—应答”模式。将源地址伪造成攻击目的地址，则应答的“回包”被发送到目标，如果回包体积比较大或协议支持递归效果，攻击的效果会被放大，性价比高。\n\t说明：将源地址设为假的无法回应，即为SYN-flood攻击，制造流量和攻击目标收到的流量为1:1，回报率低。\n\t流量放大：SSDP协议，递归效果产生的放大倍数非常大。\n\t脉冲型：即“打打停停”，攻击持续时间非常短。（目的：避免触发自动化防御机制）\n\t链路冷洪：不直接攻击目标而是以阻塞目标网络的上一级链路为目的。（原因：避免防御系统对攻击流量分摊）\n\n#### DDOS防御结构：\n\tISP近源清洗：电信运营商提供的近源清洗和流量压制，此做法为弃卒保帅，避免全站服务对所有用户彻底无法访问。\n\t意义：对超过自身带宽储备和自身DDOS防御能力之外超大流量时补充性缓解措施。\n\t云清洗/CDN硬抗：场景-如抢购访问量非常大时，平台上在CDN层面用验证码过滤了绝大多数请求，最后到达数据库的请求量相比非常小。\n\t云清洗厂商策略：\n\t设置好网站的CNAME，将域名指向云清洗厂商的DNS服务器\n\t——>云清洗厂商的DNS将穿透CDN的回源的请求指向源站\n\t——>(检测到受攻击)检测方法：客户网站部署反向代理，托管所有的并发连接。\n\t——>域名指向自己的清洗集群，然后再将清洗后的流量回源。\n\t总结：更改CNAME指向，等待DNS递归剩下.\n\tDC级近目的清洗：主要用到华为的ADS设备。若探针检测到受到DDOS攻击则将Internet请求都指向DDOS清洗中心——>清洗完正常流量回到IDC业务机。\n\tOS/APP层：DDOS最后一道防线。主要对应用层协议做补充防护。如禁用monlist，不提供UDP服务。\n\tWeb服务对相同IP/IP+cookie/HTTP头部/request URL进行检测计数->触发->阻断\n\t防御应用：\n\t对Web业务：以上四层全部适用\n\t对游戏：CDN在此场景无效，DNS引流+ADS来清洗。还有在客户端和服务端通信协议做处理（如封包加标签，依赖信息对称）\n\t服务策略：分级策略：避免某些服务导致全站不可用\n    Failover机制：冗余技术\n    有损服务：避免单点瓶颈，关键时刻能进行割肉。\n\t不过总的来说DDOS攻击比较恐怖，一般防御很难抵抗主要取决于哪一方拥有的带宽资源大了。","tags":["攻击"]},{"title":"testsetsetsetestsetestsetes","url":"%2F2018%2F08%2F31%2Ftest%2F","content":"\n\n### 插入图片\n![你想输入的替代文字](/images/vi.png)\n\n### 插入音乐\n<iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=330 height=86 \n\tsrc=\"http://music.163.com/outchain/player?type=2&id=25706282&auto=0&height=66\">\n</iframe>\n\n### 插入视频\n\nIdina Menze和Caleb Hyles激情对唱Let It Go：\n<iframe \n\theight=498 width=510 \n\tsrc=\"http://player.youku.com/embed/XNjcyMDU4Njg0\" \n\tframeborder=0 allowfullscreen>\n","tags":["test"]},{"title":"apt-get指令的autoclean,clean,autoremove的区别","url":"%2F2018%2F07%2F19%2Fapt-get%E6%8C%87%E4%BB%A4%E7%9A%84autoclean%2Cclean%2Cautoremove%E7%9A%84%E5%8C%BA%E5%88%AB%2F","content":"\n#### apt-get autoclean:\n    如果你的硬盘空间不大的话，可以定期运行这个程序，将已经删除了的软件包的.deb安装文件从硬盘中删除掉。如果你仍然需要硬盘空间的话，可以试试apt-get clean，这会把你已安装的软件包的安装包也删除掉，当然多数情况下这些包没什么用了，因此这是个为硬盘腾地方的好办法。\n\n\n\n#### apt-get clean:\n    类似上面的命令，但它删除包缓存中的所有包。这是个很好的做法，因为多数情况下这些包没有用了。但如果你是拨号上网的话，就得重新考虑了。\n\n\n\n#### apt-get autoremove:\n    删除为了满足其他软件包的依赖而安装的，但现在不再需要的软件包。\n\n\n\n#### apt-get remove \n\tapt-get remove 软件包名称：\n    删除已安装的软件包（保留配置文件）。\n\n#### apt-get --purge remove \n\tapt-get --purge remove软件包名称：\n    删除已安装包（不保留配置文件)。","tags":["clean"],"categories":["linux"]},{"title":"virtualenv介绍及基本使用","url":"%2F2017%2F05%2F19%2Fvirtualenv%E4%BB%8B%E7%BB%8D%E5%8F%8A%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F","content":"\n#### virtualenv介绍\n\n在python开发中，我们可能会遇到一种情况，就是当前的项目依赖的是某一个版本，但是另一个项目依赖的是另一个版本，这样就会造成依赖冲突，而virtualenv就是解决这种情况的，virtualenv通过创建一个虚拟化的python运行环境，将我们所需的依赖安装进去的，不同项目之间相互不干扰，如下所示。\n\n#### 安装virtualenv\n\n```bash\npip install virtualenv\n```\n\n#### virtualenv运行使用\n\n```bash\n#创建虚拟化环境\nvirtualenv venv\n#我本机此时默认的python环境为python2.7，那么此时创建的虚拟环境就是以python2.7创建的虚拟化环境，如果需要选择一个python解释器来创建虚拟化环境，命令则为：\nvirtualenv -p /usr/bin/python2.7 venv\n```\n<!--more-->\n#### 启用\n\n```bash\nsource venv/bin/activate\n```\n\n#### 安装依赖\n\n在以上完成之后就可以通过命令pip install 来安装python包了，这里安装python包就不需要root权限了，直接就可以安装十分方便。在venv的环境中，使用pip安装的包都不会再是全局性的包，只会在当前的虚拟环境中起作用，避免了污染系统环境。\n\n#### 退出当前系统环境\n\n```bash\ndeactivate\n```\n\n#### 作用\n\nvirtualenv就是一个搭建虚拟化的python环境，便于不同的项目在同一台机器上开发运行。\nvirtualenv更多的还是适用于本地开发不同的项目，但是在生产环境中还是使用docker给不同的项目创建不同的容器，各自分开运行为好，不宜放在一个单独的物理机中运行。","tags":["python"],"categories":["linux"]},{"title":"ELK+Zookeeper+Kafka集群安装配置","url":"%2F2017%2F03%2F22%2FELK%2BZookeeper%2BKafka%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F","content":"\n### 集群部署结构示例\n\n| 结构层级   |      服务器      |  应用 |\n|----------|-------------|------|\n| 日志采集 |   | filebeat |\n| 数据处理，日志缓存 |    192.168.20.110  192.168.20.111 192.168.20.112   |   jdk+logstash+kafka+zookeeper |\n| 转发 | 192.168.20.113 |    jdk+Logstash |\n| 持久、检索 | 192.168.9.114  192.168.9.115 |    jdk+elasticsearch  |\n| 展示层 | 92.168.9.116     |    jdk+kibana+elasticsearch(master) |\n<!--more-->\n\n### 环境准备\n\n    1、注意防火墙\n\n    2、安装JDK环境\n    ``` bash\n    cat >> /etc/profile <<EOF\n    JAVA_HOME=/data/program/jdk1.8\n    PATH=\\$PATH:\\$JAVA_HOME/bin\n    EOF\t\n    ```\n\n    3、内核优化\n    ``` bash\n    cat >>/etc/sysctl <<EOF\n    fs.file-max=65535\n    vm.max_map_count = 655360\n    EOF\n\n    sysctl -p\n\n    cat >>/etc/security/limits.conf <<EOF\n    * soft nofile 65536\n    * hard nofile 131072\n    * soft nproc 2048\n    * hard nproc 4096\n    EOF\n    ###此文件修改后需要重新登录用户，才会生效\n    ```\n\n### Elasticsearch集群安装配置（四、五）\n    ``` bash\n    #ES下载安装\n    wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.3.0.tar.gz\n    tar zxvf elasticsearch-6.3.0.tar.gz\n    mv elasticsearch-6.3.0.tar.gz /data/program/elasticsearch\n\n    #创建数据和日志目录\n    mkdir /data/program/elasticsearch/data\n    mkdir /data/program/elasticsearch/logs\n\n    #添加ES启动用户\n    useradd elk\n    chown -R elk:elk /data/program/elasticsearch\n\n    #创建如下配置文件(config/elasticsearch.yml)(集群其它节点只修改node.name即可)\n    cd /data/program/elasticsearch\n    echo \"\" > config/elasticsearch.yml \n\n    cat > config/elasticsearch.yml <<EOF\n    cluster.name: TT-LOGS\n    node.name: t6\n    path.data: /data/program/elasticsearch/data\n    path.logs: /data/program/elasticsearch/logs\n\n    bootstrap.memory_lock: false\n    bootstrap.system_call_filter: false\n    network.host: 0.0.0.0\n    http.port: 9200\n    transport.tcp.port: 9300\n    discovery.zen.ping.unicast.hosts: [\"192.168.9.116:9300\", \"192.168.9.115:9300\", \"192.168.9.114:9300\"]\n    discovery.zen.minimum_master_nodes: 2m\n\n    http.cors.enabled: true\n    http.cors.allow-origin: \"*\"\n    http.cors.allow-credentials: true\n    EOF\n\n    #修改JVM内存（config/jvm.options）\n    -Xms2g\n    -Xmx2g\n\n    #启动集群\n    su elk && cd /data/program/elasticsearch\n    ./bin/elasticsearch -d\n\n    #安装elasticsearch-head插件\n    wget https://npm.taobao.org/mirrors/node/latest-v4.x/node-v4.5.0-linux-x64.tar.gz\n    #配置下环境变量,编辑/etc/profile添加\n    export NODE_HOME=/usr/local/node-v4.5.0-linux-x64\n    export PATH=$PATH:$NODE_HOME/bin/\n    export NODE_PATH=$NODE_HOME/lib/node_modules\n    #执行 source /etc/profile\n\n    #安装npm\n    npm install -g cnpm --registry=https://registry.npm.taobao.org\n    npm install -g grunt\n    npm install -g grunt-cli --registry=https://registry.npm.taobao.org --no-proxy\n    wget https://github.com/mobz/elasticsearch-head/archive/master.zip\n    unzip master.zip\n\n    #进入elasticsearch-head-master目录，执行下面命令\n    npm install\n\n\n    #安装完成之后，修改服务器监听地址,目录：elasticsearch-head/Gruntfile.js,增加hostname属性，设置为*\n    connect: {\n        server: {\n            options: {\n                port: 9100,\n                hostname: '0.0.0.0',\n                base: '.',\n                keepalive: true\n            }\n        }\n    }\n    #通过命令grunt server启动head\n\n\n    cat > restart.sh <<EOF\n    #!/bin/bash\n    p_num=`jps|grep Elasticsearch|wc -l`\n    if [[ \\$p_num > 0 ]];then\n            jps|grep Elasticsearch|awk '{print $1}'|xargs kill\n            echo \"ES成功关闭\"\n    else\n            echo \"ES进程已经关闭\"\n    fi\n    cd /data/program/elasticsearch\n\n    runuser -l elk -c \"/data/program/elasticsearch/bin/elasticsearch -d\"\n    if [[ $? == 0 ]];then\n            echo \"ES成功启动\"\n    else\n            echo \"ES启动失败\"\n    fi\n    EOF\n    ```\n\n### 安装配置kibana（四、五）\n\n``` bash\nwget https://artifacts.elastic.co/downloads/kibana/kibana-6.3.0-linux-x86_64.tar.gz\ntar zxvf kibana-6.3.0-linux-x86_64.tar.gz\nmv kibana-6.3.0-linux-x86_64 /data/program/kibana\n\ncd /data/program/kibana\n#配置文件在config的kibana.yml中，此处我仅修改了\nserver.port: 5601\nserver.host: \"10.112.101.90\"\nelasticsearch.url: \"http://10.112.101.90:9200\"\n\n#运行\nbin/kibana\n\n# 启动脚本\ncat > restart <<EOF\n#!/bin/bash\np_num=`ps -ef|grep node|wc -l`\nif [[ $p_num > 0 ]];then\n        ps -ef|grep node|awk '{print $2}'|xargs kill\n        echo \"kibana成功关闭\"\nelse\n        echo \"kibana进程已经关闭\"\nfi\ncd /data/program/kibana\n\nrunuser -l elk -c \"nohup /data/program/kibana/bin/kibana &\"\nif [[ $? == 0 ]];then\n        echo \"kibana成功启动\"\nelse\n        echo \"kibana启动失败\"\nfi\nEOF\n```\n### logstash安装配置（三）\n\n``` bash\nwget https://artifacts.elastic.co/downloads/logstash/logstash-6.3.0.tar.gz\ntar zxvf logstash-6.3.0.tar.gz\nmv logstash-6.3.0 /data/program/logstash\n\n#编辑配置文件，这里写一个测试的（把一下内容写进一个配置文件）\ninput {\n        file {\n                path => [\"/tmp/test_data\"]\n                codec => json {\n                        charset => \"UTF-8\"\n                }\n        }\n}\n\noutput {\n        elasticsearch {\n                hosts => [\"172.168.254.26:9200\"]\n                index => \"lalala-%{+YYYY.MM.dd}\"\n                document_type => \"test\"\n                #user => \"elastic\"\n                #password => \"changeme\"\n        }\n\n#启动logstash\ncd /data/program/logstash\nnohup ./bin/logstash -f config/test.conf &> run.log &\n\n\n#启动脚本\n#cat > restart.sh <<EOF\n#!/bin/bash\np_num=`jps|grep Logstash|wc -l`\nif [[ \\$p_num > 0 ]];then\n        jps|grep Logstash|awk '{print $1}'|xargs kill\n        echo \"Logstash成功关闭\"\nelse\n        echo \"Logstash进程已经关闭\"\nfi\ncd /data/program/logstash\n\nrunuser -l elk -c \"nohup /data/program/logstash/bin/logstash -f /data/program/logstash/config/file_to_es.conf &> run.log &\"\nif [[ $? == 0 ]];then\n        echo \"Logstash成功启动\"\nelse\n        echo \"Logstash启动失败\"\nfi\nEOF\n\n\n#制造些假数据进行测试\ncat > /tmp/test_data <<EOF\n{\"user\": \"test\", \"age\": \"11\"}\n{\"user\": \"test1\", \"age\": \"12\"}\n{\"user\": \"test2\", \"age\": \"13\"}\n{\"user\": \"test3\", \"age\": \"14\"}\n{\"user\": \"test4\", \"age\": \"15\"}\n{\"user\": \"test5\", \"age\": \"16\"}\n{\"user\": \"test6\", \"age\": \"17\"}\n{\"user\": \"test7\", \"age\": \"18\"}\n{\"user\": \"test8\", \"age\": \"19\"}\n{\"user\": \"test9\", \"age\": \"20\"}\nEOF\n\n#访问kibana，创建索引(management-->index patterns-->create index patterns)\n#如果logstatsh已经开始往elasticsearch中推送数据，则在创建index下会有显示。\n```\n\n### 安装配置zookeeper集群(二)\n``` bash\nwget http://apache.01link.hk/zookeeper/stable/zookeeper-3.4.12.tar.gz\ntar zxvf zookeeper-3.4.12.tar.gz\nmv zookeeper-3.4.12.tar.gz /data/program/zookeeper\ncd /data/program/zookeeper/conf\ncp zoo_sample.cfg zoo.cfg\ncat > zoo.cfg <<EOF\ntickTime=2000\ninitLimit=10\nsyncLimit=5\ndataDir=/data/program/zookeeper/data\nclientPort=2181\nserver.1=192.168.20.110:12888:13888\nserver.2=192.168.20.111:12888:13888\nserver.3=192.168.20.112:12888:13888\nEOF\n\n#创建数据目录,写入id\ncd /data/program/zookeeper\nmkdir -p data\necho 1 > ./data/myid\n\n#启动服务\ncd data/program/zookeeper\n./bin/zkServer.sh start\n\n#查看集群状态\n./bin/zkServer.sh status\n\n#以上所有节点配置相同，myid的值不同。\n```\n\n### 安装配置kafka集群(二)\n``` bash\nwget http://apache.01link.hk/kafka/1.1.0/kafka_2.11-1.1.0.tgz\ntar zxvf kafka_2.11-1.1.0.tgz\nmv kafka_2.11-1.1.0 /data/program/kafka\n\n#修改配置文件如下\ncd /data/program/kafka/config\nmv server.properties  server.properties.bak\ncat >  server.properties  <<EOF\nbroker.id=1\nport = 9092\nhost.name = 192.168.20.110\nlog.dirs=/data/program/kafka/logs\nlog.retention.hours=1\nzookeeper.connect=192.168.20.110:2181,192.168.20.111:2181,192.168.20.112:2181\ndefault.replication.factor=2\nEOF\n\n#创建日志目录\ncd ..\nmkdir -p logs\n#以上配置使用其它所有节点，修改broker.id和host.name即可。\n#配置好后，启动集群\n./bin/kafka-server-start.sh -daemon config/server.properties\n\n#创建topic，消费者和生产者进行测试。\n#创建topic\n./bin/kafka-topics.sh --create --zookeeper 192.168.20.110:2181 --replication-factor 1 --partitions 2 --topic logview\n#创建消费者\n./bin/kafka-console-consumer.sh --zookeeper 192.168.20.110:2181 --topic logview --from-beginning\n#另一个节点创建一个生产者\n./bin/kafka-console-producer.sh --broker-list 192.168.20.110:9092 --topic logview\n\n#生产者创建完毕后，输入任何字符，都会在消费者节点看到，说明集群简历成功。\n```\n\n### 安装配置logstatsh(二)\n``` bash\nwget https://artifacts.elastic.co/downloads/logstash/logstash-6.3.0.tar.gz\ntar zxvf logstash-6.3.0.tar.gz\nmv logstash-6.3.0 /data/program/logstash\n\n#创建配置文件，从filebeat获取日志，输出到kafka集群\ncd /data/program/logstash/config\n\ncat > filebeat_to_kafka.conf <<EOF\ninput {\n    beats {\n        port => 5044\n        }\n}\n\noutput {\n    kafka {\n        bootstrap_servers => \"192.168.20.110:9092,192.168.20.111:9092,192.168.20.112:9092\"\n        topic_id => \"logview\"\n        }\n}\nEOF\n\n#启动logstash\ncd /data/program/logstash\nnohup ./bin/logstash -f config/filebeat_to_kafka.conf &> run.log &\n```\n\n### 在应用主机安装filebeat(一)\n``` bash\nwget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.3.0-linux-x86_64.tar.gz\ntar zxvf filebeat-6.3.0-linux-x86_64.tar.gz\nmv filebeat-6.3.0-linux-x86_64 /data/programe/filebeat\n\n#修改配置文件\ncd /data/programe/filebeat\ncat > filebeat.yml <<EOF\nfilebeat.inputs:\n- type: log\n  enabled: true\n  paths:\n    - /data/test.log\nfilebeat.config.modules:\n  path: \\${path.config}/modules.d/*.yml\n  reload.enabled: false\nsetup.template.settings:\n  index.number_of_shards: 3\noutput.logstash:\n  hosts: [\"192.168.20.110:5044\"\nEOF\n\n#启动filebeat\nnohup ./filebeat -c filebeat.yml > /dev/null &\n```\n\n\n\n\n\n\n","tags":["ELK"],"categories":["数据库"]},{"title":"网站被cc攻击了该如何应对","url":"%2F2016%2F12%2F22%2F%E7%BD%91%E7%AB%99%E8%A2%ABcc%E6%94%BB%E5%87%BB%E4%BA%86%E8%AF%A5%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%2F","content":"\n如果你的网站是使用的是Nginx做的反向代理，那么可以利用Nginx原生的limit_req模块来针对请求进行限制，(ngx_http_limit_req_module 模块)当然，也可以使用tengine的limit_req模块，对官方模块进行了增强(The Tengine Web Server)或者还有一个比较高端的模块：(yaoweibin/nginx_limit_access_module 路 GitHub), 作者是,姚神\n\n<!--more-->\n作者：知道创宇 云安全\n链接：https://www.zhihu.com/question/19742963/answer/375949327\n来源：知乎\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n\nCC攻击原理攻击者控制某些主机不停地发大量数据包给对方服务器造成服务器资源耗尽，一直到宕机崩溃。\nCC主要是用来攻击页面的，每个人都有这样的体验：当一个网页访问的人数特别多的时候，打开网页就慢了，CC就是模拟多个用户(多少线程就是多少用户)不停地进行访问那些需要大量数据操作(就是需要大量CPU时间)的页面，造成服务器资源的浪费，CPU长时间处于100%，永远都有处理不完的连接直至就网络拥塞，正常的访问被中止。\nCC攻击防御策略\n1.取消域名绑定取消域名绑定后Web服务器的CPU能够马上恢复正常状态，通过IP进行访问连接一切正常。但是不足之处也很明显，取消或者更改域名对于别人的访问带来了不变，另外，对于针对IP的CC攻击它是无效的，就算更换域名攻击者发现之后，攻击者也会对新域名实施攻击。\n2.更改Web端口一般情况下Web服务器通过80端口对外提供服务，因此攻击者实施攻击就以默认的80端口进行攻击，所以，可以修改Web端口达到防CC攻击的目的。\n3.IIS屏蔽IP我们通过命令或在查看日志发现了CC攻击的源IP，就可以在IIS中设置屏蔽该IP对Web站点的访问，从而达到防范IIS攻击的目的。\n\nCC攻击的防范手段\n1.优化代码尽可能使用缓存来存储重复的查询内容，减少重复的数据查询资源开销。减少复杂框架的调用，减少不必要的数据请求和处理逻辑。程序执行中，及时释放资源，比如及时关闭mysql连接，及时关闭memcache连接等，减少空连接消耗。\n2.限制手段对一些负载较高的程序增加前置条件判断，可行的判断方法如下：必须具有网站签发的session信息才可以使用（可简单阻止程序发起的集中请求）；必须具有正确的referer（可有效防止嵌入式代码的攻击）；禁止一些客户端类型的请求（比如一些典型的不良蜘蛛特征）；同一session多少秒内只能执行一次。\n3.完善日志尽可能完整保留访问日志。日志分析程序，能够尽快判断出异常访问，比如单一ip密集访问；比如特定url同比请求激增。面对来势汹汹的CC攻击，其实最好的方式还是选择第三方的云安全厂商（就像我们）来解决问题。\n\n知道创宇国际顶尖安全研究团队为抗D保自主研发的Nightwatch Anti-CC防护引擎可以根据访问者的URL，频率、行为等访问特征，智能识别CC攻击，迅速识别CC攻击并进行拦截，在大规模CC攻击时可以避免源站资源耗尽，保证企业网站的正常访问。好的广告打完了，感谢您的阅读⁄(⁄ ⁄•⁄ω⁄•⁄ ⁄)⁄\n\n\n1. 硬件，如梭子鱼\n2. 开源waf，如openstar\n3. 商业，如知道创宇\n4. 免费 360网站卫士","tags":["cc"],"categories":["linux"]},{"title":"Fail2ban的应用","url":"%2F2016%2F12%2F02%2FFail2ban%E7%9A%84%E5%BA%94%E7%94%A8%2F","content":"\n#### 简介\n\tfail2ban可以监视你的系统日志，然后匹配日志的错误信息执行相应的屏蔽动作。网上大部分教程都是关于fail2ban+iptables组合，考虑到CentOS 7已经自带Firewalld，所以这里我们也可以利用fail2ban+Firewalld来防CC攻击和SSH爆破。\n\n### 安装fail2ban\n\n```bash\n#CentOS内置源并未包含fail2ban，需要先安装epel源\nyum -y install epel-release\n#安装fial2ban\n#因为都用Centos7了,所有说我们需要安装支持firewalld的Fail2ban版本.(因为Centos7默认的防火墙是:firewalld)\nyum -y install fail2ban fail2ban-firewalld fail2ban-systemd\n```\n<!--more-->\n#### 配置文件说明\n\n```bash\n/etc/fail2ban/action.d/ //采取相对应措施的目录\n/etc/fail2ban/fail2ban.conf //fail2ban的配置文件\n/etc/fail2ban/fail2ban.d/ //fail2ban的配置文件目录\n/etc/fail2ban/filter.d/ //具体过滤规则文件目录\n/etc/fail2ban/jail.conf //阻挡设定文件\n/etc/fail2ban/jail.d/ //阻挡设定文件的目录\n/etc/fail2ban/paths-*.conf //不同linux发行版下路径的相关设置，在jail.conf的[INCLUDES]里指定\nfail2ban.conf是针对fail2ban程序运行本身的一些设置。\njail.conf 是fail2ban的业务功能设置，里面设置了需要监控那些服务以及如何保护等，里边已经针对常用的服务提供了监控方案，比如sshd、apache、3proxy等，笔者只启用了sshd的保护。有一个[DEFAULT]部分适用于所有其他部分，除非默认选项在其他部分中覆盖。\n```\n```bash\n#基本配置解析\nignoreip ：这是一个空格分隔的IP地址列表，不能被fail2ban阻止。 例如，如果连接到服务器的计算机具有静态IP地址，则可能需要在此处列出。\nbantime ：如果被fail2ban（600秒= 10分钟）捕获，主机被阻止的时间（秒）》\nmaxretry ：最大 主机被fail2ban阻止之前失败的登录尝试次数。\n过滤器 ：指在/etc/fail2ban/filter.d中的相应过滤器文件。\nlogpath ：fail2ban检查失败的登录尝试的日志文件。\n#如/etc/fail2ban/jail.conf顶部的注释所示 ，我们不会修改/etc/fail2ban/jail.conf本身来将其调整为我们的需要，而是通过创建新的配置文件来覆盖/ etc / fail2ban / jail.local 。\n```\n#### 默认配置及参数说明\n\n```bash\n#新建配置\nvi /etc/fail2ban/jail.local\n#默认配置\n[DEFAULT]\nignoreip = 127.0.0.1/8\nbantime  = 86400\nfindtime = 600\nmaxretry = 5\n#这里banaction必须用firewallcmd-ipset,这是fiewalll支持的关键，如果是用Iptables请不要这样填写\nbanaction = firewallcmd-ipset\naction = %(action_mwl)s\n\n#参数说明：\nignoreip：IP白名单，白名单中的IP不会屏蔽，可填写多个以（,）分隔\nbantime：屏蔽时间，单位为秒（s）\nfindtime：时间范围\nmaxretry：最大次数\nbanaction：屏蔽IP所使用的方法，上面使用firewalld屏蔽端口\n```\n#### SSH防爆破配置\n\n```bash\n#继续修改jail.local这个配置文件，在后面追加如下内容：\n\n[sshd]\nenabled = true\nfilter  = sshd\nport    = 22\naction = %(action_mwl)s\nlogpath = /var/log/secure\n\n#[sshd]：名称，可以随便填写\n#filter：规则名称，必须填写位于filter.d目录里面的规则，sshd是fail2ban内置规则\n#port：对应的端口\n#action：采取的行动\n#logpath：需要监视的日志路径\n```\n\n#### 防止CC攻击\n\n```bash\n#这里仅以Nginx为例，使用fail2ban来监视nginx日志，匹配短时间内频繁请求的IP，并使用firewalld将其IP屏蔽，达到CC防护的作用。\n\n#需要先新建一个nginx日志匹配规则\nvi /etc/fail2ban/filter.d/nginx-cc.conf\n#填写如下内容\n[Definition]\nfailregex =  -.*- .*HTTP/1.* .* .*$\nignoreregex =\n#继续修改jail.local追加如下内容：\n\n[nginx-cc]\nenabled = true\nport = http,https\nfilter = nginx-cc\naction = %(action_mwl)s\nmaxretry = 20\nfindtime = 60\nbantime = 3600\nlogpath = /usr/local/nginx/logs/access.log\n#上面的配置意思是如果在60s内，同一IP达到20次请求，则将其IP ban 1小时，上面只是为了测试，请根据自己的实际情况修改。logpath为nginx日志路径。\n```\n\n#### 常用操作\n\n```bash\n#启动\nsystemctl start fail2ban\n#重启\nsystemctl restart fail2ban\n#开机重启\nsystemctl enable fail2ban\n#查看状态\nsystemctl status fail2ban.service\n#查看配置状态\nfail2ban-client status\n#默认配置\nvim /etc/fail2ban/jail.conf\n#查看攻击者\nfail2ban-client status sshd\n#确保防火墙已开起\nsystemctl enable firewalld\nsystemctl start firewalld\n#更新 SELinux 策略\nyum update -y selinux-policy*\n#查看被禁用的ip\niptables -L -n\n#查看登陆失败日志\ncat /var/log/secure | grep 'Failed password'\n#解锁ip\nfail2ban-client set sshd unbanip IPADDRESS\n```","tags":["攻击防护"],"categories":["数据库"]},{"title":"CMDB、ITIL和ITSM间的关系","url":"%2F2016%2F11%2F14%2FCMDB%E3%80%81ITIL%E5%92%8CITSM%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB%2F","content":"\n#### ITSM（Information Technology Service Management）\n\n\tIT项目的生命周期中只有20%的时间与规划、建设、设施有关，其余80%的时间都与IT项目的服务和运维有关。随着企业信息化建设的不断深入，为了保证IT服务的质量，ITSM应运而生。\n\tITSM是一个理念，是一套方法论，可以帮助企业对IT服务进行有效管理的高质量。它结合了高质量服务不可缺少的流程、人员和技术三大要素：标准流程负责监控IT服务的运行状况；人员素质关系到服务质量的高低；技术则保证服务的质量和效率。这三大关键性要素的整合使ITSM 成为企业IT管理人员管理企业IT系统的法宝和利器。ITSM的根本目标也有三个：以客户为中心提供IT服务；提供高质量、低成本的服务；提供的服务是可准确计价的。\n\tITSM从宏观的角度可以理解为是一个领域或行业；从中观的角度可以理解为是一种IT管理的方法论；从微观角度则可以理解为是一套协同运作的流程。就微观层次来讲，ITSM作为一种全新的IT管理理念和方法论，通过一套协同运作的流程，可以帮助IT部门以合理的成本提供更高质量的IT服务。\n<!--more-->\n#### ITIL（Information Technology Infrastructure Library）\n\n\tITIL是CCTA（英国国家计算机和电信局）于20世纪80年代中期开始开发的一套针对IT行业的服务管理标准库。\n\tITIL产生的背景是，当时英国政府为了提高政府部门IT服务的质量，启动一个项目来邀请国内外知名IT厂商和专家共同开发一套规范化的、可进行财务计量的IT资源使用方法。这种方法应该是独立于厂商的，并且可适用于不同规模、不同技术和业务需求的组织。这个项目的最终成果就是现在被广泛认可的ITIL，它把英国各个行业在IT管理方面的最佳实践归纳起来变成规范，旨在提高IT资源的利用率和IT服务质量。目前已经成为业界通用的事实标准。\n\n#### 两者之间的关系和区别\n\n\t1）ITIL是ITSM领域的最佳实践，ITIL为ITSM提供创建了一组核心流程和专有名词；\n\t2）ITIL并不是ITSM的全部，ITIL只是告诉我们什么该做，但没有说具体怎么做，而对ITSM而言，这些都是ITSM的范围；\n\t3）先有ITSM理念，后有ITIL标准；因为ITIL，ITSM才得到关注和发扬；\n\t4）ITIL是标准，是ITSM实施过程中的抽象和经验总结，它是ITSM实施中的一套流程和准则；\n\t5）ITIL和ITSM是企业信息化发展到一定阶段出现的产物,是IT技术在现代企业中重要性的一种体现。\n\n#### IT管理关键模块\n\n\tITIL中有十个重要的IT管理关键模块，分别是配置管理、服务台、问题管理、变更管理、软件控制和发布、服务管理、容量管理、可用度管理、意外事件管理、费用管理。\n\n(1)配置管理(Configuration Management)\n\t配置管理的目的是在维持配置管理数据库(CMDB)中每个IT基础建设的配置记录。第二个目的是提供配置项目(CI)的报表。这包含了一些管理信息如问题记录，变动记录，版本信息，状态信息，关系信息等。在实际的项目中，CMDB常常被认为是构建其它ITIL流程的基础而优先考虑，ITIL项目的成败与是否成功建立CMDB有非常大的关系。\n\n \n(2)服务台(Help Desk)\n\t服务台提供每天对IT使用者的服务窗口。使用者反馈对IT服务不满、疑问和建议等。基于这个原因，服务台应该是一个很容易让使用者可以反馈的界面窗口。服务台同时也是使用者在使用IT服务的登录点，他们的表现代表IT服务给客户的服务品质。服务台同时也要负责尽快地协助顾客恢复服务的运作，比如提供使用指引，修正，或针对某一意外事件做补救。服务台不负责意外事件的分析，这类的深入分析是属于问题管理的范畴。\n\n \n(3)问题管理(Problem Management)\n\t问题管理的目的是在找出并去除IT服务中的错误，以维持一个稳定的IT服务。\n\n \n(4)变更管理 (Change Management)\n\t变更管理的目的是要确保在IT服务变动的过程中能够有标准化的方法以有效地监控这些变动，降低或消除因为变动所造成的问题。所谓“变动”是指一些在IT基础建设项目上的动作所造成一个新的状态。所有在配置项目上的变动都必需纳入变更管理的控制。\n\n \n(5)软件控制和发布 (Software Control & Distribution)\n\t软件控制和发布的目的是要保障所有软件模块的安全性，以确保只有经过完整测试的正确版本得到授权进入正式运作环境。为了控制软件的版本，我们必需建立一个“最终软件库”(Definitive SoftwareLibrary；DSL)，这可能是一个有实体或逻辑上的储藏室。不论哪一种形式，它就是一个存放正式授权软件版本的地方。\n\n(6)服务管理(Service Management)\n\t服务管理的目的是要在一个可接受的成本下，让服务提供者和顾客之间达成一个彼此同意的最佳服务协议。这表示服务管理是需要服务供应者和接受者之间长期沟通的。服务管理着重在从商业角度考虑的服务水准，而不是从IT的观点。长期的端到端的监控报告和每个组成部分的使用率虽然重要，但对企业的服务品质才是重点。\n\n(7)容量管理 (Capacity Management)\n\t容量管理的目的是要支持IT服务的最佳效率，主要是在调整营运需求和IT资源的平衡。简单地说，容量管理是要确保在合适的时间，地点和适当的成本下提供合适的资源。对IT部门来说，有效地利用可用资源很重要，并且要对系统营运的未来需求制定计划。\n\n(8)可用性管理(Availability Management)\n\t可用性管理是在正确使用资源，方法及技术的前提下，保障IT服务的可用性。当企业营运越来越依赖IT，为了维持竞争力，IT必需避免或减小预期外的当机时间。可用度管理在深入探讨那些资源和测量是维持最佳营运状态所必要的，希望能让资源的使用最有效。\n\n(9)意外事故管理(Contingency Management)\n\t意外事件管理是处理IT的危机并要从中恢复运转，例如有一段时间无法提供服务，这需要将工作转移到另一套系统，而这并不应是平常会遇到的。我们必需发展一套在面临IT危机时能够恢复正常运转的计划以备不时之需。\n\n(10)费用管理(Cost Management)\n\t费用管理是在提供深入了解，监督和IT恢复运作的花费。这个程序提供了相关的财务信息以期达到性价比最高。没有费用管理，就很难制定服务质量协议(Service Level Agreement)。","tags":["itsm"],"categories":["linux"]},{"title":"系统初始化常用的工具包","url":"%2F2016%2F10%2F22%2F%E7%B3%BB%E7%BB%9F%E5%88%9D%E5%A7%8B%E5%8C%96%E5%B8%B8%E7%94%A8%E7%9A%84%E5%B7%A5%E5%85%B7%E5%8C%85%2F","content":"\n#### 简介\n\t我比较喜欢操作系统最小化安装，这样虽然避免系统安装很多无用的工具和程序，但是也会为将来我们对系统的使用造成诸多的不便。为了解决诸多不便，我们可以在最小化安装系统后再去安装一些自己需要的包，这样既减少了系统资源的消耗，又能方便日后工作。以下对我常使用的工具罗列和记录。\n\n#### YUM源管理\n\n```bash\nyum install epel-release -y\n#epel提供了丰富的yum 安装第三方软件源\n```\n\n#### 进程管理\n\n```bash\nyum install psmisc -y\n#psmisc 提供pstree、killall、fuser等常用工具\n#fuser 显示使用指定文件或者文件系统的进程的PID。\n#killall 杀死某个名字的进程，它向运行指定命令的所有进程发出信号。\n#pstree 树型显示当前运行的进程。\n#pstree.x11 与pstree功能相同，只是在退出前需要确认。\n```\n\n#### 网络工具\n\n```bash\nyum install net-tools telnet bind-utils traceroute  nmap-ncat -y\n#net-tools 包含了ifconfig、netstat等工具\n#bind-utils包含nslookup dig\n```\n#### 其它工具\n\n```bash\nyum install lrzsz wget unzip zip\n```","tags":["yum"],"categories":["linux"]},{"title":"使用CacheCloud管理Redis实例","url":"%2F2016%2F10%2F13%2F%E4%BD%BF%E7%94%A8CacheCloud%E7%AE%A1%E7%90%86Redis%E5%AE%9E%E4%BE%8B%2F","content":"\n#### CacheCloud是什么？\n\t最近在使用CacheCloud管理Redis，所以简单说一下，这里主要说一下我碰到的问题。CacheCloud官网从安装到使用文档非常详细了。\n\tCacheCloud提供一个Redis云管理平台：实现多种类型(Redis Standalone、Redis Sentinel、Redis Cluster)自动部署、解决Redis实例碎片化现象、提供完善统计、监控、运维功能、减少运维成本和误操作，提高机器的利用率，提供灵活的伸缩性，提供方便的接入客户端。\n\n#### 下载CacheCloud二进制版本\n\n```bash\n#下载CacheCloud\n#项目源码地址：https://github.com/sohutv/cachecloud，开发者主页：https://cachecloud.github.io\n#二进制下载地址：https://pan.baidu.com/s/1nvTv90l\n```\n<!--more-->\n#### 准备Mysql环境\n\t略...\n#### 准备JDK环境\n\t不要使用openJdk，需要使用Oracle提供的JDK，确保jdk 1.7+，去Oracle官网下载二进制版本。\n\t环境安装 略...\n\n#### 初始化CacheCloud数据\n\t导入项目中cachecloud.sql初始化库表结构，默认插入admin超级管理员。\n\t由于MySQL 5.7使用了严格SQL模式，会导致cachecloud.sql导入报错的，所以直接取消SQL模式即可（最好也修改一下my.cnf配置文件）。\n```bash\nmysql> set global sql_mode='';\nmysql> set session sql_mode='';\n#创建字符集为utf8的数据库并导入数据\nmysql> create database cachecloud charset utf8;\nmysql> use cachecloud;\nmysql> source /root/cachecloud/script/cachecloud.sql;\n\n#创建CacheCloud连接用户\nmysql> grant all on *.* to 'admin'@'localhost' identified by 'admin';\nmysql> grant all on *.* to 'admin'@'127.0.0.1' identified by 'admin';\nmysql> flush privileges;\n```\n\n#### CacheCloud项目配置\n\n```bash\ncat /opt/cachecloud-web/jdbc.properties \ncachecloud.db.url = jdbc:mysql://127.0.0.1:3306/cache_cloud?useUnicode=true&characterEncoding=UTF-8\ncachecloud.db.user = admin\ncachecloud.db.password = admin\ncachecloud.maxPoolSize = 20\njdbc.driver = com.mysql.jdbc.Driver\njdbc.validationQuery = select 1 from dual\n```\n#### 启动\n\t执行项目根目录下的start.sh即可启动。","tags":["CacheCloud"],"categories":["数据库"]},{"title":"Docker的常用操作","url":"%2F2016%2F10%2F09%2FDocker%E7%9A%84%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F","content":"\n#### 搭建私有仓库\n\n```bash\n#拉取镜像\ndocker pull registry\n#创建数据库镜像\nmkdir -p /data/docker/registry\n#启动容器，建立registry实例。/data/docker/registry/ 这个为物理机的路径。\ndocker run -d --name registry -p 5000:5000 --restart=always -v /data/docker/registry/:/var/lib/registry/ registry\n\n#配置daemon.json，去掉docker默认的https的访问\ncat /etc/docker/daemon.json\n{ \"insecure-registries\":[\"192.168.3.180:5000\"] }\n```\n\n#### Docker CLI自动补全\n\n```bash\n#执行以下脚本，重新打开shell即可\nyum install -y bash-completion\n/usr/share/bash-completion/bash_completion \n\n```\n<!--more-->\n#### 镜像操作\n\n```bash\n#Dockerfile生成镜像\ndocker build -t group/nginx .\n#-t 指定生成镜像的名字\n#.  指定Dockerfile的位置\n\n#拉取镜像，从默认仓库\ndocker pull nginx\n#拉取镜像，从指定仓库\ndocker pull 192.168.3.180:5000/nginx\n\n#查看本地镜像 -a，代表所有镜像\ndocker images -a\n\n#删除镜像,rmi 后面可以是镜像名称或者ID,-f 代表强制删除\ndocker rmi -f nginx\n\n#tag镜像\ndocker tag nginx 192.168.3.180:5000/nginx:v1.2\n\n#提交镜像\ndocker push 192.168.3.180:5000/nginx:v1.2\n```\n\n#### 容器操作\n\n```bash\n#运行一个容器\ndocker run -dit -p 80:8080 -v /volume/:/data 015502052fc4\ndocker run -dit -p 80:8080 -v /volume/:/data 192.168.3.180:5000/nginx:v1.2\n\n#查看所有容器\ndocker ps -a\n\n#进入容器Shell(可交互)\ndocker exec -it 578e7904aae7 /bin/bash\n\n#启动一个容器\ndocker start 578e7904aae7\n#关闭一个容器\ndocker stop 578e7904aae7\n#删除一个容器\ndocker rm 578e7904aae7\n```","tags":["容器化"],"categories":["容器化"]},{"title":"Docker的核心及概念","url":"%2F2016%2F10%2F09%2FDocker%E7%9A%84%E6%A0%B8%E5%BF%83%E5%8F%8A%E6%A6%82%E5%BF%B5%2F","content":"\n![](http://www.machunpeng.cn/server/../Public/Uploads/2018-04-26/5ae16fe530602.jpg)\n\n#### 镜像 image\n\tDocker 把应用程序及其依赖，打包在 image 文件里面。只有通过这个文件，才能生成 Docker 容器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。\n\timage 是二进制文件。实际开发中，一个 image 文件往往通过继承另一个 image 文件，加上一些个性化设置而生成。举例来说，你可以在 Ubuntu 的 image 基础上，往里面加入 Apache 服务器，形成你的 image。\n<!--more-->\n#### 仓库 registry\n\t仓库是集中存放镜像的地方，注册服务器是存放仓库的具体服务器，每个服务器可以有多个仓库，每个仓库可以有多个镜像。\n\t仓库分为公共仓库和私有仓库。\n\t1、Docker Hub\n\tDocker官方维护了一个公共的仓库https://hub.docker.com 其中包含了15000多个镜像，大部分需求都可以通过DockerHub中直接下载镜像来实现。\n\t我们可以通过docker login命令来输入用户名、密码和邮箱来完成注册和登录。注册成功后，本地用户目录的.dockercfg中将保存用户的认证信息。\n\t我们可以通过docker search命令来搜索镜像，docker pull 下载镜像,docker push命令上传本地镜像。\n\t2、创建和使用私有仓库\n\t我们可以通过官方提供的registry镜像来简单搭建一套本地私有仓库。\n\n#### 容器 container\n\t容器是从镜像创建的应用运行实例，容器之间是相互隔离、互不可见的。可以把容器看做一个简易版的linux系统环境（包括root权限、进程空间、用户空间和网络空间等），以及运行在这个环境上的应用打包而成的应用盒子。\n\t镜像自身是自读的，容器从镜像启动的时候，docker会在镜像的最上层创建一个可写文件层，镜像本身保持不变。\n\t可以利用docker create命令创建一个容器，创建后的的容器处于停止状态，可以使用docker start命令来启动它。也可以运行docker run命令来直接从镜像启动运行一个容器。docker run = docker create + docker start。\n     当利用docker run创建并启动一个容器时，docker在后台的标准操作包括：\n    （1）检查本地是否存在指定的镜像，不存在就从公有仓库下载。\n    （2）利用镜像创建并启动一个容器。\n    （3）分配一个文件系统，并在只读的镜像层外面挂载一层可读写层。\n    （4）从宿主机配置的网桥接口中桥接一个虚拟的接口到容器中。\n    （5）从地址池中配置一个IP地址给容器。\n    （6）执行用户指定的应用程序。\n    （7）执行完毕后容器终止。","tags":["容器化"],"categories":["容器化"]},{"title":"Docker简介","url":"%2F2016%2F10%2F09%2FDocker%E7%AE%80%E4%BB%8B%2F","content":"\n#### 环境配置的难题\n2013年发布至今， Docker 一直广受瞩目，被认为可能会改变软件行业。\n但是，许多人并不清楚 Docker 到底是什么，要解决什么问题，好处又在哪里？本文就来详细解释，帮助大家理解它，还带有简单易懂的实例，教你如何将它用于日常开发。\n软件开发最大的麻烦事之一，就是环境配置。用户计算机的环境都不相同，你怎么知道自家的软件，能在那些机器跑起来？\n用户必须保证两件事：操作系统的设置，各种库和组件的安装。只有它们都正确，软件才能运行。举例来说，安装一个 Python 应用，计算机必须有 Python 引擎，还必须有各种依赖，可能还要配置环境变量。\n如果某些老旧的模块与当前环境不兼容，那就麻烦了。开发者常常会说：\"它在我的机器可以跑了\"（It works on my machine），言下之意就是，其他机器很可能跑不了。\n环境配置如此麻烦，换一台机器，就要重来一次，旷日费时。很多人想到，能不能从根本上解决问题，软件可以带环境安装？也就是说，安装的时候，把原始环境一模一样地复制过来。\n<!--more-->\n#### 虚拟机\n虚拟机（virtual machine）就是带环境安装的一种解决方案。它可以在一种操作系统里面运行另一种操作系统，比如在 Windows 系统里面运行 Linux 系统。应用程序对此毫无感知，因为虚拟机看上去跟真实系统一模一样，而对于底层系统来说，虚拟机就是一个普通文件，不需要了就删掉，对其他部分毫无影响。\n虽然用户可以通过虚拟机还原软件的原始环境。但是，这个方案有几个缺点。\n（1）资源占用多\n虚拟机会独占一部分内存和硬盘空间。它运行的时候，其他程序就不能使用这些资源了。哪怕虚拟机里面的应用程序，真正使用的内存只有 1MB，虚拟机依然需要几百 MB 的内存才能运行。\n（2）冗余步骤多\n虚拟机是完整的操作系统，一些系统级别的操作步骤，往往无法跳过，比如用户登录。\n（3）启动慢\n启动操作系统需要多久，启动虚拟机就需要多久。可能要等几分钟，应用程序才能真正运行。\n\n#### Linux 容器\n由于虚拟机存在这些缺点，Linux 发展出了另一种虚拟化技术：Linux 容器（Linux Containers，缩写为 LXC）。\nLinux 容器不是模拟一个完整的操作系统，而是对进程进行隔离。或者说，在正常进程的外面套了一个保护层。对于容器里面的进程来说，它接触到的各种资源都是虚拟的，从而实现与底层系统的隔离。\n由于容器是进程级别的，相比虚拟机有很多优势。\n（1）启动快\n容器里面的应用，直接就是底层系统的一个进程，而不是虚拟机内部的进程。所以，启动容器相当于启动本机的一个进程，而不是启动一个操作系统，速度就快很多。\n（2）资源占用少\n容器只占用需要的资源，不占用那些没有用到的资源；虚拟机由于是完整的操作系统，不可避免要占用所有资源。另外，多个容器可以共享资源，虚拟机都是独享资源。\n（3）体积小\n容器只要包含用到的组件即可，而虚拟机是整个操作系统的打包，所以容器文件比虚拟机文件要小很多。\n总之，容器有点像轻量级的虚拟机，能够提供虚拟化的环境，但是成本开销小得多。\n\n#### Docker 是什么\nDocker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。\nDocker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。\n总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。\n\n#### Docker 的用途\n Docker 的主要用途，目前有三大类。\n（1）提供一次性的环境。比如，本地测试他人的软件、持续集成的时候提供单元测试和构建的环境。\n（2）提供弹性的云服务。因为 Docker 容器可以随开随关，很适合动态扩容和缩容。\n（3）组建微服务架构。通过多个容器，一台机器可以跑多个服务，因此在本机就可以模拟出微服务架构。\n","tags":["容器化"],"categories":["容器化"]},{"title":"单机多网口高可用实现","url":"%2F2016%2F07%2F13%2F%E5%8D%95%E6%9C%BA%E5%A4%9A%E7%BD%91%E5%8F%A3%E9%AB%98%E5%8F%AF%E7%94%A8%E5%AE%9E%E7%8E%B0%2F","content":"\n#### 查看内核是否支持bonding模块\n\n```bash\n[root@mfsmaster ~]# cat /boot/config-2.6.32-358.el6.x86_64 |grep -i bonding\nCONFIG_BONDING=m\n```\n#### 创建虚拟网口定义文件\n\n```bash\ncat /etc/sysconfig/network-scripts/ifcfg-bond0\nDEVICE=\"bond0\"\nBOOTPROTO=\"static\"\nIPV6INIT=\"no\"\nIPADDR=172.26.1.1\nNETMASK=255.255.255.0\nGATEWAY=172.26.1.254\nDNS1=114.114.114.114\nDNS2=211.136.20.203\nMTU=\"1500\"\nNM_CONTROLLED=\"yes\"\nONBOOT=\"yes\"\nTYPE=\"Ethernet\"\nUSERCTL=\"no\"\n```\n<!--more-->\n#### 修改要绑定的物理网口定义文件\n\n```bash\ncat /etc/sysconfig/network-scripts/ifcfg-eth0\nDEVICE=eth0\nBOOTPROTO=none\nONBOOT=yes\nUSERCTL=no\nMASTER=bond0\nSLAVE=yes\n\ncat /etc/sysconfig/network-scripts/ifcfg-eth1\nDEVICE=eth1\nBOOTPROTO=none\nONBOOT=yes\nUSERCTL=no\nMASTER=bond0\nSLAVE=yes\n```\n#### 创建bonding.conf文件\n\n```bash\ncat　/etc/modprobe.d／bonding.conf\nalias bond0 bonding\noptions bond0 miimon=100 mode=1\n\n＃重启网络服务，完成\nservice network restart\n```","tags":["高可用"],"categories":["linux"]},{"title":"Firewalld的应用","url":"%2F2016%2F07%2F12%2FFirewalld%E7%9A%84%E5%BA%94%E7%94%A8%2F","content":"\n#### 简介\n\tFirewalld服务是红帽RHEL7系统中默认的防火墙管理工具，特点是拥有运行时配置与永久配置选项且能够支持动态更新以及\"zone\"的区域功能概念，使用图形化工具firewall-config或文本管理工具firewall-cmd。　防火墙的网络区域定义了网络连接的可信等级，我们可以根据不同场景来调用不同的firewalld区域\n\n#### zone概念\n\n```bash\n硬件防火墙默认一般有三个区，firewalld引入这一概念系统默认存在以下区域：\ndrop：（丢弃），任何接受的网络数据包都被丢弃，没有任何回复。仅能有发送出去的网络连接。\nblock：（限制）拒绝所有外部连接，允许内部发起的连接，任何接受的网络连接都被IPV4的icmp-host-prohibited信息和ipv6的icmp6-adm-prohibited信息所拒绝。\npublic：（公共）在公共区域内使用，不能相信网络内的其他计算机不会对你的计算造成危害，只能接受经过选取的连接。\nexternal：（外部）特别是为路由器启用了伪装功能的外部网。你不能信任来自网络的其他计算，不嫩更相信他们不会对你的计算机造成危害，只能接受经过选择的连接。\ndmz：（非军事区）用于你的非军事区内的电脑，此区域内可公开访问，可以有限地进入你的内部网络，仅仅接受经过选择的连接。\nwork：用于工作区。你可以基本相信网络内的其他电脑不会危害你的电脑。仅仅接受经过选择的连接。\nhome：用于家庭网络。你可以基本相信网络内的其他计算机不会危害你的计算机。仅仅接受经过选择的连接。\ninternal：用于内部网络，你可以基本信任网络内的其他计算机不会威胁你的计算机，仅仅接受经过选择的连接。\ntrusted：可接受所有的网络连接\n```\n<!--more-->\n#### 安装运行Firewalld\n\n```bash\n#安装\nyum install firewalld firewall-config\n#启动\nsystemctl start  firewalld\n#查看状态\nsystemctl status firewalld 或者 firewall-cmd --state\n#停止\nsystemctl disable firewalld\n#禁用\nsystemctl stop firewalld\n```\n\n#### 常用操作\n\n```bash\n#查看版本\nfirewall-cmd --version\n#查看帮助\nfirewall-cmd --help\n#显示状态\nfirewall-cmd --state\n#查看区域信息\nfirewall-cmd --get-active-zones\n#查看当前的区域\nfirewall-cmd --get-default-zone\n#查看指定接口所属区域\nfirewall-cmd --get-zone-of-interface=eth0\n#给指定网卡设置zone\nfirewall-cmd --zone=public --add-interface=eth0\n#针对网卡更改zone\nfirewall-cmd --zone=dmz --change-interface=eth0\n#针对网卡删除zone\nfirewall-cmd --zone=dmz --remove-interface=eth0\n#设置默认规则为dmz\nfirewall-cmd --set-default-zone=dmz\n#查看public域中的所有服务\nfirewall-cmd --zone=public --list-services\n#查看public域中的所有端口\nfirewall-cmd --zone=public --list-ports \n\n#允许8080与8081端口流量通过public区域，立即生效且永久生效\nfirewall-cmd --permanent --zone=public --add-port=8080-8081/tcp\nfirewall-cmd --reload\n#拒绝192.168.10.0/24网段的用户访问ssh服务\nfirewall-cmd --permanent --zone=public --add-rich-rule=\"rule family=\"ipv4\" source address=\"192.168.10.0/24\" service name=\"ssh\" reject\"\n\n#将访问主机888端口的请求转发至22端口\nfirewall-cmd --permanent --zone=public --add-forward-port=port=888:proto=tcp:toport=22:toaddr=192.168.0.85\nfirewall-cmd --reload\n#不再允许http服务流量通过public区域，要求立即生效且永久生效\nfirewall-cmd --permanent --zone=public --remove-service=http\nfirewall-cmd --reload\n\n#拒绝所有包\nfirewall-cmd --panic-on\n#取消拒绝状态\nfirewall-cmd --panic-off\n#查看是否拒绝\nfirewall-cmd --query-panic\n\n#更新防火墙规则\nfirewall-cmd --reload\nfirewall-cmd --complete-reload\n#两者的区别就是第一个无需断开连接，就是firewalld特性之一动态添加规则，第二个需要断开连接，类似重启服务\n\n#将接口添加到区域，默认接口都在public\nfirewall-cmd --zone=public --add-interface=eth0\n#永久生效再加上 --permanent 然后reload防火墙\n#设置默认接口区域\n# firewall-cmd --set-default-zone=public\n#立即生效无需重启\n#查看所有打开的端口：\nfirewall-cmd --zone=dmz --list-ports\n#加入一个端口到区域：\nfirewall-cmd --zone=dmz --add-port=8080/tcp\n#添加服务\nfirewall-cmd --zone=work --add-service=smtp\n#移除服务\nfirewall-cmd --zone=work --remove-service=smtp\n```\n","tags":["iptales"],"categories":["linux"]},{"title":"Elasticsearch的备份和恢复","url":"%2F2016%2F07%2F02%2FElasticsearch%E7%9A%84%E5%A4%87%E4%BB%BD%E5%92%8C%E6%81%A2%E5%A4%8D%2F","content":"\n#### 创建备份目录\n\n```bash\nmkdir /data/backup\nchmod 777 /data/backup\n```\n\n#### 修改ES配置\n\n```bash\n#在elasticsearch.yml中加入一行:\npath.repo:  /mnt/backup/\n#或者直接修改/etc/init.d/elasticsearch,将原来的DAEMON_OPTS选项\nDAEMON_OPTS=\"-d -p $PID_FILE --default.path.home=$ES_HOME --default.path.logs=$LOG_DIR --default.path.data=$DATA_DIR --default.path.conf=$CONF_DIR\"\n#修改为:\nREPO_DIR=/mnt/backup\nDAEMON_OPTS=\"-d -p $PID_FILE --default.path.home=$ES_HOME --default.path.logs=$LOG_DIR \n\n#修改后重启es集群\n```\n<!--more-->\n\n#### 创建备份仓库\n\n```bash\ncurl -XPUT 'http://192.168.1.10:9200/_snapshot/EsBackup_zip' -d '{\n\"type\": \"fs\",\n\"settings\": {\n    \"location\": \"/mnt/backup/compress_snapshot\",\n    \"compress\": true\n    }\n}'\n#成功后结果返回{\"acknowledged\":true}. 这时查看刚创建的仓库:\n\ncurl -XGET 'http://192.168.1.10:9200/_snapshot?pretty'\n#正常结果返回:\n{\n  \"EsBackup_zip\" : {\n    \"type\" : \"fs\",\n    \"settings\" : {\n      \"compress\" : \"true\",\n      \"location\" : \"/mnt/backup/compress_snapshot\"\n    }\n  }\n}\n```\n\n#### 备份指定索引数据\n\n```bash\n#假设要备份单个索引, 索引名为: user_behavior_201702\ncurl -XPUT 'http://192.168.1.10:9200/_snapshot/EsBackup_zip/snapshot_user_behavior_201702' -d '{\"indices\": \"user_behavior_201702\"}'\n#提交备份快照请求后, 查看备份状态:\ncurl -XGET 'http://192.168.1.12:9200/_snapshot/EsBackup_zip/snapshot_user_behavior_201702?pretty'\n#假设要备份多个索引, 比如idx_1, idx_2, idx_3, 则可以:\ncurl -XPUT 'http://192.168.1.10:9200/_snapshot/EsBackup_zip/snapshot_some_name' -d '{\"indices\": \"idx_1,idx_2,idx_3\"}'\n#假设要备份全部索引数据, 则可以:\ncurl -XPUT 'http://192.168.1.10:9200/_snapshot/EsBackup_zip/snapshot_all'\n```\n\n#### 恢复备份索引\n\n```bash\n#删除已备份的索引:\ncurl -XDELETE \"http://192.168.1.10:9200/user_behavior_201702\"\n#恢复单个索引:\ncurl -XPOST 'http://192.168.1.10:9200/_snapshot/EsBackup_zip/snapshot_user_behavior_201702/_restore' -d '{\n    \"indices\": \"user_behavior_201702\", \n    \"rename_replacement\": \"restored_ub_201702\"\n}'\n#恢复整个快照索引:\ncurl -XPOST 'http://192.168.1.10:9200/_snapshot/EsBackup_zip/snapshot_some_name/_restore'\n#提交请求成功后返回{\"accepted\":true}。\n#查看恢复状态:\ncurl -XGET \"http://192.168.1.10:9200/_snapshot/EsBackup_zip/snapshot_user_behavior_20170\n```","tags":["Elasticsearch"],"categories":["数据库"]},{"title":"Elasticsearch安装","url":"%2F2016%2F07%2F02%2FElasticsearch%E5%AE%89%E8%A3%85%2F","content":"\n#### 基本名词\n\n```bash\nindex: es里的index相当于一个数据库。 \ntype: 相当于数据库里的一个表。 \nid： 唯一，相当于主键。 \nnode:节点是es实例，一台机器可以运行多个实例，但是同一台机器上的实例在配置文件中要确保http和tcp端口不同。 \ncluster:代表一个集群，集群中有多个节点，其中有一个会被选为主节点，这个主节点是可以通过选举产生的，主从节点是对于集群内部来说的。 \nshards：代表索引分片，es可以把一个完整的索引分成多个分片，这样的好处是可以把一个大的索引拆分成多个，分布到不同的节点上，构成分布式搜索。分片的数量只能在索引创建前指定，并且索引创建后不能更改。 \nreplicas:代表索引副本，es可以设置多个索引的副本，副本的作用一是提高系统的容错性，当个某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高es的查询效率，es会自动对搜索请求进行负载均衡\n```\n\n#### 下载安装\n\n```bash\nwget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.2.2.tar.gz\ntar zxvf elasticsearch-6.2.2.tar.gz\nmv elasticsearch-6.2.2 /data/program/elasticsearch-6.2.2\n```\n<!--more-->\n\n#### 配置\n\n```bash\nsed \"/^#/d\" elasticsearch.yml \n\n#----------------- Paths ---------------------\npath.data: /data/program/elasticsearch/data\npath.logs: /data/program/elasticsearch/logs\n#---------------- Memory --------------\nbootstrap.memory_lock: false\nbootstrap.system_call_filter: false\n#--------------- Network -------------\nnetwork.host: 0.0.0.0\nhttp.port: 9200\n\n\n#修改内存配置文件：\nvim jvm.options\n\n-Xms512m\n-Xmx512m\n\n#改系统参数\nvi /etc/sysctl.conf \n#添加下面配置：\nvm.max_map_count=65536\n\nvi /etc/security/limits.conf \n* soft nofile 819200 \n* hard nofile 819200 \n* soft nproc 2048\n* hard nproc 4096 \n\nvi /etc/security/limits.d/90-nproc.conf \n* soft nproc 1024\n#修改为\n* soft nproc 4096\n```\n#### 创建启动脚本\n\n```bash\nvi start.sh\nrunuser -l es -c '/data/program/elasticsearch-6.2.2/bin/elasticsearch -d'\n```\n#### 安装插件\n\n```bash\n#安装中文分词插件：\ngit clone https://github.com/medcl/elasticsearch-analysis-ik\n#下载完切换到相应版本：git checkout tags/v6.2.2\n#进入elasticsearch-analysis-ik文件夹内执行：mvn clean package命令打包编译。\n#将target/releases文件夹内的elasticsearch-analysis-ik-6.2.2.zip copy到es的plugins文件夹内\n#解压后修改文件夹名称为analysis-ik\n#重启生效\n\n#安装head插件\n#在https://github.com/mobz/elasticsearch-head上下载head插件，并解压到/usr/local/elasticsearch-6.2.2/\n#Head插件可以实现基本信息的查看，rest请求的模拟，数据的检索等等\n\n#必须要有node环境，没有的话需要安装：\nwget https://npm.taobao.org/mirrors/node/latest-v4.x/node-v4.4.7-linux-x64.tar.gz\n\n#添加环境变量：\nNODE_HOME=/usr/local/node-v4.4.7-linux-x64\nPATH=$PATH:$NODE_HOME/bin \nNODE_PATH=$NODE_HOME/lib/node_modules \nexport NODE_HOME PATH NODE_PATH\n\nnode -v\n\n#安装grunt-cli\nnpm install -g grunt-cli\ngrunt -version\n\n#修改文件Gruntfile.js，在第93行添加一行：\nhostname: '0.0.0.0',\n\n#在/usr/local/elasticsearch-6.2.2/elasticsearch-head下执行：\nnpm install\n#安装完成后会生成一个node_modules的文件夹\n\n#修改elasticsearch.yml配置文件，添加两行：\nhttp.cors.enabled: true \nhttp.cors.allow-origin: \"*\"\n\n#执行命令启动head服务：\ngrunt server\n```\n\n#### 导入数据测试\n\n```bash\ncurl -H \"Content-Type: application/json\" -XPOST 'localhost:9200/bank/account/_bulk?pretty' --data-binary \"@accounts.json\"\n```","tags":["Elasticsearch"],"categories":["数据库"]},{"title":"Elasticsearch-head介绍","url":"%2F2016%2F07%2F02%2FElasticsearch-head%E4%BB%8B%E7%BB%8D%2F","content":"\n\telasticsearch-head是一个界面化的集群操作和管理工具，可以对集群进行傻瓜式操作。你可以通过插件把它集成到es（首选方式）,也可以安装成一个独立webapp。\n\n\tes-head主要有三个方面的操作：\n\n\t显示集群的拓扑,并且能够执行索引和节点级别操作\n\t搜索接口能够查询集群中原始json或表格格式的检索数据\n\t能够快速访问并显示集群的状态\n\t有一个输入窗口,允许任意调用RESTful API。这个接口包含几个选项,可以组合在一起以产生有趣的结果; \n\t请求方法(get、put、post、delete),查询json数据,节点和路径\n\t支持JSON验证器\n\t支持重复请求计时器\n\t支持使用javascript表达式变换结果\n\t收集结果的能力随着时间的推移(使用定时器),或比较的结果\n\t能力图表转换后的结果在一个简单的条形图(包括时间序列)","tags":["Elasticsearch-head"],"categories":["数据库"]},{"title":"Elasticsearch集群部署配置","url":"%2F2016%2F07%2F02%2FElasticsearch%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE%2F","content":"\n\t基于基本安装复制三份到各节点，修改配置文件如下：\n```bash\ncluster.name: lcc-application # 必须一样 \nnode.name: node-191-168-10-173 # 必须不一样\n\npath.data: /data/program/elasticsearch-6.2.0/data/\npath.logs: /data/program/elasticsearch-6.2.0/logs/\n\nbootstrap.memory_lock: false\nbootstrap.system_call_filter: false\n\nnetwork.host: 0.0.0.0 \nhttp.port: 9200\n#集群发现#集群节点ip或者主机\ndiscovery.zen.ping.unicast.hosts: [\"192.168.10.173\", \"192.168.10.174\",\"192.168.10.175\"] \n#这个参数决定了要选举一个Master需要多少个节点。默认为1，设置为N/2+1 \ndiscovery.zen.minimum_master_nodes: 2\n\n#下面两行配置为haad插件配置，三台服务器一致。 \nhttp.cors.enabled: true \nhttp.cors.allow-origin: \"*\"\n```","tags":["Elasticsearch"],"categories":["数据库"]},{"title":"Elasticsearch之基本操作","url":"%2F2016%2F07%2F02%2FElasticsearch%E4%B9%8B%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F","content":"\n#### 摘要：\t\n\t本文简单介绍了elasticsearch的HTTP API中的插入、删除、更新、查找、搜索功能。\n\telasticsearch是一个是开源的（Apache2协议），分布式的，RESTful的，构建在Apache Lucene之上的的搜索引擎。\n\t它有很多特点例如Schema Free，Document Oriented。它是#nosql的，基于JSON，同时支持多种API，包括HTTP, thrift, memcached。支持HTTP,是比较爽的一点，因为基本上所有的应用都可以用ES了，页面上的js脚本都可以去查询。\n\n#### 插入\n\n```bash\n#先来一个简单的官方例子，插入的参数为-XPUT，插入一条记录。\ncurl -XPUT 'http://localhost:9200/twitter/tweet/1' -d '{\n    \"user\" : \"kimchy\",\n    \"post_date\" : \"2009-11-15T14:12:12\",\n    \"message\" : \"trying out Elastic Search\"\n}'\n{\"ok\":true,\"_index\":\"twitter\",\"_type\":\"tweet\",\"_id\":\"1\",\"_version\":6}\n#从上面的这个例子中，可以看出ES的http的服务的默认端口9200，后面的/twitter/tweet/1是这条记录的索引部分。这也就体现了它的RESTful风格，所有的记录都是通过URI确定。这三级目录分布对应了_index，_type, _id（绿框内可以看出来）。实际上ES上存放的所有的记录都只能通过三级目录的方式找到，不能多也不能少。_id字段可以是数字也可以是字符串。在执行上面的命令时ES会自动创建这些索引。-d后面跟上了要插入的json格式的记录。-XPUT表明这是插入一条数据，ES中叫创建一个索引。ES返回的结果中，一个_version字段，表明了当前记录的版本号，当你想这个索引重新put一条记录时，版本号会自动加一\n```\n<!--more-->\n#### 删除\n\n```bash\n#删除的http请求参数为-XDELETE，通过下面的命令可以删除这条记录：\ncurl -XDELETE 'http://localhost:9200/twitter/tweet/1'\n#删除这条记录的时候，_verison也会自动加一的。\n```\n#### 查询\n\n```bash\n#创建了一个索引后，可以通过下面的方式查询（参数-XGET）出来\n#执行下面的查询命令，可以等到下面的结果：\ncurl -XGET 'http://localhost:9200/twitter/tweet/1'\n{\"_index\":\"twitter\",\"_type\":\"tweet\",\"_id\":\"1\",\"_version\":5,\"exists\":true, \"_source\" : {\n    \"user\" : \"kimchy\",\n    \"post_date\" : \"2009-11-15T14:12:12\",\n    \"message\" : \"trying out Elastic Search\"\n}}\n\n#exists表示是否有查询结果，_source字段是查询到的记录。\n#查询的时候，可以将_type设置成为_all，ES就会返回在_index下所有type中，第一个匹配_id的记录。\n#还可以通过参数对返回结果继续控制，例如：用fields选取返回的字段，用pretty控制返回的json格式是否更阅读友好。format=yaml可以设置输入格式为YAML。 下面是两个例子\n\ncurl -XGET 'http://localhost:9200/twitter/tweet/1?fields=message,user&pretty=true'\ncurl -XGET 'http://localhost:9200/twitter/tweet/1?fields=message,user&format=yaml'\n#当然ES还支持一次查询多组记录，即multi get，在URI中是使用关键字_mget，具体可以参考ES的文档multi get。\n```\n#### 更新\n\n```bash\n#ES同样支持更新，但是更新的方式是通过一个提供的脚本进行的。ES的做法是，通过index找到相应的存放记录的节点，然后执行脚本，执行完之后，返回新的索引。实际上执行的是一个get和reindex的过程，在这个过程中，通过versioning来控制没有其它的更新操作（这个功能是0.19后可用的）。具体实现的原理应该和elasticsearch Versioning相关。get，reindex的含义是，ES先取出这条记录，然后根据新数据生成新记录，然后在把新记录放回到ES中（并不会覆盖老的记录）。\n\n#首先创建一条记录\ncurl -XPUT localhost:9200/test/type1/1 -d '{\n    \"counter\" : 1,\n    \"tags\" : [\"red\"]\n}'\n#将counter的值加4\ncurl -XPOST 'localhost:9200/test/type1/1/_update' -d '{\n    \"script\" : \"ctx._source.counter += count\",\n    \"params\" : {\n        \"count\" : 4\n    }\n}'\n#也可以添加一个tag的值\ncurl -XPOST 'localhost:9200/test/type1/1/_update' -d '{\n    \"script\" : \"ctx._source.tags += tag\",\n    \"params\" : {\n        \"tag\" : \"blue\"\n    }\n}'\n#现在还支持upsert功能，即在更新的时候，如果记录没有这个key，则插入这个key，下面是一个例子，如果没有counter字段，则插入该字段：\ncurl -XPOST 'localhost:9200/test/type1/1/_update' -d '{\n    \"script\" : \"ctx._source.counter += count\",\n    \"params\" : {\n        \"count\" : 4\n    },\n    \"upsert\" : {\n        \"counter\" : 1\n    }\n}'\n\n```\n\n#### 搜索\n\n```bash\n#elasticsearch的名字里面有一个search，那么主要功能也是search了。\n#es的search有两种形式，一是通过URI，二是通过Requst Body。通过URI查询，即将查询的语句放入到请求的url中，例如：\ncurl -XGET 'http://localhost:9200/twitter/tweet/_search?q=user:kimchy'\n\n#第二种方式，即在查询的请求中加入一个doc\ncurl -XGET 'http://localhost:9200/twitter/tweet/_search' -d '{\n    \"query\" : {\n        \"term\" : { \"user\" : \"kimchy\" }\n    }\n}'\n#query body的定义可以查看query DSL 另外两种查询方式都可以带参数，参数的含义参考URI Request和Request Body。\n#ES的搜索功能是可以跨index和type的，例如下面这几条命令\ncurl -XGET 'http://localhost:9200/twitter/_search?q=user:kimchy'\ncurl -XGET 'http://localhost:9200/twitter/tweet,user/_search?q=user:kimchy'\ncurl -XGET 'http://localhost:9200/kimchy,elasticsearch/tweet/_search?q=tag:wow'\ncurl -XGET 'http://localhost:9200/_all/tweet/\\_search?q=tag:wow'\ncurl -XGET 'http://localhost:9200/\\_search?q=tag:wow'\n#第一条是在所有的twitter这个index下的所有type中查找，第二条是在tweet,user这两个type中查找，第三条是在kimchy,elasticsearch这两个index的tweet这个type中查找，第四条使用了_all关键字，是在所有的index的tweet的type中查找，第五条更暴力，在所有的index和type中查找。\n#查找还有其它的很多选项，sort，高亮，选取返回记录的域Fields，还可以对返回的域使用一个脚本进行计算script Fields，或者对返回结果继续统计Facets，Facets的内容比较多，它支持关键词统计，范围内统计，直方图式统计，日期的直方图式统计，过滤，查询，还有记录地理位置距离的统计geo distance。 支持名字过滤Named Filters。 定义搜索类型Search Type 。例如什么Query And Fetch，Query Then Fetch。 索引加速的功能Index Boost，可以让某一个索引的权重大于另外一个。 保持上次检索的环境了结果Scroll。保留每一个命中的score值Explain。 设置命中的min_score。保留版本号Version。\n#Search的参数很多，我也没有一一看，不过果然是名字里面有个search，对检索的各种场景都有支持\n#当然还支持多个查询multi search，例如下面这个例子\ncat requests\n{\"index\" : \"test\"}\n{\"query\" : {\"match_all\" : {}}, \"from\" : 0, \"size\" : 10}\n{\"index\" : \"test\", \"search_type\" : \"count\"}\n{\"query\" : {\"match_all\" : {}}}\n{}\n{\"query\" : {\"match_all\" : {}}}\ncurl -XGET localhost:9200/_msearch --data-binary @requests; echo\n\n```\n\n#### 小结\n\t下面是两篇不错的文章，大家也可以借鉴一下：\n\thttp://blog.csdn.net/laigood12345/article/details/7421173\n\thttp://www.qwolf.com/?p=1387\n\telasticsearch的中文站点：http://www.elasticsearch.cn/","tags":["Elasticsearch"],"categories":["数据库"]},{"title":"Elasticsearch实践指南","url":"%2F2016%2F07%2F02%2FElasticsearch%E5%AE%9E%E8%B7%B5%E6%8C%87%E5%8D%97%2F","content":"\n#### 简介\n\tElasticsearch是基于Lucene开发的一个准实时搜索服务，搜索延时在秒级。ES存储主要通过自身解析json数据，然后json里面的key映射为Lucene里面的字段，使用lucene进行搜索和索引。ES不仅支持普通的全文搜索和按词搜索，还支持模糊匹配，近义词搜索，聚合，排序，geo等特性。ES的开源特性也使得它社区活跃，版本迭代更新迅速，现在主要分为2.0和5.0两个大版本，建议大家使用最新的5.0版本会更容易升级和获取一些更高级的特性。\n\t下面是一些上线或者线上使用Elasticsearch需要了解的特性\n<!--more-->\n#### CPU\n\tes主要依赖于硬盘和内存，所以对CPU要求不高，一般8核就行，如果并发比较多可以适当增加。\n\n#### 硬盘\n\t硬盘决定你es写入读取数据速度，磁盘建议用15k的机械硬盘,并配置为raid0，如果集群节点<5个，请使用raid5，这样保证一个硬盘故障不会影响服务。虽然es本身可以通过分片去保证数据的冗余，但是es每个节点大量数据爬行还是对较小的集群有一定影响。（土豪直接上SSD，需要正确配置I/O调度程序，阵列卡建议>h710，否则就像ssd跑车上安装一个拖拉机引擎）\n\n#### 内存优化\n\t1  .ES的内存使用分为两部分ES缓存和Lucene通过内核缓存加速一些数据。\n\t2  . 如果服务器内存  `nG > 64G`,ES的内存尽量设置低于32G，建议最大31G. 因为es使用“内存指针压缩”技术，一旦内存内存大于32G这项技术将失效，内存有效使用只有原来的60%~70%。你不必为内存浪费而担心，因为lucene会通过系统把一些聚合和排序的数据缓存起来方便你快速查询使用。\n\t3 .如果服务器内存  `nG < 64G`，建议给ES分配  内存 (n-2)/2G.  首先2G是给系统预留，然后es和lucene\n\t4 . 如果你想继续你的实时查询，尽量不要使用swap(交换分区)，建议关闭系统swap使用\n\n#### 网络\n\t建议千兆光纤，高速网络可以保证集群节点故障后快速恢复，以及添加节点后快速再平衡。\n\t尽量不要跨机房，除非需要灾备，或者有足够的带宽，否则你将迎来es节点数据同步的无限等待。\n\n#### 数据文档结构数据\n\t因为所有es节点需要实时同步‘索引列表’，‘文档类型’，‘字段名’等信息，所以在节点数固定的情况下索引，字段名等不要太多否则会给es的master节点造成压力。\n\t简单举例：我要保存用户提交字段和信息，各个字段名因为是动态生成，理论上是无上限的，但是es的master要实时的同步这些字段信息到每个节点，如果现在只有100个字段还好，要是有1000个字段就会产生问题，如果有2000个字段就严重到无法使用了，当然索引的数量也是同样的意义，\n\n#### 索引优化\n\tes的每个索引默认总计10个分片，5个主分片，每个主分片对应一个副分片。\n\t1 .  当然很多情况下这个无法满足你实际需求，例如你的集群有8个节点，计划单个索引超过100亿条数据，为了让这个索引查询速度快一点，你可以增加索引分片数量：1.增加主副分片对数，增加副分片的数量。这样不仅加速搜索还增加了数据的冗余。\n\t2 . 一些只读的索引可以使用‘optimize的API’进行把每个索引合并为一个单独数据段，这样可以节省资源加速操作，但是需要注意这样会消耗一定IO，如果当前节点请求繁忙，不要进行此类操作。\n\t3 . 在使用索引的时候尽量使用索引别名，在以后索引重建或者索引名变更时避免宕机维护。\n\n#### 操作优化\n\t1 . 并发请求不要一次太多，否则超过es内部队列长度将失败。\n\t2 . 如果一次一定要提交太多任务写入尽量添加失败判断，一旦失败等待3~5秒重试操作，否则数据将丢失。\n\t3 .文档尽量一次写入不要更改和删除，因为es的更改和删除只是给旧数据做了一个标签，查询的时候依然会查询匹配，只是不在结果中计算。\n\n#### 故障处理\n\t如果有ES集群单节点掉出集群不要慌张ES有自愈的能力，你只需要保证集群稳定，磁盘充足即可自动修复。\n\t如果集群突然大多节点掉出集群，且出现分片丢失，那你需要考虑分片丢失是否能够接受，如果不能你可以通过同时停止全部节点，并启动全部节点进入时间门来尝试恢复全部数据。\n\t正常情况下少数节点掉出集群，导致一些只读的分片丢失，可以把这些掉出的节点重新加入回集群即可恢复分片。","tags":["Elasticsearch"],"categories":["数据库"]},{"title":"系统任务调度-Rundeck","url":"%2F2016%2F05%2F19%2F%E7%B3%BB%E7%BB%9F%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6-Rundeck%2F","content":"\n\n#### 简介\n\nRundeck 是你主机系统的服务器应用程序你指定一个中央行政控制中心。内部，Rundeck 将作业定义和执行历史记录存储在关系数据库中。输出从命令和工作处决保存在磁盘上，但可以转发到远程存储例如logstash。Rundeck 分布式执行使用默认为 SSH 但插件允许您使用其他手段如 MCollective、 Salt、 WinRM 或自定义的方法的可插拔的节点执行层的命令。Rundeck 服务器配置包括定义允许的远程主机的出站用户的设置。远程计算机不需要回发到服务器进行连接。\n<!--more-->\n#### 安装\n\n这里使用的是rundeck的jar包安装，读者也可以采用rpm包方式的安装，这里看个人喜好，版本为目前最新版本，下载地址 http://rundeck.org/downloads.html\n\n定义Rundeck的环境变量来进行下一步的安装\n```bash\n#vim /etc/profile 在末尾添加\nexport RDECK_BASE=/data/programs/rundeck_x.x.x\n#source /etc/profile\n#echo $RDECK_BASE\n/data/programs/rundeck_x.x.x\n\n#定义安装目录后创建之后才能安装\nmkdir -p $RDECK_BASE\n#复制下载的jar包到安装目录夹中\ncp rundeck-launcher-x.x.x.jar $RDECK_BASE\n\n#启动jar包\ncd $RDECK_BASE\njava -XX:MaxPermSize=256m -Xmx1024m -jar rundeck-launcher-x.x.x.jar\n\n#启动成功后，我们可以看到rundeck的目录下有以下目录：\netc  libext  projects  rundeck-launcher-2.6.3.jar  server  tools  var\n#启动和关闭\n#在初始化jar包之后，下一次启动和关闭可以进行如下操作：\n#Startup\n$RDECK_BASE/server/sbin/rundeckd start\n#Shutdown\n$RDECK_BASE/server/sbin/rundeckd stop\n```\n#### 基本概念\n\n```bash\nRole-based Access Control Policies︰ Rundeck 访问控制策略将授予用户和用户组某些权限执行权限限制访问rundeck 资源，如项目、 工作、 节点、 命令和 API。\nProjects ︰ 项目是分开管理活动的地方。所有的 Rundeck 活动发生在项目的上下文内。多个项目可以保持相同的 Rundeck 服务器上。\nJobs ︰ 作业封装步骤、 作业选项和节点在哪里执行步骤的序列。\nNodes ︰ 节点是一种资源，是网络访问主机物理或虚拟实例。资源模型是在项目中的节点表示。\nCommands ︰ 命令是在一个节点上执行单个可执行字符串。Rundeck 调用命令通过节点的遗嘱执行人并计算命令字符串来执行它的节点上。\nExecutions ︰ 执行是活动的表示某一正在运行或已完成的命令或工作。关于执行数据在 rundeck 用于监测进展的工作或命令和后来的报道发生了什么事。\nPlugins ︰ Rundeck 所做的大多数是通过其插件之一。插件的存在在节点上执行命令、 执行中的工作步骤、 发送关于作业状态的通知，收集有关您的网络中的主机的信息，将一个文件复制到远程的服务器、 存储和流日志，或谈到用户目录。\n```\n\n#### 添加node\n\n```bash\n#在创建完一个project之后，在rundeck的主目录下面，保存着它的一个配置，在node的配置文件中添加节点如下：\nvim /opt/programs/rundeck_2.6.3/projects/Rundeck_Test/etc/resources.xml \n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project>\n  <node name=\"bd-stg-test-97\" description=\"Rundeck server node\" tags=\"\" hostname=\"bd-stg-test-97\" osArch=\"amd64\" osFamily=\"unix\" osName=\"Linux\" osVersion=\"2.6.32-573.el6.x86_64\" username=\"apprun\"/>\n  <node name=\"bd-stg-test-98\" description=\"Rundeck client node1\" tags=\"\" hostname=\"172.16.57.98\" osArch=\"amd64\" osFamily=\"unix\" osName=\"Linux\" osVersion=\"2.6.32-573.el6.x86_64\" username=\"apprun\"/>\n  <node name=\"bd-stg-test-99\" description=\"Rundeck client node2\" tags=\"\" hostname=\"172.16.57.99\" osArch=\"amd64\" osFamily=\"unix\" osName=\"Linux\" osVersion=\"2.6.32-573.el6.x86_64\" username=\"apprun\"/>\n</project>\n\n#添加完成后，不需要重启服务，刷新后，可以看到node信息已经出现在web界面\n```","tags":["rundeck"],"categories":["linux"]},{"title":"Redis主从配置故障切换","url":"%2F2016%2F05%2F16%2FRedis%E4%B8%BB%E4%BB%8E%E9%85%8D%E7%BD%AE%E6%95%85%E9%9A%9C%E5%88%87%E6%8D%A2%2F","content":"\n#### 节点准备\n\n|主机名|IP|角色|\n| ------------ | ------------ | ------------ |\n|master|172.17.0.1|主|\n|slave01|172.16.0.2|从|\n|slave02|172.16.0.3|从|\n|arbiter01|172.16.0.4|仲裁|\n|arbiter02|172.16.0.5|仲裁|\n|arbiter03|172.16.0.6|仲裁|\n\n#### 安装redis实例，所有节点\n\t略...\n<!--more-->\n#### 配置实例，所有节点\n\n```bash\n#主节点  配置如下：\nport 6379\nlogfile \"/data/program/redis/logs/6379.log\"\ndir \"/data/program/redis/data/6379\"\ndbfilename \"dump.rdb\"\nappendonly yes\nappendfilename \"appendonly.aof\"\nrequirepass \"123456\"\n\nmasterauth \"123455\"\n```\n```bash\n#从节点配置 \nport 6379\nlogfile \"/data/program/redis/logs/6379.log\"\ndir \"/data/program/redis/data/6379\"\ndbfilename \"dump.rdb\"\nappendonly yes\nappendfilename \"appendonly.aof\"\nrequirepass \"123456\"\nmasterauth \"123456\"\n#\nslaveof 172.16.10.4 6379\n```\n```bash\n#仲裁节点配置\nport 26379\n#MyMaster\nsentinel monitor MyMaster 172.16.0.1 6379 1\nsentinel down-after-milliseconds MyMaster 5000\nsentinel failover-timeout MyMaster 900000\nsentinel auth-pass mymaster 123456\nsentinel parallel-syncs MyMaster 2\n```\n#### 启动所有节点\n\n```bash\n#主从节点\nredis-server /data/program/redis/conf/redis.conf\n#仲裁节点\nredis-sentinel /data/program/redis/conf/sentinel.conf\n\n```\n#### 检查主从状态\n\n```bash\nredis-cli\n#查询状态信息\n> ping\n#返回的结果如果是PONG，则表示服务运行正常\n#然后继续执行命令，检查主备是否正常\n> info Replication\n#查看返回结果（关键点）\n#master应为（offset和lag无所谓）：\nrole:master\nconnected_slaves:2\nslave0:ip=172.16.0.2,port=6379,state=online,offset=1241704,lag=0\nslave1:ip=172.16.0.3,port=6379,state=online,offset=1241704,lag=0\n\n#slave应为：\nrole:slave\nmaster_host:172.16.0.4\nmaster_port:6379\nmaster_link_status:up\n```\n#### 检查sentinel状态\n\n```bash\nredis-cli -p 26379\n#查询状态信息\n> info\n#查看结果如果有如下所示，即表示正常集群配置正常运行\n# Sentinel\nsentinel_masters:1\nsentinel_tilt:0\nsentinel_running_scripts:0\nsentinel_scripts_queue_length:0\nmaster0:name=MyMaster,status=ok,address=172.16.0.1:6379,slaves=2,sentinels=3\n\n\n```","tags":["主从切换"],"categories":["数据库"]},{"title":"Redis哨兵sentinel配置文件详解","url":"%2F2016%2F05%2F16%2FRedis%E5%93%A8%E5%85%B5sentinel%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3%2F","content":"\n#### Sentinel的工作方式\n\t每个Sentinel以每秒钟一次的频率向它所知的Master，Slave以及其他 Sentinel 实例发送一个 PING 命令 \n\t如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel 标记为主观下线。 \n\t如果一个Master被标记为主观下线，则正在监视这个Master的所有 Sentinel 要以每秒一次的频率确认Master的确进入了主观下线状态。 \n\t当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认Master的确进入了主观下线状态， 则Master会被标记为客观下线 \n\t在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率向它已知的所有Master，Slave发送 INFO 命令 \n\t当Master被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次 \n\t若没有足够数量的 Sentinel 同意 Master 已经下线， Master 的客观下线状态就会被移除。 \n\t若 Master 重新向 Sentinel 的 PING 命令返回有效回复， Master 的主观下线状态就会被移除。\n<!--more-->\n#### Sentinel命令\n\n```bash\n#PING ：返回 PONG 。\n#SENTINEL masters ：列出所有被监视的主服务器，以及这些主服务器的当前状态；\n#SENTINEL slaves <master name> ：列出给定主服务器的所有从服务器，以及这些从服务器的当前状态；\n#SENTINEL get-master-addr-by-name <master name> ： 返回给定名字的主服务器的 IP 地址和端口号。 如果这个主服务器正在执行故障转移操作， 或者针对这个主服务器的故障转移操作已经完成， 那么这个                     命令返回新的主服务器的 IP 地址和端口号；\n#SENTINEL reset <pattern> ： 重置所有名字和给定模式 pattern 相匹配的主服务器。 pattern 参数是一个 Glob 风格的模式。 重置操作清楚主服务器目前的所有状态， 包括正在执行中的故障转移， 并移除目前已经发现和关联的， 主服务器的所有从服务器和 Sentinel ；\n#SENTINEL failover <master name> ： 当主服务器失效时， 在不询问其他 Sentinel 意见的情况下， 强制开始一次自动故障迁移。\n\n#客户端可以通过SENTINEL get-master-addr-by-name <master name>获取当前的主服务器IP地址和端口号，以及SENTINEL slaves <master name>获取所有的Slaves信息\n```\n#### 配置文件\n\n```bash\nport 26379\n#Sentinel 去监视一个名为 mymaster 的主服务器， 这个主服务器的 IP 地址为 127.0.0.1 ， 端口号为 6379 ， 而将这个主服务器判断为失效至少需要 2 个 Sentinel 同意 （只要同意 Sentinel 的数量不达标，自动故障迁移就不会执行）。不过需要注意的是，无论你设置要多少个 Sentinel 同意才能判断一个服务器失效，一个 Sentinel 都需要获得系统中多数（majority） Sentinel 的支持，才能发起一次自动故障迁移，也就是说，如果只有少数（minority）Sentinel 进程正常运作的情况下，是不能执行自动故障迁移的。\nsentinel monitor MyMaster 172.16.0.1 6379 1\n#down-after-milliseconds 选项指定了 Sentinel 认为服务器已经断线所需的毫秒数（判定为主观下线SDOWN）\nsentinel down-after-milliseconds MyMaster 5000\n#failover-timeout如果在该时间（ms）内未能完成failover操作，则认为该failover失败\nsentinel failover-timeout MyMaster 900000\n#设置连接master和slave时的密码，注意的是sentinel不能分别为master和slave设置不同的密码，因此master和slave的密码应该设置相同。\nsentinel auth-pass mymaster 123456\n#parallel-syncs 选项指定了在执行故障转移时， 最多可以有多少个从服务器同时对新的主服务器进行同步， 这个数字越小， 完成故障转移所需的时间就越长，但越大就意味着越多的从服务器因为复制而不可用。可以通过将这个值设为 1 来保证每次只有一个从服务器处于不能处理命令请求的状态\nsentinel parallel-syncs MyMaster 2\n#当sentinel有任何警告级别的事件发生时（比如说redis实例的主观失效和客观失效等等），将会去调用这个脚本，这时这个脚本应该通过邮件，SMS等方式去通知系统管理员关于系统不正常运行的信息。调用该脚本时，将传给脚本两个参数，一个是事件的类型，一个是事件的描述。如果sentinel.conf配置文件中配置了这个脚本路径，那么必须保证这个脚本存在于这个路径，并且是可执行的，否则sentinel无法正常启动成功\nsentinel notification-script MyMaster <script-path>\n#当一个master由于failover而发生改变时，这个脚本将会被调用，通知相关的客户端关于master地址已经发生改变的信息。以下参数将会在调用脚本时传给脚本\nsentinel client-reconfig-script MyMaster <script-path>\n```","tags":["sentinel"],"categories":["数据库"]},{"title":"Redis配置文件详解","url":"%2F2016%2F05%2F16%2FRedis%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3%2F","content":"\t以下是配置文件内容，请阅读全文。\n<!--more-->\n```bash\n#redis.conf\n#Redis configuration file example.\n#./redis-server /path/to/redis.conf\n\n################################## INCLUDES ###################################\n#这在你有标准配置模板但是每个redis服务器又需要个性设置的时候很有用。\n#include /path/to/local.conf\n#include /path/to/other.conf\n\n################################ GENERAL #####################################\n\n#是否在后台执行，yes：后台运行；no：不是后台运行（老版本默认）\ndaemonize yes\n\n#3.2里的参数，是否开启保护模式，默认开启。要是配置里没有指定bind和密码。开启该参数后，redis只会本地进行访问，拒绝外部访问。要是开启了密码   和bind，可以开启。否   则最好关闭，设置为no。\nprotected-mode yes\n#redis的进程文件\npidfile /var/run/redis/redis-server.pid\n\n#redis监听的端口号。\nport 6379\n\n#此参数确定了TCP连接中已完成队列(完成三次握手之后)的长度， 当然此值必须不大于Linux系统定义的/proc/sys/net/core/somaxconn值，默认是511，而Linux的默认参数值是128。当系统并发量大并且客户端速度缓慢的时候，可以将这二个参数一起参考设定。该内核参数默认值一般是128，对于负载很大的服务程序来说大大的不够。一般会将它修改为2048或者更大。在/etc/sysctl.conf中添加:net.core.somaxconn = 2048，然后在终端中执行sysctl -p。\ntcp-backlog 511\n\n#指定 redis 只接收来自于该 IP 地址的请求，如果不进行设置，那么将处理所有请求\nbind 127.0.0.1\n\n#配置unix socket来让redis支持监听本地连接。\n#unixsocket /var/run/redis/redis.sock\n#配置unix socket使用文件的权限\n#unixsocketperm 700\n\n# 此参数为设置客户端空闲超过timeout，服务端会断开连接，为0则服务端不会主动断开连接，不能小于0。\ntimeout 0\n\n#tcp keepalive参数。如果设置不为0，就使用配置tcp的SO_KEEPALIVE值，使用keepalive有两个好处:检测挂掉的对端。降低中间设备出问题而导致网络看似连接却已经与对端端口的问题。在Linux内核中，设置了keepalive，redis会定时给对端发送ack。检测到对端关闭需要两倍的设置值。\ntcp-keepalive 0\n\n#指定了服务端日志的级别。级别包括：debug（很多信息，方便开发、测试），verbose（许多有用的信息，但是没有debug级别信息多），notice（适当的日志级别，适合生产环境），warn（只有非常重要的信息）\nloglevel notice\n\n#指定了记录日志的文件。空字符串的话，日志会打印到标准输出设备。后台运行的redis标准输出是/dev/null。\nlogfile /var/log/redis/redis-server.log\n\n#是否打开记录syslog功能\n# syslog-enabled no\n\n#syslog的标识符。\n# syslog-ident redis\n\n#日志的来源、设备\n# syslog-facility local0\n\n#数据库的数量，默认使用的数据库是DB 0。可以通过”SELECT “命令选择一个db\ndatabases 16\n\n################################ SNAPSHOTTING ################################\n# 快照配置\n# 注释掉“save”这一行配置项就可以让保存数据库功能失效\n# 设置sedis进行数据库镜像的频率。\n# 900秒（15分钟）内至少1个key值改变（则进行数据库保存--持久化） \n# 300秒（5分钟）内至少10个key值改变（则进行数据库保存--持久化） \n# 60秒（1分钟）内至少10000个key值改变（则进行数据库保存--持久化）\nsave 900 1\nsave 300 10\nsave 60 10000\n\n#当RDB持久化出现错误后，是否依然进行继续进行工作，yes：不能进行工作，no：可以继续进行工作，可以通过info中的rdb_last_bgsave_status了解RDB持久化是否有错误\nstop-writes-on-bgsave-error yes\n\n#使用压缩rdb文件，rdb文件压缩使用LZF压缩算法，yes：压缩，但是需要一些cpu的消耗。no：不压缩，需要更多的磁盘空间\nrdbcompression yes\n\n#是否校验rdb文件。从rdb格式的第五个版本开始，在rdb文件的末尾会带上CRC64的校验和。这跟有利于文件的容错性，但是在保存rdb文件的时候，会有大概10%的性能损耗，所以如果你追求高性能，可以关闭该配置。\nrdbchecksum yes\n\n#rdb文件的名称\ndbfilename dump.rdb\n\n#数据目录，数据库的写入会在这个目录。rdb、aof文件也会写在这个目录\ndir /var/lib/redis\n\n################################# REPLICATION #################################\n#复制选项，slave复制对应的master。\n# slaveof <masterip> <masterport>\n\n#如果master设置了requirepass，那么slave要连上master，需要有master的密码才行。masterauth就是用来配置master的密码，这样可以在连上master后进行认证。\n# masterauth <master-password>\n\n#当从库同主机失去连接或者复制正在进行，从机库有两种运行方式：1) 如果slave-serve-stale-data设置为yes(默认设置)，从库会继续响应客户端的请求。2) 如果slave-serve-stale-data设置为no，除去INFO和SLAVOF命令之外的任何请求都会返回一个错误”SYNC with master in progress”。\nslave-serve-stale-data yes\n\n#作为从服务器，默认情况下是只读的（yes），可以修改成NO，用于写（不建议）。\nslave-read-only yes\n\n#是否使用socket方式复制数据。目前redis复制提供两种方式，disk和socket。如果新的slave连上来或者重连的slave无法部分同步，就会执行全量同步，master会生成rdb文件。有2种方式：disk方式是master创建一个新的进程把rdb文件保存到磁盘，再把磁盘上的rdb文件传递给slave。socket是master创建一个新的进程，直接把rdb文件以socket的方式发给slave。disk方式的时候，当一个rdb保存的过程中，多个slave都能共享这个rdb文件。socket的方式就的一个个slave顺序复制。在磁盘速度缓慢，网速快的情况下推荐用socket方式。\nrepl-diskless-sync no\n\n#diskless复制的延迟时间，防止设置为0。一旦复制开始，节点不会再接收新slave的复制请求直到下一个rdb传输。所以最好等待一段时间，等更多的slave连上来。\nrepl-diskless-sync-delay 5\n\n#slave根据指定的时间间隔向服务器发送ping请求。时间间隔可以通过 repl_ping_slave_period 来设置，默认10秒。\n# repl-ping-slave-period 10\n\n#复制连接超时时间。master和slave都有超时时间的设置。master检测到slave上次发送的时间超过repl-timeout，即认为slave离线，清除该slave信息。slave检测到上次和master交互的时间超过repl-timeout，则认为master离线。需要注意的是repl-timeout需要设置一个比repl-ping-slave-period更大的值，不然会经常检测到超时。\n# repl-timeout 60\n\n#是否禁止复制tcp链接的tcp nodelay参数，可传递yes或者no。默认是no，即使用tcp nodelay。如果master设置了yes来禁止tcp nodelay设置，在把数据复制给slave的时候，会减少包的数量和更小的网络带宽。但是这也可能带来数据的延迟。默认我们推荐更小的延迟，但是在数据量传输很大的场景下，建议选择yes。\nrepl-disable-tcp-nodelay no\n\n#复制缓冲区大小，这是一个环形复制缓冲区，用来保存最新复制的命令。这样在slave离线的时候，不需要完全复制master的数据，如果可以执行部分同步，只需要把缓冲区的部分数据复制给slave，就能恢复正常复制状态。缓冲区的大小越大，slave离线的时间可以更长，复制缓冲区只有在有slave连接的时候才分配内存。没有slave的一段时间，内存会被释放出来，默认1m。\n# repl-backlog-size 5mb\n\n#master没有slave一段时间会释放复制缓冲区的内存，repl-backlog-ttl用来设置该时间长度。单位为秒。\n# repl-backlog-ttl 3600\n\n#当master不可用，Sentinel会根据slave的优先级选举一个master。最低的优先级的slave，当选master。而配置成0，永远不会被选举。\nslave-priority 100\n\n#redis提供了可以让master停止写入的方式，如果配置了min-slaves-to-write，健康的slave的个数小于N，mater就禁止写入。master最少得有多少个健康的slave存活才能执行写命令。这个配置虽然不能保证N个slave都一定能接收到master的写操作，但是能避免没有足够健康的slave的时候，master不能写入来避免数据丢失。设置为0是关闭该功能。\n# min-slaves-to-write 3\n\n#延迟小于min-slaves-max-lag秒的slave才认为是健康的slave。\n# min-slaves-max-lag 10\n\n# 设置1或另一个设置为0禁用这个特性。\n# Setting one or the other to 0 disables the feature.\n# By default min-slaves-to-write is set to 0 (feature disabled) and\n# min-slaves-max-lag is set to 10.\n\n################################## SECURITY ###################################\n#requirepass配置可以让用户使用AUTH命令来认证密码，才能使用其他命令。这让redis可以使用在不受信任的网络中。为了保持向后的兼容性，可以注释该命令，因为大部分用户也不需要认证。使用requirepass的时候需要注意，因为redis太快了，每秒可以认证15w次密码，简单的密码很容易被攻破，所以最好使用一个更复杂的密码。\n# requirepass foobared\n\n#把危险的命令给修改成其他名称。比如CONFIG命令可以重命名为一个很难被猜到的命令，这样用户不能使用，而内部工具还能接着使用。\n# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52\n\n#设置成一个空的值，可以禁止一个命令\n# rename-command CONFIG \"\"\n################################### LIMITS ####################################\n\n# 设置能连上redis的最大客户端连接数量。默认是10000个客户端连接。由于redis不区分连接是客户端连接还是内部打开文件或者和slave连接等，所以maxclients最小建议设置到32。如果超过了maxclients，redis会给新的连接发送’max number of clients reached’，并关闭连接。\n# maxclients 10000\n\n#redis配置的最大内存容量。当内存满了，需要配合maxmemory-policy策略进行处理。注意slave的输出缓冲区是不计算在maxmemory内的。所以为了防止主机内存使用完，建议设置的maxmemory需要更小一些。\n# maxmemory <bytes>\n\n#内存容量超过maxmemory后的处理策略。\n#volatile-lru：利用LRU算法移除设置过过期时间的key。\n#volatile-random：随机移除设置过过期时间的key。\n#volatile-ttl：移除即将过期的key，根据最近过期时间来删除（辅以TTL）\n#allkeys-lru：利用LRU算法移除任何key。\n#allkeys-random：随机移除任何key。\n#noeviction：不移除任何key，只是返回一个写错误。\n#上面的这些驱逐策略，如果redis没有合适的key驱逐，对于写命令，还是会返回错误。redis将不再接收写请求，只接收get请求。写命令包括：set setnx setex append incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby getset mset msetnx exec sort。\n# maxmemory-policy noeviction\n\n#lru检测的样本数。使用lru或者ttl淘汰算法，从需要淘汰的列表中随机选择sample个key，选出闲置时间最长的key移除。\n# maxmemory-samples 5\n\n############################## APPEND ONLY MODE ###############################\n#默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了。但是redis如果中途宕机，会导致可能有几分钟的数据丢失，根据save来策略进行持久化，Append Only File是另一种持久化方式，可以提供更好的持久化特性。Redis会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。\nappendonly no\n\n#aof文件名\nappendfilename \"appendonly.aof\"\n\n#aof持久化策略的配置\n#no表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快。\n#always表示每次写入都执行fsync，以保证数据同步到磁盘。\n#everysec表示每秒执行一次fsync，可能会导致丢失这1s数据。\nappendfsync everysec\n\n# 在aof重写或者写入rdb文件的时候，会执行大量IO，此时对于everysec和always的aof模式来说，执行fsync会造成阻塞过长时间，no-appendfsync-on-rewrite字段设置为默认设置为no。如果对延迟要求很高的应用，这个字段可以设置为yes，否则还是设置为no，这样对持久化特性来说这是更安全的选择。设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，默认为no，建议yes。Linux的默认fsync策略是30秒。可能丢失30秒数据。\nno-appendfsync-on-rewrite no\n\n#aof自动重写配置。当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，即当aof文件增长到一定大小的时候Redis能够调用bgrewriteaof对日志文件进行重写。当前AOF文件大小是上次日志重写得到AOF文件大小的二倍（设置为100）时，自动启动新的日志重写过程。\nauto-aof-rewrite-percentage 100\n#设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写\nauto-aof-rewrite-min-size 64mb\n\n#aof文件可能在尾部是不完整的，当redis启动的时候，aof文件的数据被载入内存。重启可能发生在redis所在的主机操作系统宕机后，尤其在ext4文件系统没有加上data=ordered选项（redis宕机或者异常终止不会造成尾部不完整现象。）出现这种现象，可以选择让redis退出，或者导入尽可能多的数据。如果选择的是yes，当截断的aof文件被导入的时候，会自动发布一个log给客户端然后load。如果是no，用户必须手动redis-check-aof修复AOF文件才可以。\naof-load-truncated yes\n\n################################ LUA SCRIPTING ###############################\n# 如果达到最大时间限制（毫秒），redis会记个log，然后返回error。当一个脚本超过了最大时限。只有SCRIPT KILL和SHUTDOWN NOSAVE可以用。第一个可以杀没有调write命令的东西。要是已经调用了write，只能用第二个命令杀。\nlua-time-limit 5000\n\n################################ REDIS CLUSTER ###############################\n#集群开关，默认是不开启集群模式。\n# cluster-enabled yes\n\n#集群配置文件的名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息。这个文件并不需要手动配置，这个配置文件有Redis生成并更新，每个Redis集群节点需要一个单独的配置文件，请确保与实例运行的系统中配置文件名称不冲突\n# cluster-config-file nodes-6379.conf\n\n#节点互连超时的阀值。集群节点超时毫秒数\n# cluster-node-timeout 15000\n\n#在进行故障转移的时候，全部slave都会请求申请为master，但是有些slave可能与master断开连接一段时间了，导致数据过于陈旧，这样的slave不应该被提升为master。该参数就是用来判断slave节点与master断线的时间是否过长。判断方法是：\n#比较slave断开连接的时间和(node-timeout * slave-validity-factor) + repl-ping-slave-period\n#如果节点超时时间为三十秒, 并且slave-validity-factor为10,假设默认的repl-ping-slave-period是10秒，即如果超过310秒slave将不会尝试进行故障转移 \n# cluster-slave-validity-factor 10\n\n#master的slave数量大于该值，slave才能迁移到其他孤立master上，如这个参数若被设为2，那么只有当一个主节点拥有2 个可工作的从节点时，它的一个从节点会尝试迁移。\n# cluster-migration-barrier 1\n\n#默认情况下，集群全部的slot有节点负责，集群状态才为ok，才能提供服务。设置为no，可以在slot没有全部分配的时候提供服务。不建议打开该配置，这样会造成分区的时候，小分区的master一直在接受写请求，而造成很长时间数据不一致。\n# cluster-require-full-coverage yes\n\n################################## SLOW LOG ###################################\n###slog log是用来记录redis运行中执行比较慢的命令耗时。当命令的执行超过了指定时间，就记录在slow log中，slog log保存在内存中，所以没有IO操作。\n#执行时间比slowlog-log-slower-than大的请求记录到slowlog里面，单位是微秒，所以1000000就是1秒。注意，负数时间会禁用慢查询日志，而0则会强制记录所有命令。\nslowlog-log-slower-than 10000\n\n#慢查询日志长度。当一个新的命令被写进日志的时候，最老的那个记录会被删掉。这个长度没有限制。只要有足够的内存就行。你可以通过 SLOWLOG RESET 来释放内存。\nslowlog-max-len 128\n\n################################ LATENCY MONITOR ##############################\n#延迟监控功能是用来监控redis中执行比较缓慢的一些操作，用LATENCY打印redis实例在跑命令时的耗时图表。只记录大于等于下边设置的值的操作。0的话，就是关闭监视。默认延迟监控功能是关闭的，如果你需要打开，也可以通过CONFIG SET命令动态设置。\nlatency-monitor-threshold 0\n\n############################# EVENT NOTIFICATION ##############################\n#键空间通知使得客户端可以通过订阅频道或模式，来接收那些以某种方式改动了 Redis 数据集的事件。因为开启键空间通知功能需要消耗一些 CPU ，所以在默认配置下，该功能处于关闭状态。\n#notify-keyspace-events 的参数可以是以下字符的任意组合，它指定了服务器该发送哪些类型的通知：\n##K 键空间通知，所有通知以 __keyspace@__ 为前缀\n##E 键事件通知，所有通知以 __keyevent@__ 为前缀\n##g DEL 、 EXPIRE 、 RENAME 等类型无关的通用命令的通知\n##$ 字符串命令的通知\n##l 列表命令的通知\n##s 集合命令的通知\n##h 哈希命令的通知\n##z 有序集合命令的通知\n##x 过期事件：每当有过期键被删除时发送\n##e 驱逐(evict)事件：每当有键因为 maxmemory 政策而被删除时发送\n##A 参数 g$lshzxe 的别名\n#输入的参数中至少要有一个 K 或者 E，否则的话，不管其余的参数是什么，都不会有任何 通知被分发。详细使用可以参考http://redis.io/topics/notifications\n\nnotify-keyspace-events \"\"\n\n############################### ADVANCED CONFIG ###############################\n#数据量小于等于hash-max-ziplist-entries的用ziplist，大于hash-max-ziplist-entries用hash\nhash-max-ziplist-entries 512\n#value大小小于等于hash-max-ziplist-value的用ziplist，大于hash-max-ziplist-value用hash。\nhash-max-ziplist-value 64\n\n#数据量小于等于list-max-ziplist-entries用ziplist，大于list-max-ziplist-entries用list。\nlist-max-ziplist-entries 512\n#value大小小于等于list-max-ziplist-value的用ziplist，大于list-max-ziplist-value用list。\nlist-max-ziplist-value 64\n\n#数据量小于等于set-max-intset-entries用iniset，大于set-max-intset-entries用set。\nset-max-intset-entries 512\n\n#数据量小于等于zset-max-ziplist-entries用ziplist，大于zset-max-ziplist-entries用zset。\nzset-max-ziplist-entries 128\n#value大小小于等于zset-max-ziplist-value用ziplist，大于zset-max-ziplist-value用zset。\nzset-max-ziplist-value 64\n\n#value大小小于等于hll-sparse-max-bytes使用稀疏数据结构（sparse），大于hll-sparse-max-bytes使用稠密的数据结构（dense）。一个比16000大的value是几乎没用的，建议的value大概为3000。如果对CPU要求不高，对空间要求较高的，建议设置到10000左右。\nhll-sparse-max-bytes 3000\n\n#Redis将在每100毫秒时使用1毫秒的CPU时间来对redis的hash表进行重新hash，可以降低内存的使用。当你的使用场景中，有非常严格的实时性需要，不能够接受Redis时不时的对请求有2毫秒的延迟的话，把这项配置为no。如果没有这么严格的实时性要求，可以设置为yes，以便能够尽可能快的释放内存。\nactiverehashing yes\n\n##对客户端输出缓冲进行限制可以强迫那些不从服务器读取数据的客户端断开连接，用来强制关闭传输缓慢的客户端。\n#对于normal client，第一个0表示取消hard limit，第二个0和第三个0表示取消soft limit，normal client默认取消限制，因为如果没有寻问，他们是不会接收数据的。\nclient-output-buffer-limit normal 0 0 0\n#对于slave client和MONITER client，如果client-output-buffer一旦超过256mb，又或者超过64mb持续60秒，那么服务器就会立即断开客户端连接。\nclient-output-buffer-limit slave 256mb 64mb 60\n#对于pubsub client，如果client-output-buffer一旦超过32mb，又或者超过8mb持续60秒，那么服务器就会立即断开客户端连接。\nclient-output-buffer-limit pubsub 32mb 8mb 60\n\n#redis执行任务的频率为1s除以hz。\nhz 10\n\n#在aof重写的时候，如果打开了aof-rewrite-incremental-fsync开关，系统会每32MB执行一次fsync。这对于把文件写入磁盘是有帮助的，可以避免过大的延迟峰值。\naof-rewrite-incremental-fsync yes\n```","tags":["编译安装"],"categories":["数据库"]},{"title":"Redis集群模式(codis)","url":"%2F2016%2F05%2F16%2FRedis%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F(codis)%2F","content":"\n#### 总体架构\n![](http://www.machunpeng.cn/server/../Public/Uploads/2018-04-14/5ad1ab9e988ff.png)\n<!--more-->\n#### Codis 3.x 由以下组件组成\n\t1.Codis Server：基于 redis-3.2.8 分支开发。增加了额外的数据结构，以支持 slot 有关的操作以及数据迁移指令。具体的修改可以参考文档 redis 的修改。\n\t2.Codis Proxy：客户端连接的 Redis 代理服务, 实现了 Redis 协议。 除部分命令不支持以外(不支持的命令列表)，表现的和原生的 Redis 没有区别（就像 Twemproxy）。 对于同一个业务集群而言，可以同时部署多个 codis-proxy 实例；不同 codis-proxy 之间由 codis-dashboard 保证状态同步。\n\t3.Redis sentinel：Redis官方推荐的高可用性(HA)解决方案。它可以实现对Redis的监控、通知、自动故障转移。如果Master不能工作，则会自动启动故障转移进程，将其中的一个Slave提升为Master，其他的Slave重新设置新的Master服务。\n\t4.Codis Dashboard：集群管理工具，支持 codis-proxy、codis-server 的添加、删除，以及据迁移等操作。在集群状态发生改变时，codis-dashboard 维护集群下所有 codis-proxy 的状态的一致性。 对于同一个业务集群而言，同一个时刻 codis-dashboard 只能有 0个或者1个；所有对集群的修改都必须通过 codis-dashboard 完成。\n\t5.Codis Admin：集群管理的命令行工具。 可用于控制 codis-proxy、codis-dashboard 状态以及访问外部存储。\n\t6.Codis FE：集群管理界面。 多个集群实例共享可以共享同一个前端展示页面； 通过配置文件管理后端codis-dashboard列表，配置文件可自动更新。\n\t7.Storage：为集群状态提供外部存储。 提供namespace概念，不同集群的会按照不同product name进行组织； 目前仅提供了zookeeper、etcd、filesystem三种实现，但是提供了抽象的 interface 可自行扩展。\n\n#### 部署规划\n|序号|IP|主机名|部署程序|\n|-------------| ------------ | ------------ |----------- |\n|1|192.168.1.11|WebServer-11|codis-server:(6379&6380)|\n|2|192.168.1.12|WebServer-12|codis-server:(6379&6380)|\n|3|192.168.1.13|WebServer-13|codis-server:(6379&6380)|\n|4|192.168.1.14|WebServer-14|codis-server:(6379&6380)|\n|5|192.168.1.15|WebServer-15|codis-server:(6379&6380)|\n|6|192.168.1.21|WebServer-21|codis-proxy:19000|\n|7|192.168.1.22|\tWebServer-22|codis-proxy:19000|\n|8|192.168.1.31|WebServer-31|codis-dashborad:18080、codis-fe:18090|\n|9|192.168.1.41|WebServer-41|redis-sentinel:26379|\n|10|192.168.1.42|WebServer-42|redis-sentinel:26379|\n|11|192.168.1.43|WebServer-43|redis-sentinel:26379|\n|12|192.168.1.51|WebServer-51|zookeeper:2181|\n|13|192.168.1.52|WebServer-52|zookeeper:2181|\n|14|192.168.1.53|WebServer-53|zookeeper:2181|\n\n#### 源码安装ZK，并配置[主机12-14]\n\t用于存放数据路由表。ßzookeeper简称zk。在生产环境中，zk部署越多，其可靠性越高。由于zk集群是以宕机个数过半才会让整个集群宕机，因此，奇数个zk更佳。如下：zoo.cfg\n```bash\nmaxClientCnxns=50 #最大连接数设置. 注：可不配置. \ntickTime=2000 #一个周期(tick)的时长(单位：毫秒). 注：可用默认值 \ninitLimit=10 #初始化同步阶段最多耗费tick个数. 注：可用默认值 \nsyncLimit=5 #等待应答的最大间隔tick个数. 注：可用默认值 \ndataDir=/data/zookeeper/ #数据存储目录. 注：勿放在/tmp目录 \nclientPort=2181 #帧听端口. 注：可用默认值 \nserver.1=zookeeper-node1:2888:3888 \nserver.2=zookeeper-node2:2888:3888 \nserver.3=zookeeper-node3:2888:3888\n```\n```bash\n#创建zk数据目录(datadir) \nmkdir -p /data/program/zookeeper/data\n#生成ID，这里需要注意， myid对应的zoo.cfg的server.ID.比如zookeeper-node2对应的myid应该是2.\necho “1” > /data/program/zookeeper/data/myid\n #服务启动\n./bin/Server.sh start\n```\n#### 安装JDK环境\n\t略...\n#### 添加域名（hosts）\n\t略...\n#### 编译Codis-配置环境[主机1-11]\n```bash\n#安装go环境，先从官网(https://golang.org/dl/)下载golang安装包，并将其解压，再拷贝至/usr/local/go/中，最后配置如下环境变量\n#vim $HOME/.bashrc\nexport GOROOT=/usr/local/go # 安装路径 \nexport GOPATH=$HOME/godir # 工作路径 \nexport PATH=$PATH:$GOPATH/bin:$GOROOT/bin # 命令搜索路径\n```\n\n#### 编译Codis-下载codis源码\n\n```bash\ngo get github.com/CodisLabs/codis.git -b release3.2\n```\n#### 编译Codis\n\n```bash\n# 切换源码目录\ncd $GOPATH/src/github.com/CodisLabs/\n # 执行编译\nmake\n# 查看结果\nls ./bin/\ncodis-admin codis-dashboard codis-fe codis-ha codis-proxy codis-server redis-benchmark redis-cli\n#完成编译后，将会在bin目录中看到codis-admin、codis-dashboard、codis-fe、codis-ha、codis-proxy、codis-server六个可执行文件。另外，bin/assert文件夹是codis-dashboard的http服务需要的前端资源，其需要和codis-dashboard放置在同一个文件夹中。 \n#补充：在目录./extern/redis-3.2.8/src/中可以找到redis-sentinel可执行文件，其将会用于集群主从的切换。\n\n#拷贝codis程序\nmkdir -p /usr/local/codis/bin\ncp -fr $GOPATH/github.com/CodisLabs/codis/bin/* /usr/local/codis/bin/ \ncp -fr $GOPATH/github.com/CodisLabs/codis/conf/* /usr/local/codis/conf/\n```\n#### 配置Codis-server 主[1-5]\n\n```bash\ncd /usr/local/codis/conf/\n# 主配置\ncp redis.conf redis-6379.conf \n# 修改配置\nvim redis-6379.conf \n\ndaemonize yes \n# 进程ID文件路径 \npidfile /usr/loca/codis/proc/redis-6379.pid \n# 绑定端口 \nport 6379 \ntimeout 86400 \ntcp-keepalive 60 \nloglevel notice \n# 日志文件路径 \nlogfile /usr/local/codis/log/redis-6379.log \ndatabases 16 \nsave “” \nsave 900 1 \nsave 300 10 \nsave 60 10000 \nstop-writes-on-bgsave-error no \nrdbcompression yes \n# dump文件\ndbfilename dump-6379.rdb  \n# dump路径 \ndir /usr/local/codis/data/redis_data_6379 \n# Master密码（从主同步密码） \nmasterauth \"123456\" \nslave-serve-stale-data yes \nrepl-disable-tcp-nodelay no \nslave-priority 100 \n# 鉴权密码（客户端连接密码） \nrequirepass \"123456\" \nmaxmemory 10gb \nmaxmemory-policy allkeys-lru \nappendonly no \nappendfsync everysec \nno-appendfsync-on-rewrite yes \nauto-aof-rewrite-percentage 100 \nauto-aof-rewrite-min-size 64mblua-time-limit 5000 \nslowlog-log-slower-than 10000 \nslowlog-max-len 128 \nhash-max-ziplist-entries 512 \nhash-max-ziplist-value 64 \nlist-max-ziplist-entries 512 \nlist-max-ziplist-value 64 \nset-max-intset-entries 512 \nzset-max-ziplist-entries 128 \nzset-max-ziplist-value 64 \nclient-output-buffer-limit normal 0 0 0 \nclient-output-buffer-limit slave 0 0 0 \nclient-output-buffer-limit pubsub 0 0 0 \nhz 10 \naof-rewrite-incremental-fsync yes \nrepl-backlog-size 33554432\n```\n#### 配置Codis-server 从[1-5]\n\n```bash\ncd /usr/local/codis/conf/\n# 从配置\ncp redis.conf redis-6380.conf \n# 修改配置\nvim redis-6380.conf \n\ndaemonize yes \n# 进程ID文件路径 \npidfile /usr/loca/codis/proc/redis-6380.pid \n# 绑定端口 \nport 6380 \ntimeout 86400 \ntcp-keepalive 60 \nloglevel notice \n# 日志文件路径 \nlogfile /usr/local/codis/log/redis-6380.log \ndatabases 16 \n# 如果不希望存储到磁盘，则可以使用井号注销save配置行 \nsave “” \nsave 900 1\nsave 300 10\nsave 60 10000\nstop-writes-on-bgsave-error no \nrdbcompression yes \n# dump文件 \ndbfilename dump-6380.rdb \n# dump路径 \ndir /usr/local/codis/data/redis_data_6380\n# Master密码（适合主从集群） \nmasterauth \"123456\"  \nslave-serve-stale-data yes \nrepl-disable-tcp-nodelay no \nslave-priority 100 \n# 鉴权密码（客户端连接密码） \nrequirepass \"123456\" \nmaxmemory 10gb \nmaxmemory-policy allkeys-lru \nappendonly no \nappendfsync everysec \nno-appendfsync-on-rewrite yes \nauto-aof-rewrite-percentage 100 \nauto-aof-rewrite-min-size 64mblua-time-limit 5000 \nslowlog-log-slower-than 10000 \nslowlog-max-len 128 \nhash-max-ziplist-entries 512 \nhash-max-ziplist-value 64 \nlist-max-ziplist-entries 512 \nlist-max-ziplist-value 64 \nset-max-intset-entries 512 \nzset-max-ziplist-entries 128 \nzset-max-ziplist-value 64 \nclient-output-buffer-limit normal 0 0 0 \nclient-output-buffer-limit slave 0 0 0 \nclient-output-buffer-limit pubsub 0 0 0 \nhz 10 \naof-rewrite-incremental-fsync yes \nrepl-backlog-size 33554432\n```\n#### 启动主从[1-5]\n\n```bash\ncd /usr/local/codis/bin/\n #启动主程序\n./codis-server ../conf/redis-6379.conf &\n#启动从程序\n./codis-server ../conf/redis-6380.conf &\n```\n#### 配置Codis-dashboard[8]\n\t作用：集群管理工具，支持 codis-proxy、codis-server 的添加、删除，以及据迁移等操作。在集群状态发生改变时，codis-dashboard 维护集群下所有 codis-proxy 的状态的一致性。\n\t1.对于同一个业务集群而言，同一个时刻 codis-dashboard 只能有 0个或者1个；\n\t2.所有对集群的修改都必须通过 codis-dashboard 完成。\n\n```bash\ncd /usr/local/codis/bin/\n#生成配置 \n./codis-dashboard - -default-conifg | tee ../conf/dashboard.conf\n # 修改配置\nvim ../conf/dashboard.conf\n\n# 外部存储类型\ncoordinator_name = \"zookeeper\"\n # 外部存储IP列表\ncoordinator_addr = \"192.168.1.51:2181,192.168.1.52:2181,192.168.1.53:2181\"\n# 项目名称 \nproduct_name = \"chatroom\"\n# 集群密码（注意:需要与redis配置中的requirepass保持一致）\nproduct_auth = “123456”\n# RESTful API 端口\nadmin_addr = \"0.0.0.0:18080\"\n\n\n#为了防止出现dashboard监控页面中OPS始终为0的现象，需要将各proxy的IP和主机名写到hosts文件中。\n # 添加域名\nvim /etc/hosts\n192.168.1.21 WebSocket-21 \n192.168.1.22 WebSocket22\n```\n#### 启动Codis-dashboard\n\n```bash\ncd ./bin/ \n #启动程序(注意：使用绝对路径）\nnohup ./codis-dashboard --ncpu=24 --config=/usr/local/codis/conf/dashboard.conf --log=/usr/local/codis/log/dashboard.log --log-level=WARN &\n\n#参数描述如下：\n#--ncpu\t最大使用CPU个数\t\n#--config\t指定配置路径和文件\t使用绝对路径\n#--log\t指定日志输出路径和文件\t使用绝对路径\n#--log-level\t指定日志级别\t取值：INFO、WARN、DEBUG、ERROR，推荐使用WRAN.\n\n#如果想关闭dashboard服务，可执行：\n./codis-admin - -dashboard=192.168.1.31:18080 –auth=123456 - -shutdown\n```\n#### 配置Codis-proxy[6-7]\n\t作用：客户端连接的 Redis 代理服务, 实现了 Redis 协议。 除部分命令不支持以外(不支持的命令列表)，表现的和原生的 Redis 没有区别（就像 Twemproxy）。\n\t1.对于同一个业务集群而言，可以同时部署多个 codis-proxy 实例； \n\t2.不同 codis-proxy 之间由 codis-dashboard 保证状态同步。\n\n```bash\ncd /usr/local/codis/bin/\n # 生成配置\n./codis-proxy - -default-config | tee ../conf/proxy.conf\n#修改配置\nvim ../proxy.conf\n\n# 设置项目名 \nproduct_name = \"chatroom\"\n# 设置登录dashboard的密码（注意：与redis中requirepass一致）\nproduct_auth = \"123456\" \n# Redis客户端的登录密码（注意：与redis中requirepass不一致） \nsession_auth = \"56789\" \n# Set bind address for admin(rpc), tcp only. \nadmin_addr = \"0.0.0.0:11080\" \n# Set bind address for proxy, proto_type can be “tcp”,”tcp4”, “tcp6”, “unix” \nor “unixpacket”. \nproto_type = “tcp4” \n#绑定端口（Redis客户端连接此端口） \nproxy_addr = \"0.0.0.0:19000\" \n# 外部存储 \n# 外部存储类型 \njodis_name = \"zookeeper\" \n# 外部存储列表 \njodis_addr = “192.168.1.51:2181,192.168.1.52:2181,192.168.1.53:2181” \njodis_timeout = “20s” \n#会话设置 \n#如果不为０可能导致应用程序出现”write: broken pipe”的问题\nsession_recv_timeout = “0s” \n```\n#### 启动Codis-proxy[6-7]\n\n```bash\nnohup ./codis-proxy - -ncpu=24 - -config=../conf/proxy.conf - -log=../log/proxy.log - -log-level=WRAN &\n```\n\t程序codis-proxy启动后，仍然处于waiting状态，虽然侦听了proxy_addr端口，但是不会accept连接请求。只有将codis-proxy加入到集群并完成集群状态的同步，才能将状态改为online。最终才能accept连接请求。\n\n#### 配置Redis-sentinel[9-11]\n\n```bash\n#拷贝程序\ncp -fr $GOPATH/github.com/CodisLabs/codis/extern/redis-3.2.8/src/redis-sentinel /usr/local/codis/bin/\n#拷贝配置\ncp -fr $GOPATH/github.com/CodisLabs/codis/extern/redis-3.2.8/sentinel.conf /usr/local/codis/conf/\n#修改配置\ncd /usr/local/codis/\nvim ./conf/sentinel.conf\n\nbind 0.0.0.0 \nprotected-mode no \nport 26379 \ndir “/usr/local/codis/data/\n#其他结点的配置与此一致。\n```\n#### 启动Redis-sentinel[9-11]\n\n```bash\ncd /usr/local/codis/bin/ \nnohup ./redis-sentinel ../conf/sentinel.conf &\n```\n#### 配置odis-fe[8]\n\t作用：集群管理界面。\n\t1.多个集群实例共享可以共享同一个前端展示页面； \n\t2.通过配置文件管理后端codis-dashboard列表，配置文件可自动更新。\n\n```bash\n#生成配置\n./codis-amdin - -dashboard-list - -zookeeper=192.168.1.51:2181 | tee ../conf/codis.json\n[ { \n“name”:”chatroom”, \n“dashboard”:192.168.1.31:18087” \n} ]\n```\n#### 启动odis-fe[8]\n\n```bash\n#nohup ./codis-fe - -ncpu=4 - -log=../log/fe.log - -log-level=WARN - -dashboard-list=../conf/codis.josn –listen=0.0.0.0:18090 &\n#打开浏览器，输入192.168.1.31:18090便可看到codis集群的监控界面\n```\n#### 加入集群\n","tags":["codis"],"categories":["数据库"]},{"title":"Redis集群模式(官方版)","url":"%2F2016%2F05%2F16%2FRedis%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F(%E5%AE%98%E6%96%B9%E7%89%88)%2F","content":"\n#### redis使用中遇到的瓶颈\n\t我们日常在对于redis的使用中，经常会遇到一些问题\n\t1、高可用问题，如何保证redis的持续高可用性。\n\t2、容量问题，单实例redis内存无法无限扩充，达到32G后就进入了64位世界，性能下降。\n\t3、并发性能问题，redis号称单实例10万并发，但也是有尽头的。\n\n#### redis-cluster的优势\n\t1、官方推荐，毋庸置疑。\n\t2、去中心化，集群最大可增加1000个节点，性能随节点增加而线性扩展。\n\t3、管理方便，后续可自行增加或摘除节点，移动分槽等等。\n\t4、简单，易上手。\n\n<!--more--> \n#### 集群模型\n![](http://www.machunpeng.cn/server/../Public/Uploads/2018-04-14/5ad17cfc29365.png)\n\n#### 节点准备\n\n|主机名|IP|角色|\n| ------------ | ------------ | ------------ |\n|Master1|172.16.10.1|master|\n|Master1|172.16.10.2|master|\n|Master1|172.16.10.3|master|\n|Slave1|172.16.10.4|slave|\n|Slave1|172.16.10.5|slave|\n|Slave1|172.16.10.6|slave|\n\n#### 安装Redis实例，所有节点\n\t略...\n\n#### 修改系统配置，所有节点\n\n```bash\nvim /etc/sysctl.conf\nvm.overcommit_memory = 1\n```\n\n#### 配置所有实例，如下\n\n```bash\n#redis.conf默认配置\ndaemonize yes\npidfile /data/program/redis/redis.pid\nport 6379\ntcp-backlog 511\nbind 0.0.0.0\ntimeout 0\ntcp-keepalive 0\nloglevel notice\nlogfile /data/program/redis/logs/redis.log\ndatabases 16\nsave 900 1\nsave 300 10\nsave 60 10000\nstop-writes-on-bgsave-error yes\nrdbcompression yes\nrdbchecksum yes\ndbfilename dump.rdb\nslave-serve-stale-data yes\nslave-read-only yes\nrepl-diskless-sync no\nrepl-diskless-sync-delay 5\nrepl-disable-tcp-nodelay no\nslave-priority 100\nappendonly yes\nappendfilename \"appendonly.aof\"\nappendfsync everysec\nno-appendfsync-on-rewrite no\nauto-aof-rewrite-percentage 100\nauto-aof-rewrite-min-size 64mb\naof-load-truncated yes\nlua-time-limit 5000\nslowlog-log-slower-than 10000\nslowlog-max-len 128\nlatency-monitor-threshold 0\nnotify-keyspace-events \"\"\nhash-max-ziplist-entries 512\nhash-max-ziplist-value 64\nlist-max-ziplist-entries 512\nlist-max-ziplist-value 64\nset-max-intset-entries 512\nzset-max-ziplist-entries 128\nzset-max-ziplist-value 64\nhll-sparse-max-bytes 3000\nactiverehashing yes\nclient-output-buffer-limit normal 0 0 0\nclient-output-buffer-limit slave 256mb 64mb 60\nclient-output-buffer-limit pubsub 32mb 8mb 60\nhz 10\n\n#自定义配置\naof-rewrite-incremental-fsync yes\nmaxmemory 4096mb\nmaxmemory-policy allkeys-lru\ndir /data/program/redis/data/6379\n\n#集群配置\ncluster-enabled yes\n#集群配置文件不同于实例配置文件\ncluster-config-file /data/program/redis/conf/node.conf\ncluster-node-timeout 5000\n\n\n#从ping主间隔默认10秒\n#复制超时时间\nrepl-timeout 60\n\n#远距离主从\nconfig set client-output-buffer-limit \"slave 536870912 536870912 0\"\nconfig set repl-backlog-size 209715200\n```\n#### 启动实例\n\n```bash\nredis-server /data/program/redis/conf/redis.conf\n```\n#### 创建redis-cluster\n\n实际上，Redis集群的操作在后文你可以看到是通过Ruby脚本来完成的，因此我们需要安装Ruby相关的RPM包，以及Redis和Ruby的接口包。\n\n```bash\nyum install ruby\nyum install rubygems\ngem install redis\n\n#通过ruby脚本创建redis集群\n#集群命令中 --replicas 1，这个代表什么意思呢？1其实代表的是一个比例，就是主节点数/从节点数的比例。那么想一想，在创建集群的时候，哪些节点是主节点呢？哪些节点是从节点呢？答案是将按照命令中IP:PORT的顺序，先是3个主节点，然后是3个从节点\n ./redis-trib.rb create --replicas 1 172.16.10.1:6379 172.16.10.2:6379 172.16.10.3:6379 172.16.10.4:6379 172.16.10.5:6379 172.16.10.6:6379\n```\n#### 验证集群\n\n```bash\nredis-cli -c -h 172.16.10.1 -p 6379\n>cluster node\n#执行后显示节点信息\n...\n...\n>cluster info\n#\n...\n...\n```\n#### solt的概念\n\n```bash\n#slot对于Redis集群而言，就是一个存放数据的地方，就是一个槽。对于每一个Master而言，会存在一个slot的范围，而Slave则没有。在Redis集群中，依然是Master可以读、写，而Slave只读。数据的写入，实际上是分布的存储在slot中，这和以前1.X的主从模式是不一样的（主从模式下Master/Slave数据存储是完全一致的），因为Redis集群中3台Master的数据存储并不一样。当存储某一个数据的时候，会分配一个slot，而这个slot从属于某一个Master，也就是说你需要明白，数据是分布的存储在Redis集群当中的\n```\n#### 维护-在线扩容\n\n按照以上操作，新增两个redis实例（10.7，10.8），修改配置并启动，然后加入集群，如下：\n\n```bash\n./redis-trib.rb add-node 172.16.10.7:6379 172.16.10.6:6379\n#在往集群中添加节点A的时候，需要提供一个在集群中已经存在的节点B的信息。因为知道了B的信息，就知道了整个集群的信息。要知道集群中的每一个节点都有这么一个文件，存储着集群中每一个节点的信息:节点的角色、节点的ID、连接状态、slot范围、IP/PORT信息等。仔细观察图中，你可以发现，新加入的8007节点，实际上被默认为master节点，并且没有slot分配！这说明，新加入的节点现在还不可以存储数据，因此我们要为新节点分配slot槽，如下：\n./redis-trib.rb reshard 172.16.10.7:6379\n#要知道slot都分配在master上，因此其实我们要做的就是从集群的masters上进行重新分配。上面的命令需要指定一个master节点进行reshard分片\n#执行完上条命令会让输入分配solt的数量，输入solt数量后确定,然后输入接受solt的节点IP，这里就是新加入节点的IP。再然后会让你选择从那个节点上获得solt，可以输入all,所有节点均匀的分配一部分slot。也可以通过\"done\"来指定某一个master进行分配。注意分配给10.7是通过节点ID来指定的\n\n\n#按照上面的操作，我将10.8节点也加入集群中，10.8是10.7的从节点，就不需要分配slot槽。注意到add-node方式加入的节点，默认就是master节点，因此这里我们得利用replicate指定主节点\nredis-trib.rb add-node 172.16.10.8:6379 172.16.10.1:6379\nredis-cli -c -h 172.16.10.8 -p 6379\n>cluster replicate  \"nodeid\"\n#nodeid\t是10.7的节点ID，可以通过cluter nodes获得。\n#或者直接如下操作：\nredis-trib.rb add-node --slave --master-id xxxxx 172.16.10.8:6379 172.16.10.1:6379\n```\n#### 维护-删除节点\n删除节点时，数据怎么办呢？对于从节点，删除就删除了，并不要紧，关键是主节点，因为主节点上有slot。因此，在删除主节点前，我们要对主节点的slot进行重新分配，完成数据的迁移。\n\n```bash\n#删除从节点\nredis-trib.rb del-node 172.16.10.8:6379 '9c240333476469e8e2c8e80b089c48f389827265'\n\n#移走主节点的solt\nredis-trib.rb reshard 172.16.10.7:6379\nHow many slots do you want to move (from 1 to 16384)? 1000 //被删除master的所有slot数量\nWhat is the receiving node ID? 5d8ef5a7fbd72ac586bef04fa6de8a88c0671052 //接收6378节点slot的master\nPlease enter all the source node IDs.\nType 'all' to use all the nodes as source nodes for the hash slots.\nType 'done' once you entered all the source nodes IDs.\nSource node #1:03ccad2ba5dd1e062464bc7590400441fafb63f2 //被删除master的node-id\nSource node #2:done\n\n#删除master\nredis-trib.rb del-node 172.16.10.7:6379 '03ccad2ba5dd1e062464bc7590400441fafb63f2'\n```\n#### 查看集群状况\n\n```bash\nredis-trib.rb check 172.16.10.1:6379\n#任何一个主节点都可以\n```","tags":["redis集群"],"categories":["数据库"]},{"title":"Redis常用操作","url":"%2F2016%2F05%2F16%2FRedis%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F","content":"\n#### Redis 控制台常用命令\n\tTIME 查看时间戳与微秒数\n\tDBSIZE 查看当前库中的key数量\n\tBGREWRITEAOF 后台进程重写AOF\n\tBGSAVE       后台保存rdb快照\n\tSAVE         保存rdb快照\n\tLASTSAVE     上次保存时间\n\tSLAVEOF      设为slave服务器\n\tFLUSHALL     清空所有db\n\tFLUSHDB      清空当前db\n\tSHUTDOWN[\"\"|save|nosave]     断开连接,关闭服务器\n\tSLOWLOG   显示慢查询\n\tINFO      显示服务器信息\n\tCONFIG GET 获取配置信息\n\tCONFIG SET 设置配置信息\n\tMONITOR    打开控制台\n\tSYNC       主从同步\n\tCLIENT LIST 客户端列表\n\tCLIENT KILL 关闭某个客户端\n\tCLIENT SETNAME 为客户端设置名字\n\tCLIENT GETNAME 获取客户端名字\n\n<!--more-->\n\n#### 操作实例\n```bash\nredis 127.0.0.1:6380> time  ,显示服务器时间 , 时间戳(秒), 微秒数\n1) \"1375270361\"\n2) \"504511\"\n```\n\n```bash\nredis 127.0.0.1:6380> dbsize  // 当前数据库的key的数量\n(integer) 2\n```\n```bash\nredis 127.0.0.1:6380> select 2\nOK\n```\n```bash\nredis 127.0.0.1:6380[2]> dbsize\n(integer) 0\n```\n\n\n#### 答疑\n\n\t注:如果不小心运行了flushall,立即 shutdown nosave ,关闭服务器\n\t然后 手工编辑aof文件, 去掉文件中的 “flushall ”相关行, 然后开启服务器,就可以导入回原来数据.\n\t如果,flushall之后,系统恰好bgrewriteaof了,那么aof就清空了,数据丢失.\n\t \n\tSlowlog 显示慢查询\n\t注:多慢才叫慢?\n\t答:由slowlog-log-slower-than 10000 ,来指定,(单位是微秒)\n\n\t服务器储存多少条慢查询的记录?\n\t答: 由 slowlog-max-len 128 ,来做限制\n\tInfo [Replication/CPU/Memory..]\n\n\t查看redis服务器的信息\n\tConfig get 配置项 \n\tConfig set 配置项值 (特殊的选项,不允许用此命令设置,如slave-of, 需要用单独的slaveof命令来设置)\n\n\n\tRedis运维时需要注意的参数\n\t1: 内存\n\t# Memory\n\tused_memory:859192 数据结构的空间\n\tused_memory_rss:7634944 实占空间\n\tmem_fragmentation_ratio:8.89 前2者的比例,1.N为佳,如果此值过大,说明redis的内存的碎片化严重,可以导出再导入一次.\n\n\t2: 主从复制\n\t# Replication\n\trole:slave\n\tmaster_host:192.168.1.128\n\tmaster_port:6379\n\tmaster_link_status:up\n\n\t \n\t3:持久化\n\t# Persistence\n\trdb_changes_since_last_save:0\n\trdb_last_save_time:1375224063\n\n\t \n\t4: fork耗时\n\t#Status\n\tlatest_fork_usec:936  上次导出rdb快照,持久化花费微秒\n\t注意:如果某实例有10G内容,导出需要2分钟,\n\t每分钟写入10000次,导致不断的rdb导出,磁盘始处于高IO状态.\n\n\t \n\t5: 慢日志\n\tconfig get/set slowlog-log-slower-than\n\tCONFIG get/SET slowlog-max-len\n\tslowlog get N 获取慢日志\n\n\n\t运行时更改master-slave\n\n\t修改一台slave(设为A)为new master\n\t1) 命令该服务不做其他redis服务的slave\n\t   命令: slaveof no one\n\t2) 修改其readonly为yes\n\n\t \n\t其他的slave再指向new master A\n\t1) 命令该服务为new master A的slave\n\t   命令格式 slaveof IP port","tags":["redis集群"],"categories":["数据库"]},{"title":"Redis编译安装","url":"%2F2016%2F05%2F16%2FRedis%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%2F","content":"\n\n#### 下载、解压、编译\n\n```bash\nwget http://download.redis.io/releases/redis-4.0.6.tar.gz\ntar zxvf redis-4.0.6.tar.gz\ncd redis-4.0.6\nmake\n```\n#### 安装\n\n```bash\n#安装\nmake PREFIX=/data/program/redis install\n#创建配置文件目录\nmkdir /data/program/redis/conf\n#创建日志存放目录\nmkdir /data/program/redis/logs\n#创建数据目录\nmkdir /data/program/redis/data\n#复制配置模板\n```\n#### 配置\n\n```bash\ncp redis.conf /data/program/redis/conf/\n#修改redis.conf的daemonize yes\n```\n#### 启动\n\n```bash\n/data/program/redis/bin/redis-server /data/program/redis/conf/redis.conf\n```\n\n#### 关闭\n\n```bash\n/data/program/redis/bin/redis-cli shutdown\n```","tags":["编译安装"],"categories":["数据库"]},{"title":"RabbitMQ用户权限","url":"%2F2016%2F05%2F11%2FRabbitMQ%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90%2F","content":"\n#### 用户角色分类\n\tnone、management、policymaker、monitoring、administrator\n\n<!--more-->\n#### 各类角色描述：\n\tnone\n\t不能访问 management plugin\n\n\tmanagement\n\t用户可以通过AMQP做的任何事外加：\n\t列出自己可以通过AMQP登入的virtual hosts  \n\t查看自己的virtual hosts中的queues, exchanges 和 bindings\n\t查看和关闭自己的channels 和 connections\n\t查看有关自己的virtual hosts的“全局”的统计信息，包含其他用户在这些virtual hosts中的活动。\n\n\tpolicymaker \n\tmanagement可以做的任何事外加：\n\t查看、创建和删除自己的virtual hosts所属的policies和parameters\n\n\tmonitoring  \n\tmanagement可以做的任何事外加：\n\t列出所有virtual hosts，包括他们不能登录的virtual hosts\n\t查看其他用户的connections和channels\n\t查看节点级别的数据如clustering和memory使用情况\n\t查看真正的关于所有virtual hosts的全局的统计信息\n\n\tadministrator   \n\tpolicymaker和monitoring可以做的任何事外加:\n\t创建和删除virtual hosts\n\t查看、创建和删除users\n\t查看创建和删除permissions\n\t关闭其他用户的connections\n\n#### 创建用户并设置角色\n\n```bash\n#可以创建管理员用户，负责整个MQ的运维，例如：\nrabbitmqctl add_user  user_admin  passwd_admin\n#赋予其administrator角色\nrabbitmqctl set_user_tags user_admin administrator\n```\n```bash\n#可以创建RabbitMQ监控用户，负责整个MQ的监控，例如：\nsudo rabbitmqctl add_user  user_monitoring  passwd_monitor\n#赋予其monitoring角色：\nsudo rabbitmqctl set_user_tags user_monitoring monitoring\n```\n```bash\n#可以创建某个项目的专用用户，只能访问项目自己的virtual hosts\nsudo rabbitmqctl  add_user  user_proj  passwd_proj\n#赋予其monitoring角色：\nsudo rabbitmqctl set_user_tags user_proj management\n```\n\n```bash\n#创建和赋角色完成后查看并确认：\nsudo rabbitmqctl list_users\n```\n#### 权限控制\n\n\t默认virtual host：\"/\"\n\t默认用户：guest \n\tguest具有\"/\"上的全部权限，仅能有localhost访问RabbitMQ包括Plugin，建议删除或更改密码。可通过将配置文件中loopback_users置孔来取消其本地访问的限制：\n\t[{rabbit, [{loopback_users, []}]}]\n\n\t用户仅能对其所能访问的virtual hosts中的资源进行操作。这里的资源指的是virtual hosts中的exchanges、queues等，操作包括对资源进行配置、写、读。配置权限可创建、删除、资源并修改资源的行为，写权限可向资源发送消息，读权限从资源获取消息。比如：\n\texchange和queue的declare与delete分别需要exchange和queue上的配置权限\n\texchange的bind与unbind需要exchange的读写权限\n\tqueue的bind与unbind需要queue写权限exchange的读权限\n\t发消息(publish)需exchange的写权限\n\t获取或清除(get、consume、purge)消息需queue的读权限\n\n\t对何种资源具有配置、写、读的权限通过正则表达式来匹配，具体命令如下：\n\tset_permissions [-p <vhostpath>] <user> <conf> <write> <read>\n\t其中，<conf> <write> <read>的位置分别用正则表达式来匹配特定的资源，如'^(amq\\.gen.*|amq\\.default)$'可以匹配server生成的和默认的exchange，'^$'不匹配任何资源\n\n\t需要注意的是RabbitMQ会缓存每个connection或channel的权限验证结果、因此权限发生变化后需要重连才能生效。\n\n#### 为用户授权\n\n```bash\nsudo rabbitmqctl  set_permissions -p /vhost1  user_admin '.*' '.*' '.*'  \n#该命令使用户user_admin具有/vhost1这个virtual host中所有资源的配置、写、读权限以便管理其中的资源\n\n\n#查看权限：\nsudo rabbitmqctl list_user_permissions user_admin  \nListing permissions for user \"user_admin\" ...  \n/vhost1<span style=\"white-space:pre\"> </span>.*<span style=\"white-space:pre\"> </span>.*<span style=\"white-space:pre\"> </span>.*  \n  \n$sudo rabbitmqctl list_permissions -p /vhost1  \nListing permissions in vhost \"/vhost1\" ...  \nuser_admin<span style=\"white-space:pre\">  </span>.*<span style=\"white-space:pre\"> </span>.*<span style=\"white-space:pre\"> </span>.*  \n```","tags":["消息中间件"],"categories":["数据库"]},{"title":"RabbitMQ集群镜像设置","url":"%2F2016%2F05%2F11%2FRabbitMQ%E9%9B%86%E7%BE%A4%E9%95%9C%E5%83%8F%E8%AE%BE%E7%BD%AE%2F","content":"\n#### 镜像队列的设置\n\n```bash\n#镜像队列的配置通过添加policy完成，policy添加的命令为：\nrabbitmqctl set_policy [-p Vhost] Name Pattern Definition [Priority]\n-p Vhost： 可选参数，针对指定vhost下的queue进行设置\nName: policy的名称\nPattern: queue的匹配模式(正则表达式)\nDefinition：镜像定义，包括三个部分ha-mode, ha-params, ha-sync-mode\nha-mode:指明镜像队列的模式，有效值为 all/exactly/nodes\nall：表示在集群中所有的节点上进行镜像\nexactly：表示在指定个数的节点上进行镜像，节点的个数由ha-params指定\nnodes：表示在指定的节点上进行镜像，节点名称通过ha-params指定\nha-params：ha-mode模式需要用到的参数\nha-sync-mode：进行队列中消息的同步方式，有效值为automatic和manual\npriority：可选参数，policy的优先级\n\n#例如，对队列名称以“queue_”开头的所有队列进行镜像，并在集群的两个节点上完成进行，policy的设置命令为：\nrabbitmqctl set_policy --priority 0 --apply-to queues mirror_queue \"^queue_\" '{\"ha-mode\":\"exactly\",\"ha-params\":2,\"ha-sync-mode\":\"automatic\"}'\n```\n\t也可以通过RabbitMQ的web管理界面设置：\n![](http://192.168.3.99:8080/server/../Public/Uploads/2018-04-16/5ad452c7e167c.png)","tags":["RabbitMQ集群"],"categories":["数据库"]},{"title":"RabbitMQ集群功能和原理","url":"%2F2016%2F05%2F11%2FRabbitMQ%E9%9B%86%E7%BE%A4%E5%8A%9F%E8%83%BD%E5%92%8C%E5%8E%9F%E7%90%86%2F","content":"\n#### 设计集群的目的\n\t允许消费者和生产者在RabbitMQ节点崩溃的情况下继续运行\n\t通过增加更多的节点来扩展消息通信的吞吐量\n\n#### 集群配置方式\n\tRabbitMQ可以通过三种方法来部署分布式集群系统，分别是：cluster,federation,shovel\n\n\tcluster:\n\t不支持跨网段，用于同一个网段内的局域网\n\t可以随意的动态增加或者减少\n\t节点之间需要运行相同版本的RabbitMQ和Erlang\n\n\tfederation:应用于广域网，允许单台服务器上的交换机或队列接收发布到另一台服务器上交换机或队列的消息，可以是单独机器或集群。federation队列类似于单向点对点连接，消息会在联盟队列之间转发任意次，直到被消费者接受。通常使用federation来连接internet上的中间服务器，用作订阅分发消息或工作队列。\n\tshovel:连接方式与federation的连接方式类似，但它工作在更低层次。可以应用于广域网。\n<!--more-->\n#### 节点类型\n\tRAM node:内存节点将所有的队列、交换机、绑定、用户、权限和vhost的元数据定义存储在内存中，好处是可以使得像交换机和队列声明等操作更加的快速。\n\tDisk node:将元数据存储在磁盘中，单节点系统只允许磁盘类型的节点，防止重启RabbitMQ的时候，丢失系统的配置信息。\n\n\t问题说明： RabbitMQ要求在集群中至少有一个磁盘节点，所有其他节点可以是内存节点，当节点加入或者离开集群时，必须要将该变更通知到至少一个磁盘节点。如果集群中唯一的一个磁盘节点崩溃的话，集群仍然可以保持运行，但是无法进行其他操作（增删改查），直到节点恢复。 \n\t解决方案：设置两个磁盘节点，至少有一个是可用的，可以保存元数据的更改。\n\n#### Erlang Cookie\n\tErlang Cookie是保证不同节点可以相互通信的密钥，要保证集群中的不同节点相互通信必须共享相同的Erlang Cookie。具体的目录存放在/var/lib/rabbitmq/.erlang.cookie。\n\t说明： 这就要从rabbitmqctl命令的工作原理说起，RabbitMQ底层是通过Erlang架构来实现的，所以rabbitmqctl会启动Erlang节点，并基于Erlang节点来使用Erlang系统连接RabbitMQ节点，在连接过程中需要正确的Erlang Cookie和节点名称，Erlang节点通过交换Erlang Cookie以获得认证。\n\n\n#### 镜像队列\n\n\t功能和原理 \n\tRabbitMQ的Cluster集群模式一般分为两种，普通模式和镜像模式。\n\n\t普通模式：默认的集群模式，以两个节点（rabbit01、rabbit02）为例来进行说明。对于Queue来说，消息实体只存在于其中一个节点rabbit01（或者rabbit02），rabbit01和rabbit02两个节点仅有相同的元数据，即队列的结构。当消息进入rabbit01节点的Queue后，consumer从rabbit02节点消费时，RabbitMQ会临时在rabbit01、rabbit02间进行消息传输，把A中的消息实体取出并经过B发送给consumer。所以consumer应尽量连接每一个节点，从中取消息。即对于同一个逻辑队列，要在多个节点建立物理Queue。否则无论consumer连rabbit01或rabbit02，出口总在rabbit01，会产生瓶颈。当rabbit01节点故障后，rabbit02节点无法取到rabbit01节点中还未消费的消息实体。如果做了消息持久化，那么得等rabbit01节点恢复，然后才可被消费；如果没有持久化的话，就会产生消息丢失的现象。\n\n\t镜像模式：将需要消费的队列变为镜像队列，存在于多个节点，这样就可以实现RabbitMQ的HA高可用性。作用就是消息实体会主动在镜像节点之间实现同步，而不是像普通模式那样，在consumer消费数据时临时读取。缺点就是，集群内部的同步通讯会占用大量的网络带宽。\n\n#### 实现机制 \n\t镜像队列实现了RabbitMQ的高可用性（HA），具体的实现策略如下所示：\n\n\n|ha-mode|ha-params|功能\n|-----|------|------|\n|all|空|镜像队列将会在整个集群中复制。当一个新的节点加入后，也会在这 个节点上复制一份。|\n|exactly|count|镜像队列将会在集群上复制count份。如果集群数量少于count时候，队列会复制到所有节点上。如果大于Count集群，有一个节点crash后，新进入节点也不会做新的镜像。|\n|nodes|node name|镜像队列会在node name中复制。如果这个名称不是集群中的一个，这不会触发错误。如果在这个node list中没有一个节点在线，那么这个queue会被声明在client连接的节点。|\n\n```bash\n#实例列举：\nqueue_args(\"x-ha-policy\":\"all\") //定义字典来设置额外的队列声明参数\nchannel.queue_declare(queue=\"hello-queue\",argument=queue_args)\n#如果需要设定特定的节点（以rabbit@localhost为例），再添加一个参数\nqueue_args(\"x-ha-policy\":\"nodes\",\n           \"x-ha-policy-params\":[\"rabbit@localhost\"])\nchannel.queue_declare(queue=\"hello-queue\",argument=queue_args)\n#可以通过命令行查看那个主节点进行了同步\nrabbitmqctl list_queue name slave_pids synchronised_slave_pids\n```\n\n","tags":["RabbitMQ集群"],"categories":["数据库"]},{"title":"RabbitMQ集群-多机多节点部署","url":"%2F2016%2F05%2F11%2FRabbitMQ%E9%9B%86%E7%BE%A4-%E5%A4%9A%E6%9C%BA%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2%2F","content":"\n#### 多机多节点部署\n\t不同于单机多节点的情况，在多机环境，如果要在cluster集群内部署多个节点，需要注意两个方面：\n\t1、保证需要部署的这几个节点在同一个局域网内\n\t2、需要有相同的Erlang Cookie，否则不能进行通信，为保证cookie的完全一致，采用从一个节点copy的方式\n\n#### 环境介绍\n\n|RabbitMQ节点|IP地址|工作模式|操作系统|\n|-----|-------|-------|------|\n|rabbitmqCluster|186.16.195.24|DISK|CentOS 7.0 - 64位|\n|rabbitmqCluster01|186.16.195.25|DISK|CentOS 7.0 - 64位|\n|rabbitmqCluster02|186.16.195.26|DISK|CentOS 7.0 - 64位|\n\n<!--more-->\n#### 局域网配置 \n\n```bash\n#分别在三个节点的/etc/hosts下设置相同的配置信息\n186.16.195.24 rabbitmqCluster\n186.16.195.25 rabbitmqCluster01\n186.16.195.26 rabbitmqCluster02\n```\n\n#### 设置不同节点间同一认证的Erlang Cookie\n\n```bash\n[root@rabbitmqCluster01]# scp /var/lib/rabbitmq/.erlang.cookie 186.16.195.25:/var/lib/rabbitmq\n[root@rabbitmqCluster02]# scp /var/lib/rabbitmq/.erlang.cookie 186.16.195.26:/var/lib/rabbitmq\n```\n\n#### 使用 -detached运行各节点\n\n```bash\nrabbitmqctl stop\nrabbitmq-server -detached \n```\n\n#### 查看各节点的状态\n\n```bash\n[root@rabbitmqCluster]#rabbitmqctl cluster_status\n[root@rabbitmqCluster01]#rabbitmqctl cluster_status\n[root@rabbitmqCluster02]#rabbitmqctl cluster_status\n```\n#### 创建并部署集群，以rabbitmqCluster01节点为例：\n\n```bash\n[root@rabbitmqCluster01]#rabbitmqctl stop_app\n[root@rabbitmqCluster01]#rabbitmqctl join_cluster rabbit@rabbitmqCluster\n[root@rabbitmqCluster01]#rabbitmqctl start_app\n```\n#### 查看集群状态\n\n```bash\n[root@rabbitmqCluster]#rabbitmqctl cluster_status\n```","tags":["RabbitMQ集群"],"categories":["数据库"]},{"title":"RabbitMQ集群-单机多节点部署","url":"%2F2016%2F05%2F11%2FRabbitMQ%E9%9B%86%E7%BE%A4-%E5%8D%95%E6%9C%BA%E5%A4%9A%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2%2F","content":"\n#### 说明\n\t在启动RabbitMQ节点之后，服务器默认的节点名称是Rabbit和监听端口5672，如果想在同一台机器上启动多个节点，那么其他的节点就会因为节点名称和端口与默认的冲突而导致启动失败，可以通过设置环境变量来实现，具体方法如下：\n```bash\n#首先在机器上设置两个节点rabbit和rabbit_01\nrabbitmqctl stop //先停止运行节点，再进行集群部署\nRABBITMQ_NODE_PORT=5672 RABBITMQ_NODENAME=rabbit //设置环境变量指定端口和节点名称\nrabbitmq-server -detached //后台启动节点\nRABBITMQ_NODE_PORT=5673 RABBITMQ_NODENAME=rabbit_01 //设置环境变量指定端口和节点名称\nrabbitmq-server -detached //后台启动节点\n\n#或者通过添加/etc/rabbitmq/rabbitmq-env.conf文件来进行设置：\nNODE_PORT=5672\nNODENAME=rabbit\nNODE_PORT=5673\nNODENAME=rabbit_01\n\n#将rabbit_01节点添加到第一个集群节点rabbit中\nrabbitmqctl -n rabbit_01@localhost stop_app //停止rabbit_01节点的应用\nrabbitmqctl -n rabbit_01@localhost join_cluster rabbit@localhost //将rabbit_01添加到集群节点rabbit中去\nrabbitmqctl cluster_status //查看集群节点的状态\nrabbitmqctl -n rabbit_01@localhost start_app //启动rabbit_01节点的应用\n\n#可以看到如下信息，说明节点添加成功，表明都是磁盘类型的节点\nCluster status of node rabbit@localhost ...\n[{nodes,[{disc,[rabbit@localhost,rabbit_01@localhost]}]},\n {running_nodes,[rabbit@localhost]},\n {cluster_name,<<\"rabbit@localhost\">>},\n {partitions,[]},\n {alarms,[{rabbit@localhost,[]}]}]\n```","tags":["RabbitMQ集群"],"categories":["数据库"]},{"title":"RabbitMQ 基础概念","url":"%2F2016%2F05%2F11%2FRabbitMQ%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%2F","content":"\n#### 基本原理\n\tMQ全称为Message Queue, 是一种分布式应用程序的的通信方法，它是消费-生产者模型的一个典型的代表，producer往消息队列中不断写入消息，而另一端consumer则可以读取或者订阅队列中的消息。RabbitMQ是MQ产品的典型代表，是一款基于AMQP协议可复用的企业消息系统。业务上，可以实现服务提供者和消费者之间的数据解耦，提供高可用性的消息传输机制，在实际生产中应用相当广泛。本文意在介绍Rabbitmq的基本原理，包括rabbitmq基本框架，概念，通信过程等\n\n#### 系统架构\n\tRabbitmq系统最核心的组件是Exchange和Queue，下图是系统简单的示意图。Exchange和Queue是在rabbitmq server（又叫做broker）端，producer和consumer在应用端\n![](http://192.168.3.99:8080/server/../Public/Uploads/2018-04-16/5ad41cd773deb.png)\n<!--more-->\n#### producer&Consumer\n\tproducer指的是消息生产者，consumer消息的消费者。\n\n#### connection与channel\n\t是指物理的连接，一个client与一个server之间有一个连接；一个连接上可以建立多个channel，可以理解为逻辑上的连接。一般应用的情况下，有一个channel就够用了，不需要创建更多的channel\n\n#### Queue\n\t消息队列，提供了FIFO的处理机制，具有缓存消息的能力。rabbitmq中，队列消息可以设置为持久化，临时或者自动删除。\n\t设置为持久化的队列，queue中的消息会在server本地硬盘存储一份，防止系统crash，数据丢失\n\t设置为临时队列，queue中的数据在系统重启之后就会丢失\n\t设置为自动删除的队列，当不存在用户连接到server，队列中的数据会被自动删除\n\n#### Exchange\n\tExchange类似于数据通信网络中的交换机，提供消息路由策略。rabbitmq中，producer不是通过信道直接将消息发送给queue，而是先发送给Exchange。一个Exchange可以和多个Queue进行绑定，producer在传递消息的时候，会传递一个ROUTING_KEY，Exchange会根据这个ROUTING_KEY按照特定的路由算法，将消息路由给指定的queue。和Queue一样，Exchange也可设置为持久化，临时或者自动删除。\n\tExchange有4种类型：direct(默认)，fanout, topic, 和headers，不同类型的Exchange转发消息的策略有所区别：\n\n#### Direct\n\t直接交换器，工作方式类似于单播，Exchange会将消息发送完全匹配ROUTING_KEY的Queue\n\n#### fanout\n\t广播是式交换器，不管消息的ROUTING_KEY设置为什么，Exchange都会将消息转发给所有绑定的Queue。\n\n#### topic\n\t主题交换器，工作方式类似于组播，Exchange会将消息转发和ROUTING_KEY匹配模式相同的所有队列，比如，ROUTING_KEY为user.stock的Message会转发给绑定匹配模式为 * .stock,user.stock， * . * 和#.user.stock.#的队列。（ * 表是匹配一个任意词组，#表示匹配0个或多个词组）\n\n#### headers\n\t消息体的header匹配（ignore）\n\n#### Binding\n\t所谓绑定就是将一个特定的 Exchange 和一个特定的 Queue 绑定起来。Exchange 和Queue的绑定可以是多对多的关系。\n\n#### virtual host\n\t在rabbitmq server上可以创建多个虚拟的message broker，又叫做virtual hosts (vhosts)。每一个vhost本质上是一个mini-rabbitmq server，分别管理各自的exchange，和bindings。vhost相当于物理的server，可以为不同app提供边界隔离，使得应用安全的运行在不同的vhost实例上，相互之间不会干扰。producer和consumer连接rabbit server需要指定一个vhost。\n\n#### 通信过程\n\t假设P1和C1注册了相同的Broker，Exchange和Queue。P1发送的消息最终会被C1消费。基本的通信流程大概如下所示：\n\tP1生产消息，发送给服务器端的Exchange\n\tExchange收到消息，根据ROUTINKEY，将消息转发给匹配的Queue1\n\tQueue1收到消息，将消息发送给订阅者C1\n\tC1收到消息，发送ACK给队列确认收到消息\n\tQueue1收到ACK，删除队列中缓存的此条消息\n\tConsumer收到消息时需要显式的向rabbit broker发送basic.ack消息或者consumer订阅消息时设置auto_ack参数为true。在通信过程中，队列对ACK的处理有以下几种情况：\n\t如果consumer接收了消息，发送ack,rabbitmq会删除队列中这个消息，发送另一条消息给consumer。\n\t如果cosumer接受了消息, 但在发送ack之前断开连接，rabbitmq会认为这条消息没有被deliver,在consumer在次连接的时候，这条消息会被redeliver。\n\t如果consumer接受了消息，但是程序中有bug,忘记了ack,rabbitmq不会重复发送消息。\n\trabbitmq2.0.0和之后的版本支持consumer reject某条（类）消息，可以通过设置requeue参数中的reject为true达到目地，那么rabbitmq将会把消息发送给下一个注册的consumer。","tags":["消息中间件"],"categories":["数据库"]},{"title":"RabbitMQ源码安装","url":"%2F2016%2F05%2F11%2FRabbitMQ%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85%2F","content":"\n\n\n#### 安装语言环境\n\tRabbitMQ是基于Erlang的，所以首先必须配置Erlang环境.\n\n```bash\nyum -y install make gcc gcc-c++ kernel-devel m4 ncurses ncurses-devel openssl-devel perl\ncd /data/src\n#下载解压\ntar -zxvf otp_src_18.2.1.tar.gz\ncd otp_src_17.4;\n./configure --prefix=/data/program/erlang;\nmake && make install\n\n#修改/etc/profile文件，增加下面的环境变量：\n#set erlang environment\nexport PATH=$PATH:/usr/local/erlang/bin\n\nsource /etc/profile\n```\n<!--more-->\n#### 安装RabbitMQ \n\n```bash\n# 安装依赖文件 否则编译时报错：line 1: xmlto: command not found \nyum install xmlto -y\ntar -zxvf rabbitmq-server-3.5.7.tar.gz\ncd rabbitmq-server-3.5.7\nmake TARGET_DIR=/data/program/rabbitmq SBIN_DIR=/data/program/rabbitmq/sbin MAN_DIR=/data/program/rabbitmq/man DOC_INSTALL_DIR=/data/program/rabbitmq/doc\nmake TARGET_DIR=/data/program/rabbitmq SBIN_DIR=/data/program/rabbitmq/sbin MAN_DIR=/data/program/rabbitmq/man DOC_INSTALL_DIR=/data/program/rabbitmq/doc install\n添加系统环境变量：\n修改/etc/profile文件，增加下面的环境变量：\nexport PATH=$PATH:/data/program/erlang/bin:/data/program/rabbitmq/sbin\nsource /etc/profile\n```\n\n#### 服务管理\n\n```bash\n#启动服务\n#运行rabbitmq:\n/usr/rabbitmq/sbin/rabbitmq-server  -detached            #默认监听端口5672、25672\n#查看rabbitmq状态:\n/usr/rabbitmq/sbin/rabbitmqctl status\n#关闭rabbitmq:\n/usr/rabbitmq/sbin/rabbitmqctl stop\n```\n\n#### 启用Web管理\n\tRabbitMQ提供了完善的管理和监控工具，分management plugin 和 rabbitmqctl 两种类型的工具。\n\trabbitmq-management plugin提供HTTP API来管理和监控RabbitMQ Server，具体包含如下功能：\n\t删除、生成、列表，包括：exchanges，queues，bindings，users，virtual hosts and permissions。\n\t监视 queue 长度，每个 channel的message rates ，每个连接的data rates，等等。\n\t发送和接收messages。\n\t监控Erlang processes，file descriptors，memory use。\n\t导出／导出object definitions to JSON。\n\t强制关闭 connections，清空 queues。\n\n\tmanagement plugin默认就在RabbitMQ的发布版本中，只需要enable就可以了，执行以下命令：\n\n```bash\ncd /data/program/rabbitmq/bin/\nrabbitmq-plugins enable rabbitmq_management\n\n#打开浏览器，输入http://[server-name]:15672/ 如 http://localhost:15672/ 即可访问\n```","tags":["消息中间件"],"categories":["数据库"]},{"title":"NG流控和f2b防止CC","url":"%2F2016%2F04%2F24%2FNG%E6%B5%81%E6%8E%A7%E5%92%8Cf2b%E9%98%B2%E6%AD%A2CC%2F","content":"\n\n\n#### CC 攻击\n攻击者通过创建大量请求导致服务器资源耗尽，主要针对特定服务接口，属于实现 DoS 攻击的一种方式（DoS 攻击更多是针对网络端口，而不是具体服务接口）。\n\n#### NGINX 流控\nlimit_req_zone：通过“漏桶”算法限制每个 IP 发起的请求频率。\nlimit_conn_zone：限制每个 IP 发起的连接数。\n\n#### fail2ban\n通过匹配服务器日志操作 iptables 来限制客户端网络连接。\n<!--more-->\n#### 实践配置\n\n```bash\n#NGINX 部分\n#在 http 部分中配置：\nlimit_req_zone $binary_remote_addr zone=sym:10m rate=5r/s;\nlimit_conn_zone $binary_remote_addr zone=conn_sym:10m;\n\n#然后在需要流控的 location 部分配置：\nlimit_req zone=sym burst=5;\nlimit_conn conn_sym 10;\n\n#重启 NGINX 后当有超流客户端请求时将在 NGINX error.log（默认在 /var/log/nginx/error.log） 中看到类似记录：\n\n2017/02/12 18:03:57 [error]15965#15965: *61240 limiting requests, excess: 6.000 by zone \"sym\", client: 121.41.106.121, server: hacpai.com, request: \"GET / HTTP/1.0\", host: \"hacpai.com\"\n#此时请求已经被 NGINX 限流，但是客户端仍然能够继续发送请求，占用服务器资源。\n```\n\n```bash\n#fail2ban 部分\n#新建 /etc/fail2ban/jail.d/sym.conf 文件，加入如下内容：\n\n[sym-cc]\nenabled  = true\nport     = https,http\nfilter   = sym\nlogpath  = /var/log/nginx/*error.log\nmaxretry = 120\nfindtime = 60\nbantime  = 120\naction   = iptables-multiport[name=Sym, port=\"https,http\", protocol=tcp]\n           sendmail-whois-lines[name=Sym, dest=youremail@gmail.com]\n\n#findtime 60 秒内如果有超过 \n#maxretry 120 次匹配到则禁止连接 \n#bantime 120 秒。禁止连接通过操作 iptables 实现 。（要发送邮件，需要安装配置好 sendmail）\n\n#重启 fail2ban 后当发生超流时可以在 /var/log/fail2ban.log 中看到类似记录：\n2017-02-12 18:01:26,968 fail2ban.actions: WARNING [sym-cc] Ban 121.41.106.121\n\n#查看当前禁止信息\nfail2ban-client status、fail2ban-client status sym-cc\n#查看配置匹配情况。\nfail2ban-regex /var/log/nginx/error.log /etc/fail2ban/filter.d/sym.conf\n```\n#### 注意事项\n\n```bash\n#注意事项\n#fail2ban\n#服务重启可能较慢，耐心等待\n#findtime 不要小于 60 秒\n#action 用 iptables-multiport 同时设置 HTTPS 和 HTTP\n#可能需要自己手动加入操作系统启动项\n#如果 NGINX 开了 access_log，其实也可以简单粗暴一点直接将 fail2ban 配置到访问日志上，这样就不#用配置 NGINX 流控模块了，不过缺点是失去了“弹性”。\n\n#NGINX\n#上面提到的 NGINX 流控模块的“弹性”主要指的是 limit_req_zone 模块中 burst 和 nodelay 两个参数的组合使用。\n\nrate：按照固定速率“漏请求”给后端服务器\nburst：可理解为桶大小，能装多少个请求\nnodelay：带了这个参数的话在桶装不下时将请求“全部倒给”后端服务器；如果不带的话请求还是按照速率慢慢漏\n\n#日志清理\n需要定时清理 NGINX、fail2ban 日志，防止磁盘空间占用过大。\n```","tags":["fail2ban"],"categories":["网络安全"]},{"title":"mysql的性能优化","url":"%2F2016%2F04%2F19%2Fmysql%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F","content":"#### 以下是mysql 优化使用过的配置文件仅供参考\n<!--more-->\n```yaml\n[mysql]\nno_auto_rehash\nprompt = (\\u@\\h)[\\d]>\nloose-default_character_set = utf8mb4\n[client]\nport = 3306\nsocket = /data/program/mysql/mysql.sock\nloose-default_character_set = utf8mb4\n[mysqld]\n# GENERAL #\nsql_mode = STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION  # 原配置\n# init-connect = 'SET NAMES utf8mb4'  # 原配置\ndefault_time_zone = '+8:00'\nlocal_infile = OFF\nserver_id = 23306\nport = 3306\nuser = mysql\ndefault_storage_engine = InnoDB\nbasedir = /data/program/mysql\nsocket = /data/program/mysql/mysql.sock\npid-file = /data/mysql3306/log3306/run/mysqld.pid\ndatadir = /data/mysql3306/data3306/\ntransaction_isolation = READ-COMMITTED\nexplicit_defaults_for_timestamp = 1\ncharacter_set_server = utf8mb4\ncollation_server = utf8mb4_general_ci\n\n# SAFETY #\nmax_allowed_packet = 64M\nskip_name_resolve = 1\n\n# BINARY LOGGING #\nmax_binlog_size = 500M\nlog_bin = /data/mysql3306/log3306/binlog/log_bin\nexpire_logs_days = 14\nsync_binlog = 100\nbinlog_format = ROW\nbinlog_cache_size = 2M\nlog_bin_trust_function_creators = 1\nbinlog_rows_query_log_events = 1\n\n# REPLICATION #\nauto_increment_increment = 2\nauto_increment_offset = 2\nskip_slave_start = 1\nlog_slave_updates = 1\nrelay_log = /data/mysql3306/log3306/relaylog/relay_bin\nrelay_log_recovery = 1\nslave_net_timeout = 60\nmaster_info_repository = TABLE\nrelay_log_info_repository = TABLE\n\n# CACHES AND LIMITS #\ntmp_table_size = 16M\nmax_heap_table_size = 16M\nread_buffer_size = 2M\nread_rnd_buffer_size = 4M\nsort_buffer_size = 2M\njoin_buffer_size = 2M\ntmpdir = /data/mysql3306/tmp3306\nquery_cache_type = 0\nquery_cache_size = 0\nmax_connections = 1000\nmax_connect_errors = 1000\nthread_cache_size = 64\nopen_files_limit = 65000\ntable_definition_cache = 2048\ntable_open_cache = 2048\n\n# INNODB #\ninnodb_flush_method = O_DIRECT\ninnodb_file_per_table  = 1\ninnodb_data_file_path = ibdata1:128M:autoextend\ninnodb_buffer_pool_size = 4G\ninnodb_buffer_pool_instances = 8\nmetadata_locks_hash_instances = 8\ninnodb_buffer_pool_load_at_startup = 1\ninnodb_buffer_pool_dump_at_shutdown = 1\ninnodb_lru_scan_depth = 2048\ninnodb_lock_wait_timeout = 10\ninnodb_io_capacity = 1000\ninnodb_io_capacity_max = 2000\ninnodb_write_io_threads = 8\ninnodb_read_io_threads = 8\ninnodb_max_dirty_pages_pct = 75\ninnodb_undo_logs = 128\ninnodb_undo_tablespaces = 3\ninnodb_autoinc_lock_mode = 2\ninnodb_stats_persistent_sample_pages = 64\ninnodb_flush_neighbors = 1\ninnodb_log_files_in_group = 3\ninnodb_log_file_size = 256M\ninnodb_log_buffer_size = 8M\ninnodb_sort_buffer_size = 64M\ninnodb_open_files = 2048\ninnodb_purge_threads = 4\ninnodb_large_prefix = 1\ninnodb_print_all_deadlocks = 1\ninnodb_strict_mode = 1\ninnodb_flush_log_at_trx_commit = 1\n\n# MyISAM #\nkey_buffer_size = 16M\nmyisam_recover_options = default\nbulk_insert_buffer_size = 32M\nmyisam_sort_buffer_size = 4M\nmyisam_repair_threads = 1\n\n# LOGGING #\nlog_error = /data/mysql3306/log3306/run/mysqld.err\nslow_query_log_file = /data/mysql3306/log3306/run/slow.log\nslow_query_log = 1\nlog_slow_admin_statements = 1\nlog_slow_slave_statements = 1\nlong_query_time = 0.5\n\n[mysqldump]\nquick\nmax_allowed_packet = 64M\nsocket = /data/program/mysql/mysql.sock\ndefault_character_set = utf8mb4\n#user = bk_user\n#password =\n\n[xtrabackup]\n#user = bk_user\n#password =\n\n[myisamchk]\nkey_buffer_size = 16M\nsort_buffer_size = 16M\n\n[mysqlhotcopy]\ninteractive_timeout\n\n[mysqld_safe]\nuser = mysql\nbasedir = /data/program/mysql\npid-file = /data/mysql3306/log3306/run/mysqld.pid\n\n```","tags":["mysql优化"],"categories":["数据库"]},{"title":"mysql多主与主从配置","url":"%2F2016%2F04%2F19%2Fmysql%E5%A4%9A%E4%B8%BB%E4%B8%8E%E4%B8%BB%E4%BB%8E%E9%85%8D%2F","content":"\n#### 节点准备\n\n本次配置用一主两从进行记录节点信息如下：\n\n|主机名|IP|角色|\n| ------------ | ------------ |\n|master|192.168.10.1|主|\n|node01|192.168.10.2|从|\n|node02|192.168.10.3|从|\n\n#### 所有节点安装Mysql服务实例\n\t略...\n<!--more-->\n#### 修改所有实例配置文件\n\n```yaml\n#配置文件中添加如下行\n#不同节点server-id不同\nserver-id = 1\n#binlog位置\nlog-bin = /data/program/mysql/bin_log/master-bin\n#需要同步的书库，如果全部同步可以不写\nbinlog-do-db = vdevops \n#不需要记录进制日志的数据库,多个可逗号隔开(主库配置，从库不写)\nbinlog-ignore-db = mysql,information_schema,performance_schema\n#不需要同步的数据库,多个可逗号隔开(从库配置，主库不写)\nreplicate-ignore-db = mysql,information_schema,performance_schema\n#将复制事件写入binlog,一台服务器既做主库又做从库此选项必须要开启(主从模式不开启)\nlog-slave-updates\n#当每进行1次事务提交之后，MySQL将进行一次fsync之类的磁盘同步指令来将binlog_cache中的数据强制写入磁盘\nsync_binlog = 1\n#过滤掉一些没啥大问题的错误\nslave-skip-errors = all\n#binlog日志格式，mysql默认采用\nbinlog_format = mixed\n#\nread-only=0\n#该服务器自增列增量\nauto_increment_increment = 2\n#该服务器自增列的初始值\nauto_increment_offset = 1\n\n#如果为多主的话注意设置 auto-increment-offset 和 auto-increment-increment\n#如上面为双主的设置：\n#服务器 A 自增列显示为：1,3,5,7,……（offset=1，increment=2）\n#服务器 B 自增列显示为：2,4,6,8,……（offset=2，increment=2）\n```\n#### 启动所有实例\n\n#### 主节点授权\n\n```bash\n#创建用户\nmysql -uroot -proot\nmysql>create user mysync;\n#授权\nmysql>GRANT REPLICATION SLAVE ON *.* TO 'mysync'@'192.168.10.%' IDENTIFIED BY '123456'\n#\n```\n#### 从节点设置\n\n```bash\nmysql>change master to master_host='172.16.10.1',master_user='slave',master_password='123456';\nmysql>start slave;\n#验证从库\nmysql>show slave status \\G;\n#Slave_IO_Running 和 Slave_SQL_Running都为 Yes则成功\n```","tags":["mysql主从"],"categories":["数据库"]},{"title":"mysql的访问权限","url":"%2F2016%2F04%2F19%2Fmysql%E7%9A%84%E8%AE%BF%E9%97%AE%E6%9D%83%E9%99%90%2F","content":"\n#### 创建root用户并给授所有权限\n\n```bash\ngrant all on *.* to root@\"%\" Identified by \"worker\";\n#all 所有操作权限\n#*.* 所有数据库和表明\n#root 为用户\n#% 表示允许所有主机连接\n#worker 密码\n\n#这里的all 代表以下权限\n#select,insert,update,delete,create,drop,index,alter,grant,references,\n#reload,shutdown,process,file共十四种可选\n```","tags":["mysql"],"categories":["数据库"]},{"title":"mysql的常用操作","url":"%2F2016%2F04%2F19%2Fmysql%E7%9A%84%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F","content":"\n#### 备份\n\n```bash\n#备份整库\nmysqldump -h主机名 -u用户名 -p 库名 > /data/backup/xxx.sql\n#备份单张表\nmysqldump -h主机名 -u用户名 -p 库名  表名 > /data/backup/xxx.sql\n```\n#### 恢复\n\n```bash\nmysql -h主机名 -u用户名 -p 库名 < /data/backup/xxx.sql\n```\n#### 执行sql脚本文件\n\n```bash\n#在shell中执行\nmysql -h主机名 -u用户名 -p -D库名 < /data/backup/xxx.sql\n#在mysql 控制台执行\nmysql>source /data/backup/xxx.sql\n#或者\nmysql>\\. /data/backup/xxx.sql\n```\n<!--more-->\n#### 查看信息\n\n```bash\n#查看字符集\nmysql>show variables like 'character%'\n\n#如果是root帐号，你能看到所有用户的当前连接。如果是其它普通帐号，只能看到自己占用的连接。 \n#show processlist;只列出前100条，如果想全列出请使用show full processlist; \nmysql>show processlist; \n\n#命令： show status; \n#命令：show status like '%下面变量%'; \n#Aborted_clients 由于客户没有正确关闭连接已经死掉，已经放弃的连接数量。 \n#Aborted_connects 尝试已经失败的MySQL服务器的连接的次数。 \n#Connections 试图连接MySQL服务器的次数。 \n#Created_tmp_tables 当执行语句时，已经被创造了的隐含临时表的数量。 \n#Delayed_insert_threads 正在使用的延迟插入处理器线程的数量。 \n#Delayed_writes 用INSERT DELAYED写入的行数。 \n#Delayed_errors 用INSERT DELAYED写入的发生某些错误(可能重复键值)的行数。 \n#Flush_commands 执行FLUSH命令的次数。 \n#Handler_delete 请求从一张表中删除行的次数。 \n#Handler_read_first 请求读入表中第一行的次数。 \n#Handler_read_key 请求数字基于键读行。 \n#Handler_read_next 请求读入基于一个键的一行的次数。 \n#Handler_read_rnd 请求读入基于一个固定位置的一行的次数。 \n#Handler_update 请求更新表中一行的次数。 \n#Handler_write 请求向表中插入一行的次数。 \n#Key_blocks_used 用于关键字缓存的块的数量。 \n#Key_read_requests 请求从缓存读入一个键值的次数。 \n#Key_reads 从磁盘物理读入一个键值的次数。 \n#Key_write_requests 请求将一个关键字块写入缓存次数。 \n#Key_writes 将一个键值块物理写入磁盘的次数。 \n#Max_used_connections 同时使用的连接的最大数目。 \n#Not_flushed_key_blocks 在键缓存中已经改变但是还没被清空到磁盘上的键块。 \n#Not_flushed_delayed_rows 在INSERT DELAY队列中等待写入的行的数量。 \n#Open_tables 打开表的数量。 \n#Open_files 打开文件的数量。 \n#Open_streams 打开流的数量(主要用于日志记载） \n#Opened_tables 已经打开的表的数量。 \n#Questions 发往服务器的查询的数量。 \n#Slow_queries 要花超过long_query_time时间的查询数量。 \n#Threads_connected 当前打开的连接的数量。 \n#Threads_running 不在睡眠的线程数量。 \n#Uptime 服务器工作了多少秒。\n```\n\n#### 重置密码\n\n```bash\nvi /etc/my.cnf \n#在[mysqld]的段中加上一句：skip-grant-tables \n#保存并且退出，重新启动mysqld ，登录并修改MySQL的root密码 \n# mysql \nmysql> USE mysql ; \nmysql> UPDATE user SET Password = password ( 'worker' ) WHERE User = 'root' ; \nmysql> flush privileges ; \nmysql> quit \n#将MySQL的登录设置修改回来 \n# vi /etc/my.cnf \n#将刚才在[mysqld]的段中加上的skip-grant-tables删除，保存并且退出，重新启动mysqld \n```\n#### 导出数据到CSV\n\n```bash\n mysql your_database -uroot -p -e \"select * from test.table2 \" > /data/test.xls \n```\n\n#### 创建数据库\n\n```bash\nCREATE DATABASE IF NOT EXISTS dbname DEFAULT CHARSET utf8 COLLATE utf8_general_ci;\n```","tags":["sql"],"categories":["数据库"]},{"title":"Mysql的编译安装","url":"%2F2016%2F04%2F19%2Fmysql%E7%9A%84%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%2F","content":"\n### 安装依赖包\n``` bash\nyum -y install gcc gcc-c++ cmake make bison bison-devel ncurses-devel openssl-devel bison perl perl-Module-Install.noarch\n```\n### 编译安装\n``` bash\ncmake \\\n-DCMAKE_INSTALL_PREFIX=/data/program/mysql \\\n-DMYSQL_DATADIR=/data/program/mysql/data \\\n-DSYSCONFDIR=/data/program/mysql/etc \\\n-DWITH_MYISAM_STORAGE_ENGINE=1 \\\n-DWITH_INNOBASE_STORAGE_ENGINE=1 \\\n-DWITH_MEMORY_STORAGE_ENGINE=1 \\\n-DWITH_READLINE=1 \\\n-DMYSQL_UNIX_ADDR=/data/program/mysql/mysql.sock \\\n-DMYSQL_TCP_PORT=3306 \\\n-DENABLED_LOCAL_INFILE=1 \\\n-DWITH_PARTITION_STORAGE_ENGINE=1 \\\n-DEXTRA_CHARSETS=all \\\n-DDEFAULT_CHARSET=utf8 \\\n-DDEFAULT_COLLATION=utf8_general_ci\n-DWITH_SYSTEMD=1    #centos7.x\n#-j使用多线程编译\nmake -j8\nmake install\n```\n<!-- more -->\n### 添加用户和组\n``` bash\ngroupadd mysql\nuseradd -s /sbin/nologin -M -g mysql mysql\n#-s表示指定用户所用的shell，此处为/sbin/nologin，表示不登录。\n#-M表示不创建用户主目录。\n#-g表示指定用户的组名为mysql。\n#最后的mysql表示用户名\nchown -R mysql:mysql /data/program/mysql\n```\n\n\n\n### 初始化数据库\n``` bash\ncd /data/program/mysql\nscripts/mysql_install_db --basedir=/data/program/mysql --datadir=/data/program/mysql/data --user=mysql\ncp support-files/mysql.server /etc/init.d/mysql\n```\n### 设置开机启动\n``` bash\nchkconfig mysql on\nservice mysql start\n```\n\n### 设置环境变量\n\n### 安全设置\n``` bash\nmysql -uroot  \nmysql> SET PASSWORD = PASSWORD('123456');\nmysql> GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY '123456' WITH GRANT OPTION;\nmysql> flush privileges;\n# “%” 代表允许所有主机用root用户访问数据库\n#这里可以做严格限制，只要吧%修改为具体的IP或者主机名即可\n```\n\n","tags":["mysql"],"categories":["数据库"]},{"title":"mongo集群模式_Sharding","url":"%2F2016%2F04%2F19%2Fmongo%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F_Sharding%2F","content":"\n#### 说明\n\t和Replica Set类似，都需要一个仲裁节点，但是Sharding还需要配置节点和路由节点。就三种集群搭建方式来说，这种是最复杂的。部署图如下：\n![](http://www.machunpeng.cn/server/../Public/Uploads/2018-04-14/5ad0d799efc82.png)\n\n#### 启动数据节点\n\n```bash\n./mongod --fork --dbpath ../data/set1/ --logpath ../log/set1.log --replSet test #192.168.4.43\n./mongod --fork --dbpath ../data/set2/ --logpath ../log/set2.log --replSet test #192.168.4.44\n#决策 不存储数据  \n./mongod --fork --dbpath ../data/set3/ --logpath ../log/set3.log --replSet test #192.168.4.45\n```\n<!--more-->\n#### 启动配置节点\n\n```bash\n./mongod --configsvr --dbpath ../config/set1/ --port 20001 --fork --logpath ../log/conf1.log #192.168.4.30\n./mongod --configsvr --dbpath ../config/set2/ --port 20002 --fork --logpath ../log/conf2.log #192.168.4.31\n```\n#### 启动路由节点\n\n```bash\n./mongos --configdb 192.168.4.30:20001,192.168.4.31:20002 --port 27017 --fork --logpath ../log/root.log #192.168.4.29\n# 这里我们没有用配置文件的方式启动，其中的参数意义大家应该都明白。一般来说一个数据节点对应一个配置节点，仲裁节点则不需要对应的配置节点。注意在启动路由节点时，要将配置节点地址写入到启动命令里\n```\n#### 配置Replica Set\n\n```bash\n./mongo 192.168.4.43:27017   #ip和port是某个节点的地址\n>use admin\n>cfg={ _id:\"testrs\", members:[ {_id:0,host:'192.168.4.43:27017',priority:2},{_id:1,host:'192.168.4.44:27017',priority:1}, {_id:2,host:'192.168.4.45:27017',arbiterOnly:true}] };\n#使配置生效  \n>rs.initiate(cfg)\n\n#\n```\n#### 配置Sharding\n\n```bash\n  #这里必须连接路由节点\n./mongo 192.168.4.29:27017\n #test表示replica set的名字 当把主节点添加到shard以后，会自动找到set里的主，备，决策节点\n>sh.addShard(\"test/192.168.4.43:27017\")\n>db.runCommand({enableSharding:\"diameter_test\"})    #diameter_test is database name\n>db.runCommand( { shardCollection: \"diameter_test.dcca_dccr_test\",key:{\"__avpSessionId\":1}})\n\n# 第一个命令很容易理解，第二个命令是对需要进行Sharding的数据库进行配置，第三个命令是对需要进行Sharding的Collection进行配置，这里的dcca_dccr_test即为Collection的名字。另外还有个key，这个是比较关键的东西，对于查询效率会有很大的影响\n```","tags":["Sharding"],"categories":["数据库"]},{"title":"mongo的用户和授权","url":"%2F2016%2F04%2F18%2Fmongo%E7%9A%84%E7%94%A8%E6%88%B7%E5%92%8C%E6%8E%88%E6%9D%83%2F","content":"\n#### 进入mongo控制台\n\n```bash\n#mongodb安装好后第一次进入是不需要密码的，也没有任何用户，通过shell命令可直接进入，cd到mongodb目录下的bin文件夹，执行命令./mongo即可。运行如下：\n[root@namenode mongodb]# ./bin/mongo\nMongoDB shell version: 1.8.2\nconnecting to: test\n> use test;\nswitched to db test\n\n```\n#### 添加管理用户\n\n```bash\n#mongoDB 没有无敌用户root，只有能管理用户的用户 userAdminAnyDatabase\n>use admin\n>db.createUser( {user: \"admin\",pwd: \"123456\",roles: [ { role: \"userAdminAnyDatabase\", db: \"admin\" } ]})\n```\n<!--more-->\n#### 以认证模式重启数据库\n\n- 创建库并授权用户\n\n```bash\n#因为admin只有用户管理权限，下面创建用户，用户都跟着库走，所以在指定库里授权，必须也在指定库里验证\n> use admin\n> db.auth(\"admin\",\"123456\")   #认证，返回1表示成功\n> use mydb\n> db.createUser({user: \"root\",pwd: \"123456\",roles: [{ role: \"readWrite\", db: \"mydb\" }]})\n\n```\n#### 用创建的用户root登录进行数据库操作\n\n```bash\n[root@localhost mongodb]# mongo 127.0.0.1/mydb -uroot -p\nMongoDB shell version: 3.2.9\nEnter password:\nconnecting to: 127.0.0.1/mydb\n> db\nmydb\n> use mydb\nswitched to db mydb\n> show collections\n```\n\n#### mongo 的内置角色\n\n```bash\n#数据库用户角色：read、readWrite;\n#数据库管理角色：dbAdmin、dbOwner、userAdmin；\n#集群管理角色：clusterAdmin、clusterManager、clusterMonitor、hostManager；\n#备份恢复角色：backup、restore；\n#所有数据库角色：readAnyDatabase、readWriteAnyDatabase、userAdminAnyDatabase、dbAdminAnyDatabase\n#超级用户角色：root  \n#这里还有几个角色间接或直接提供了系统超级用户的访问（dbOwner 、userAdmin、userAdminAnyDatabase）\n #内部角色：__system\n \n#Read：允许用户读取指定数据库\n#readWrite：允许用户读写指定数据库\n#dbAdmin：允许用户在指定数据库中执行管理函数，如索引创建、删除，查看统计或访问system.profile\n#userAdmin：允许用户向system.users集合写入，可以找指定数据库里创建、删除和管理用户\n#clusterAdmin：只在admin数据库中可用，赋予用户所有分片和复制集相关函数的管理权限。\n#readAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读权限\n#readWriteAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读写权限\n#userAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的userAdmin权限\n#dbAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的dbAdmin权限。\n#root：只在admin数据库中可用。超级账号，超级权限\n```\n#### 创建超级用户\n\n```bash\n#有没有一个超级权限？不仅可以授权，而且也可以对集合进行任意操作？答案是肯定的，只是不建议使用。那就是role角色设置成root\nmongo>use admin\nmongo>db.auth(\"dba\",\"dba\")\nmongo>db.createUser( {user: \"admin\",pwd: \"admin\",roles: [{ role: \"root\", db: \"admin\" }]})\n\n#因为帐号都是在当前需要授权的数据库下授权的，那要是不在当前数据库下会怎么样？\n#在admin下创建的帐号，不能直接在其他库验证，\n#只能在帐号创建库下认证，再去其他库进行操作。\n```\n\n#### 查看全部账户\n\n```bash\n>  use admin\nswitched to db admin\n> db.auth('dba','dba')\n1\n> db.system.users.find().pretty()\n\n#查看用户总数\n>db.system.users.find().count()\n```","tags":["数据库授权"],"categories":["数据库"]},{"title":"mongo的集群模式_Replica Set","url":"%2F2016%2F04%2F18%2Fmongo%E7%9A%84%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F_Replica%20Set%2F","content":"\n#### 说明\n \n\t副本集模式集群，其实简单来说就是集群当中包含了多份数据，保证主节点挂掉了，备节点能继续提供数据服务，提供的前提就是数据需要和主节点一致。如下图\n![图](http://www.machunpeng.cn/server/../Public/Uploads/2018-04-13/5ad0d19122560.png)\n\n\tMongodb(M)表示主节点，Mongodb(S)表示备节点，Mongodb(A)表示仲裁节点。主备节点存储数据，仲裁节点不存储数据。客户端同时连接主节点与备节点，不连接仲裁节点。\n\n\t默认设置下，主节点提供所有增删查改服务，备节点不提供任何服务。但是可以通过设置使备节点提供查询服务，这样就可以减少主节点的压力，当客户端进行数据查询时，请求自动转到备节点上。这个设置叫做Read Preference Modes，同时Java客户端提供了简单的配置方式，可以不必直接对数据库进行操作。\n\n\t仲裁节点是一种特殊的节点，它本身并不存储数据，主要的作用是决定哪一个备节点在主节点挂掉之后提升为主节点，所以客户端不需要连接此节点。这里虽然只有一个备节点，但是仍然需要一个仲裁节点来提升备节点级别。我开始也不相信必须要有仲裁节点，但是自己也试过没仲裁节点的话，主节点挂了备节点还是备节点，所以咱们还是需要它的。\n\n\t介绍完了集群方案，那么现在就开始搭建了\n<!--more-->\n#### 安装Mongo 服务，所有节点\n\t略...\n\n#### 修改配置文件，所有节点\n\n```bash\ndbpath=/data/program/mongodb/data/\nlogpath=/data/program/mongodb/log/[master slave/arbiter] .log  \npidfilepath=/data/program/mongodb/[master slave/arbiter].pid  \ndirectoryperdb=true  \nlogappend=true  \nreplSet=testrs  \nbind_ip=10.10.148.130  \nport=27017  \noplogSize=10000  \nfork=true  \nnoprealloc=true  \n\n#三个节点的配置基本相同，除了文件路径和bind的IP不同\n#参数解释：\n#dbpath：数据存放目录\n#logpath：日志存放路径\n#pidfilepath：进程文件，方便停止mongodb\n#directoryperdb：为每一个数据库按照数据库名建立文件夹存放\n#logappend：以追加的方式记录日志\n#replSet：replica set的名字\n#bind_ip：mongodb所绑定的ip地址\n#port：mongodb进程所使用的端口号，默认为27017\n#oplogSize：mongodb操作日志文件的最大大小。单位为Mb，默认为硬盘剩余空间的5%\n#fork：以后台方式运行进程\n#noprealloc：不预先分配存储\n```\n#### 启动Mongo，所有节点\n\n```bash\n./monood -f mongo.conf  \n```\n#### 配置集群\n\n```bash\n#ip和port是某个节点的地址\n./mongo 127.0.0.1:27017\n>use admin\n>cfg={ _id:\"testrs\", members:[ {_id:0,host:'192.168.1.10:27017',priority:2}, {_id:1,host:'193.168.1.11:27017',priority:1},{_id:2,host:'192.168.1.12:27017',arbiterOnly:true}] };\n#使配置生效\n>rs.initiate(cfg)\n\n#cfg是可以任意的名字，当然最好不要是mongodb的关键字，conf，config都可以。最外层的_id表示replica set的名字，members里包含的是所有节点的地址以及优先级。优先级最高的即成为主节点，即这里的10.10.148.130:27017。特别注意的是，对于仲裁节点，需要有个特别的配置——arbiterOnly:true。这个千万不能少了，不然主备模式就不能生效\n```\n#### 完成","tags":["mongo replica set"],"categories":["数据库"]},{"title":"mongo的集群模式_Master-Slaver","url":"%2F2016%2F04%2F18%2Fmongo%E7%9A%84%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F_Master-Slaver%2F","content":"\n\t这个是最简答的集群搭建，不过准确说也不能算是集群，只能说是主备。并且官方已经不推荐这种方式，所以在这里只是简单的介绍下吧，搭建方式也相对简单。用法如下：\n```bash\n#主节点\n./mongod --master --dbpath /data/program/mongodb/\n备节点 \n./mongod --slave --source <masterip:masterport> --dbpath /data/program/mongodb/\n```","tags":["mongo master-slave"],"categories":["数据库"]},{"title":"mongo的常用操作","url":"%2F2016%2F04%2F18%2Fmongo%E7%9A%84%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F","content":"\n#### 备份\n\n```bash\n#用户密码要要有认证库的权限\nmongodump -h 主机名 -u 用户名 -p 密码 -d 库名 -o /data/backup/ --authenticationDatabase=库名\n```\n\n#### 恢复\n\n```bash\nmongorestore -h 主机名 -d 库名 --dir /data/backup/备份库目录 -u 用户名 -p 密码 --authenticationDatabase=库名\n```\n<!--more-->\n#### 导出JSON文件\n\n```bash\nmongoexport -u 用户名 -p 密码 -d 库名 -c 集合 -o 文件名.dat --authenticationDatabase=库名\n```\n#### 导入JSON文件\n\n```bash\nmongoimport --db 库名 -u 用户 -p 密码 --collection 集合名 --file 文件名.json --host 127.0.0.1:27017\n```\n#### 导入CSV\n\n```bash\nmongoimport -d 库名 -c 集合 --type csv -f 字段1,字段2,... --file 文件名.csv \n```\n#### 导出CSV\n\n```bash\nmongoexport -u 用户 -p 密码 -d 库名 -c 集合 --csv -f _id,name,userType,status -o 文件名.csv --authenticationDatabase=库名\n```\n#### 按条件导出csv\n\n```bash\nmongoexport -u 用户 -p 密码 -d 库名 -c 集合 --csv -f _id,name,userType,status -q '{\"a\":\"B\"}' -o 文件名.csv --authenticationDatabase=库名\n```\n\n#### 执行JS脚本\n\n```bash\nmongo -u 用户 -p 密码 127.0.0.1:27017/库名 文件名.js \n```\n\n#### 增删改差\n\n```bash\nmongo\n>user 库名\n>db.auth(\"库名\",\"密码\")\n>db.库名.find({\"key\":\"value\"})\n#删除库\n>db.dropDatabase()\n\n```\n#### 关闭Mongo\n\n```bash\nmongo>db.shutdownServer()\n```\n#### 查看已存在的用户\n\n```bash\n> db.system.users.find()\n```\n#### 删除用户\n\n```bash\n> use mydb\n> db.system.users.remove({user:\"root\"})\n> db.system.users.find()\n```","tags":["nosql"],"categories":["数据库"]},{"title":"mongo安装配置","url":"%2F2016%2F04%2F18%2Fmongo%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F","content":"#### 安装\n\tMongo的安装相对简单，官方给出的都是二进制包，下载解压即可，如下：\n\n```bash\n# 下载\ncurl -O https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.0.6.tgz    \n# 解压\ntar -zxvf mongodb-linux-x86_64-3.0.6.tgz                                   \n#移动到指定目录\nmv  mongodb-linux-x86_64-3.0.6/ /data/program/mongodb    \n```\n#### 配置环境变量\n\t略....\n<!--more-->\n\n#### 配置\n\n```yaml\n# 数据库文件位置\ndbpath=/data/program/mongodb/data/27017\n#日志文件位置\nlogpath=/data/program/mongodb/logs/mongodb.log\n# 以追加方式写入日志\nlogappend=true\n# 是否以守护进程方式运行\nfork = true\n# 默认27017\nport = 27017\n#noauth = true\n#auth = true\n#使用此设置来配置复制副本集。指定一个副本集名称作为参数，所有主机都必须有相同的名称作为同一个副本集\nreplSet=setname\n#指定存储身份验证信息的密钥文件的路径\nkeyFile=/data/program/mongodb/keyfile\n\n\n#以上为常规选项，以下为可选项\n\n#绑定地址，多个逗号隔开\n#bind_ip = 127.0.0.1\n最大连接数。默认值：取决于系统（即的ulimit和文件描述符）限制，注意：不能设置该值大于20000\nmaxConns = 10000\n#数据库分析等级设置0 关无分析，1 开仅包括慢操作，2 开包括所有操作。默认0:关闭\nprofile = 2\n#记录profile分析的慢查询的时间，默认是100毫秒,\nslowms  = 200\n#quota：配额，默认false。是否开启配置每个数据库的最多文件数的限制。当为true则用quotaFiles来配置最多文件的数量\nquota = true\n配额数量。每个数据库的数据文件数量的限制。此选项需要quota为true。默认为8\nquotaFiles = 8\n#rest： 默认false，设置为true，使一个简单的 REST API\n#设置为true，开启后，在MongoDB默认会开启一个HTTP协议的端口提供REST的服务（nohttpinterface = false），这个端口是你Server端口加上1000，即28017\n#默认的HTTP端口是数据库状态页面，（开启后，web页面的Commands 行中的命令都可以点进去）。mongodb自带的REST，不支持 增、删、改，同时也不支持 权限认证。\n详细信息见这里和这里\nrest = true\n#修复数据库操作，默认是false\n#设置为true时，启动后修复所有数据库，设置这个选项最好在命令行上，而不是在配置文件或控制脚本。如：\n命令行修复：\n> db.repairDatabase('xxx')\n{ \"ok\" : 1 }\n> db.repairDatabase()\n{ \"ok\" : 1 }\n#修复路径，默认是在dbpath路径下的_tmp 目录\nrepairpath =\n\n#是否使用较小的默认文件。默认为false，不使用。设置为true，使用较小的默认数据文件大小。smallfiles减少数据文件的初始大小，并限制他们到512M，也减少了日志文件的大小，并限制他们到128M。如果数据库很大，各持有少量的数据，会导致mongodb创建很多文件，会影响性能\nsmallfiles = true\n#syncdelay：刷写数据到日志的频率，通过fsync操作数据。默认60秒,默认就可以，不需要设置。不会对日志文件（journal files）有影响\nsyncdelay = 60\n#指定的复制操作日志（OPLOG）的最大大小。mongod创建一个OPLOG的大小基于最大可用空间量。对于64位系统，OPLOG通常是5％的可用磁盘空间\noplogSize=\n#master：默认为false，当设置为true，则配置当前实例作为主实例。\nmaster = true\n#slave：默认为false，当设置为true，则配置当前实例作为从实例。\nslave = true\n#source：默认为空，格式为：<host><:port>。用于从实例的复制：设置从的时候指定该选项会让从复制指定主的实例\nsource = 127.0.0.1:30001\n#only：默认为空，用于从选项，指定一个数据库进行复制。\nonly = abc          #只同步abc集合（库）\n#slavedelay：设置从库同步主库的延迟时间，用于从设置，默认为0。\nslavedelay = 60     #延迟60s同步主数据\n#autoresync：默认为false，用于从设置。是否自动重新同步。设置为true，如果落后主超过10秒，会强制从自动重新同步。如果oplogSize太小，此设置可能有问题。如果OPLOG大小不足以存储主的变化状态和从的状态变化之间的差异，这种情况下强制重新同步是不必要的。当设置autoresync选项设置为false，10分钟内从不会进行大于1次的自动重新同步。\nautoresync = false\n\n```","tags":["nosql"],"categories":["数据库"]},{"title":"mongo运行状态性能监控分析","url":"%2F2016%2F03%2F13%2F%20mongo%E8%BF%90%E8%A1%8C%E7%8A%B6%E6%80%81%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%88%86%E6%9E%90%2F","content":"\n#### 查看运行状态\n\tmongostat是mongdb自带的状态检测工具，在命令行下使用。它会间隔固定时间获取mongodb的当前运行状态，并输出。如果你发现数据库突然变慢或者有其他问题的话，你第一手的操作就考虑采用mongostat来查看mongo的状态。\n\t它的输出有以下几列：\n```bash\n\tinserts/s 每秒插入次数\n\tquery/s 每秒查询次数\n\tupdate/s 每秒更新次数\n\tdelete/s 每秒删除次数\n\tgetmore/s 每秒执行getmore次数\n\tcommand/s 每秒的命令数，比以上插入、查找、更新、删除的综合还多，还统计了别的命令\n\tflushs/s 每秒执行fsync将数据写入硬盘的次数。\n\tmapped/s 所有的被mmap的数据量，单位是MB，\n\tvsize 虚拟内存使用量，单位MB\n\tres 物理内存使用量，单位MB\n\tfaults/s 每秒访问失败数（只有Linux有），数据被交换出物理内存，放到swap。不要超过100，否则就是机器内存太小，造成频繁swap写入。此时要升级内存或者扩展\n\tlocked % 被锁的时间百分比，尽量控制在50%以下吧\n\tidx miss % 索引不命中所占百分比。如果太高的话就要考虑索引是不是少了\n\tq t|r|w 当Mongodb接收到太多的命令而数据库被锁住无法执行完成，它会将命令加入队列。这一栏显示了总共、读、写3个队列的长度，都为0的话表示mongo毫无压力。高并发时，一般队列值会升高。\n\tconn 当前连接数\n\ttime 时间戳\n```\n<!--more-->\n#### 打开慢日志，查看日志\n\n```bash\nmongo\n>use admin\n>db.auth(\"dba\",\"dba\")\n1\n>db.setProfilingLevel(2);\n{\"was\" : 0 , \"slowms\" : 100, \"ok\" : 1}\n>db.getProfilingLevel()\n2\n\n```\n#### 查看profile日志\n\n```bash\n>db.system.profile.find().sort({$natural:-1})\n{\"ts\" : \"Thu Jan 29 2009 15:19:32 GMT-0500 (EST)\" , \"info\" :\"query test.$cmd ntoreturn:1 reslen:66 nscanned:0 query: { profile: 2 } nreturned:1 bytes:50\" ,\"millis\" : 0} ...\n\n#3个字段的意义\n#ts：时间戳\n#info：具体的操作\n#millis：操作所花时间，毫秒\n\n#造成慢查询可能是索引的问题，也可能是数据不在内存造成因此磁盘读入造成\n```\n#### 使用Web控制台\nMongodb自带了Web控制台，默认和数据服务一同开启。他的端口在Mongodb数据库服务器端口的基础上加1000，如果是默认的Mongodb数据服务端口(Which is 27017)，则相应的Web端口为28017，这个页面可以看到：\n\n```bash\n当前Mongodb的所有连接\n各个数据库和Collection的访问统计，包括：Reads, Writes, Queries, GetMores ,Inserts, Updates, Removes\n写锁的状态\n以及日志文件的最后几百行（CentOS+10gen yum 安装的mongodb默认的日志文件位于/var/log/mongo/mongod.log)\n```\n#### 获取当前数据库的信息\n\n```bash\n> use admin\nswitched to db admin\n>db.auth(\"dba\",\"dba\")\n> db.stats()\n{\n\"collections\" : 9,\n \"objects\" : 4278845,\n\"avgObjSize\" : 224.56603031892953,\n\"dataSize\" : 960883236,\n\"storageSize\" : 1195438080,\n\"numExtents\" : 59,\n\"indexes\" : 13,\n\"indexSize\" : 801931264,\n\"fileSize\" : 6373244928,\n\"ok\" : 1\n```\n#### 获取服务器的状态\n\n```bash\n> use admin\nswitched to db admin\n>db.auth(\"dba\",\"dba\")\n> db.serverStatus()\n....\n\n#需要关心的地方：\n#connections 当前连接和可用连接数，听过一个同行介绍过，mongodb最大处理到2000个连接就不行了（要根据你的机器性能和业务来设定），所以设大了没意义。设个合理值的话，到达这个值mongodb就拒绝新的连接请求，避免被太多的连接拖垮。\n\n#indexCounters:btree:misses 索引的不命中数，和hits的比例高就要考虑索引是否正确建立。你看我的”missRatio” : 3.543930204420982e-7，很健康吧。所以miss率在mongostat里面也可以看\n\n#其他的都能自解释，也不是查看mongo健康状况的关键，就不说明了。\n\n```\n#### 获取当前正在执行的操作\n\tMongodb 的命令一般很快就完成，但是在一台繁忙的机器或者有比较慢的命令时，你可以通过db.currentOp()获取当前正在执行的操作。在没有负载的机器上，该命令基本上都是返回空的\n\n```bash\n>  db.currentOp()\n{ \"inprog\" : [ ] }\n\n#以下是一个有负载的机器上得到的返回值样例：\n{ \"opid\" : \"shard3:466404288\", \"active\" : false, \"waitingForLock\" : false, \"op\" : \"query\", \"ns\" : \"sd.usersEmails\", \"query\" : { }, \"client_s\" : \"10.121.13.8:34473\", \"desc\" : \"conn\" },\n\n#段名字都能自解释。如果你发现一个操作太长，把数据库卡死的话，可以用这个命令杀死他\n> db.killOp(\"shard3:466404288\")\n```\n#### Mongo监控\nMongoDB Monitoring Service(MMS)是Mongodb厂商提供的监控服务，可以在网页和Android客户端上监控你的MongoDB状况。\n","tags":["性能分析"],"categories":["数据库"]},{"title":"linux下TCP状态的统计分析","url":"%2F2015%2F10%2F18%2Flinux%E4%B8%8BTCP%E7%8A%B6%E6%80%81%E7%9A%84%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%2F","content":"\n#### 查看TCP连接状态\n\n```bash\nnetstat -nat |awk '{print $6}'|sort|uniq -c|sort -rn\nnetstat -n | awk '/^tcp/ {++S[$NF]};END {for(a in S) print a, S[a]}'或\nnetstat -n | awk '/^tcp/ {++state[$NF]}; END {for(key in state) print key,\"t\",state[key]}'\nnetstat -n | awk '/^tcp/ {++arr[$NF]};END {for(k in arr) print k,\"t\",arr[k]}'\nnetstat -n | awk '/^tcp/ {print $NF}'|sort|uniq -c|sort -rn\nnetstat -ant | awk '{print $NF}' | grep -v '[a-z]' | sort | uniq -c\n```\n<!--more-->\n#### 查找请求数请20个IP(常用于查找攻来源)\n\n```bash\nnetstat -anlp|grep 80|grep tcp|awk '{print $5}'|awk -F: '{print $1}'|sort|uniq -c|sort -nr|head -n20\nnetstat -ant |awk '/:80/{split($5,ip,\":\");++A[ip[1]]}END{for(i in A) print A[i],i}' |sort -rn|head -n20\n```\n\n#### 用tcpdump嗅探80端口的访问看看谁最高\n\n```bash\ntcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F\".\" '{print $1\".\"$2\".\"$3\".\"$4}' | sort | uniq -c | sort -nr |head -20\n```\n\n#### 查找较多time_wait连接\n\n```bash\nnetstat -n|grep TIME_WAIT|awk '{print $5}'|sort|uniq -c|sort -rn|head -n20\n```\n\n#### 找查较多的SYN连接\n\n```bash\nnetstat -an | grep SYN | awk '{print $5}' | awk -F: '{print $1}' | sort | uniq -c | sort -nr | more\n```\n\n#### 根据端口列进程\n\n```bash\nnetstat -ntlp | grep 80 | awk '{print $7}' | cut -d/ -f1\n``` ","tags":["工具"],"categories":["linux"]},{"title":"gitignore文件不生效问题","url":"%2F2015%2F10%2F12%2Fgitignore%E6%96%87%E4%BB%B6%E4%B8%8D%E7%94%9F%E6%95%88%E9%97%AE%E9%A2%98%2F","content":"\n\n\t在git使用过程中有时会遇到修改了.gitignore文件，修改了之后发现，不能起作用，这是因为git存在缓存问题，所以做一下步骤即可：\n\n\tgit rm -r --cached .\n\tgit add .\n\tgit commit -m \"update gitignore\"","tags":["git"],"categories":["代码托管"]},{"title":"linux三剑客之grep","url":"%2F2015%2F10%2F08%2Flinux%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bgrep%2F","content":"\n#### grep常用参数\n\n```bash\ngrep [OPTIONS] PATTERN [FILE...]\ngrep [OPTIONS] [-e PATTERN]...  [-f FILE]...  [FILE...]\n\nOPTIONS:\n-e: 使用正则搜索\n-i: 不区分大小写\n-v: 查找不包含指定内容的行\n-w: 按单词搜索\n-c: 统计匹配到的次数\n-n: 显示行号\n-r: 逐层遍历目录查找\n-l:显示匹配的文件名\n-A: 显示匹配行及前面多少行, 如: -A3, 则表示显示匹配行及前3行\n-B: 显示匹配行及后面多少行, 如: -B3, 则表示显示匹配行及后3行\n-C: 显示匹配行前后多少行,   如: -C3, 则表示显示批量行前后3行\n--color: 匹配到的内容高亮显示\n--include: 指定匹配的文件类型\n--exclude: 过滤不需要匹配的文件类型\n```\n<!--more-->\n#### 用例\n\n```bash\n#多文件查询\ngrep leo logs.log logs_back.log\n#查找即包含leo又包含li的行\ngrep leo logs.log | grep li\n#查找匹配leo或者匹配li的行\ngrep leo | li logs.log\n#显示匹配行前2行\ngrep leo logs.log -A2\n#显示匹配行后2行\ngrep leo logs.log -B2\n#显示匹配行前后2行\ngrep leo logs.log -C2\n#不区分大小写\ngrep -i leo logs.log\n#使用正则表达式\ngrep -e '[a-z]\\{5\\}' logs.log\n#查找不包含leo的行\ngrep -v leo logs.log\n#统计包含leo的行数\ngrep -c leo logs.log\n#遍历当前目录及所有子目录查找匹配leo的行\ngrep -r leo .\n#在当前目录及所有子目录查找所有java文件中查找leo\ngrep -r leo . --include \"*.java\"\n#查找并输出到指定文件\ngrep leo logs.log > result.log\n#查找以leo开头的行\ngrep ^leo logs.log\n#查找以leo结尾的行\ngrep leo$ logs.log\n#查找空行\ngrep ^$ logs.log\n#包含变量内容的行, 注意必须用双引号, 单引号则无法引用变量\ngrep \"$LOGNAME\" file\n#打印包含字符$name的行.\ngrep '$name' file\n\n#包含以Tommy开头的行\ngrep '^Tommy' file \n#包含以.bak结束的行\ngrep '\\.bak$' file \n#包含pyramid 或Pyramid的单词的行\ngrep '[Pp]yramid' file \n#包含至少一个大写字母的行\ngrep '[A-Z]' file \n包含至少一个数字的行\ngrep '[0-9]' file \n包含五个字符,以大写开头, 和一个数字结尾的行.\ngrep '[A-Z]...[0-9]' file \n```\n\n#### egrep 与 grep -E\n\n```bash\negrep = grep -E 可以使用基本的正则表达外, 还可以用扩展表达式. 注意区别.\n#扩展表达式:\n+ 匹配一个或者多个先前的字符, 至少一个先前字符.\n? 匹配0个或者多个先前字符.\na|b|c 匹配a或b或c\n() 字符组, 如: love(able|ers) 匹配loveable或lovers.\n(..)(..)\\1\\2 模板匹配. \\1代表前面第一个模板, \\2代第二个括弧里面的模板.\nx{m,n} =x\\{m,n\\} x的字符数量在m到n个之间.```","tags":["grep"],"categories":["linux"]},{"title":"linux三剑客之sed","url":"%2F2015%2F10%2F08%2Flinux%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bsed%2F","content":"\n#### 简介\n\tsed是一个很好的文件处理工具，本身是一个管道命令，主要是以行为单位进行处理，可以将数据行进行替换、删除、新增、选取等特定工作，下面先了解一下sed的用法\n\n#### sed命令行格式为：\n\n```bash\nsed [ 选项 ] ‘editing command’ [file ...] \nsed [ -f ] filename ... [file ...]\n```\n#### 常用选项：\n\n```bash\n-n∶使用安静(silent)模式。在一般 sed 的用法中，所有来自 STDIN的资料一般都会被列出到萤幕上。但如果加上 -n 参数后，则只有经过sed 特殊处理的那一行(或者动作)才会被列出来。\n-e∶直接在指令列模式上进行 sed 的动作编辑；\n-f∶直接将 sed 的动作写在一个档案内， -f filename 则可以执行 filename 内的sed 动作；\n-r∶sed 的动作支援的是延伸型正规表示法的语法。(预设是基础正规表示法语法)\n-i∶直接修改读取的档案内容，而不是由萤幕输出。 \n ```\n <!--more-->\n \n#### 常用命令： \n```bash\na ∶新增， a 的后面可以接字符串，而这些字符串会在目前的下一行出现。 \nc ∶取代， c 的后面可以接字符串，这些字符串可以取代 n1,n2 之间的行。 \nd ∶删除，后面不接任何东西； \ni ∶插入， 与a只有一点不同，增加的字符串会在目前的上一行出现； \np ∶列印，亦即将某个选择的资料印出。在使用p的时候一般会加上-n参数。 \ns ∶取代，可以直接进行取代的工作。\n```\n#### 用例\n\n```bash\n#a∶新增， a 的后面可以接字符串，而这些字符串会在目前的下一行出现。\n#增加一行或多行字符串\ncat filename\nHello!\nworld!\n end\n#第一行后增加字符串\"people\"\nsed '1a people' filename  \nHello!\npeople\nworld! \nend\n#第一行到第三行后增加字符串\"people\"\nsed '1,3a people' filename \nHello!\npeople\nworld!\npeople\nend\npeople\n#插入\n#在文件filename中最后一行直接输入\"bye\"\nsed -i '$a bye' filename         \ncat filename\nHello!\nworld!\nend\nbye\n```\n```bash\n#i ∶插入， 与a只有一点不同，增加的字符串会在目前的上一行出现；\nsed '1i people\\nperson' filename   第一行前增加多行，使用换行符\\n\npeople\nperson\nHello!\nworld!\nend\n```\n```bash\n#c∶取代， c 的后面可以接字符串，这些字符串可以取代 n1,n2 之间的行。\n#代替一行或多行\n#第一行代替为Hi\n sed '1c Hi' filename\nHi\nworld!\nend\n#第一行到第二行代替为Hi\nsed '1,2c Hi' filename\nHi\nend\n```\n```bash\n#d∶删除，后面不接任何东西；\n#删除某行\n#删除第一行\nsed '1d' filename\n#删除最后一行\nsed '$ d' filename\n#删除第一行到第二行\nsed '1,2d' filename\n#删除第二行到最后一行\nsed '2,$ d' filename\n#若匹配字符串是变量，则需要\"\"\nsed -i '/匹配字符串/d'  filename\n```\n```bash\n#p∶列印，亦即将某个选择的资料印出。在使用p的时候一般会加上-n参数。\n#显示某行\n#显示第一行\nsed -n '1p' filename\n#显示最后一行\nsed -n '$ p' filename\n#显示第一行到第二行\nsed -n '1,2p' filename\n#显示第二行到最后一行\nsed -n '2,$ p' filename\n#使用模式进行查询\n#查询包括关键字world所在所有行\nsed -n '/world/p' filename\n#查询包括关键字$ 所在所有行，使用反斜线\\屏蔽特殊含义\nsed -n '/\\$ /p' filename\n```\n```bash\n#s ∶取代，可以直接进行取代的工作。\n#替换一行中的某部分\n#格式：sed 's/要替换的字符串/新的字符串/g'   （要替换的字符串可以用正则表达式）\nsed -n '/world/p' filename | sed 's/world/me/g'    替换world为me\nsed -n '/world/p' filename | sed 's/world//g'        删除world\n#替换匹配行中的某个字符串\nsed -i '/匹配字符串/s/替换源字符串/替换目标字符串/g' filename\n```","tags":["sed"],"categories":["linux"]},{"title":"linux三剑客之awk","url":"%2F2015%2F10%2F08%2Flinux%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8Bawk%2F","content":"\n#### 简介\n\tAWK是一种处理文本文件的语言，是一个强大的文本分析工具。之所以叫AWK是因为其取了三位创始人 Alfred Aho，Peter Weinberger, 和 Brian Kernighan 的Family Name的首字符。\n\n#### 语法\n\n```bash\nawk [选项参数] 'script' var=value file(s)\n或\nawk [选项参数] -f scriptfile var=value file(s)\n```\n<!--more-->\n#### 选项参数说明\n\n```bash\n-F fs or --field-separator fs\n指定输入文件折分隔符，fs是一个字符串或者是一个正则表达式，如-F:。\n-v var=value or --asign var=value\n赋值一个用户定义变量。\n-f scripfile or --file scriptfile\n从脚本文件中读取awk命令。\n-mf nnn and -mr nnn\n对nnn值设置内在限制，-mf选项限制分配给nnn的最大块数目；-mr选项限制记录的最大数目。这两个功能是Bell实验室版awk的扩展功能，在标准awk中不适用。\n-W compact or --compat, -W traditional or --traditional\n在兼容模式下运行awk。所以gawk的行为和标准的awk完全一样，所有的awk扩展都被忽略。\n-W copyleft or --copyleft, -W copyright or --copyright\n打印简短的版权信息。\n-W help or --help, -W usage or --usage\n打印全部awk选项和每个选项的简短说明。\n-W lint or --lint\n打印不能向传统unix平台移植的结构的警告。\n-W lint-old or --lint-old\n打印关于不能向传统unix平台移植的结构的警告。\n-W posix\n打开兼容模式。但有以下限制，不识别：/x、函数关键字、func、换码序列以及当fs是一个空格时，将新行作为一个域分隔符；操作符**和**=不能代替^和^=；fflush无效。\n-W re-interval or --re-inerval\n允许间隔正则表达式的使用，参考(grep中的Posix字符类)，如括号表达式[[:alpha:]]。\n-W source program-text or --source program-text\n使用program-text作为源代码，可与-f命令混用。\n-W version or --version\n打印bug报告信息的版本。\n\n```\n#### 基本用法\n\n```bash\n#log.txt文本内容如下：\n\n2 this is a test\n3 Are you like awk\nThis's a test\n10 There are orange,apple,mongo\n```\n\n```bash\n用法一：\nawk '{[pattern] action}' {filenames}   # 行匹配语句 awk '' 只能用单引号\n实例：\n# 每行按空格或TAB分割，输出文本中的1、4项\n awk '{print $1,$4}' log.txt\n ---------------------------------------------\n 2 a\n 3 like\n This's\n 10 orange,apple,mongo\n # 格式化输出\nawk '{printf \"%-8s %-10s\\n\",$1,$4}' log.txt\n ---------------------------------------------\n 2        a\n 3        like\n This's\n 10       orange,apple,mongo\n```\n\n```bash\n#用法二：\nawk -F  #-F相当于内置变量FS, 指定分割字符\n#实例：\n# 使用\",\"分割\nawk -F, '{print $1,$2}'   log.txt\n ---------------------------------------------\n 2 this is a test\n 3 Are you like awk\n This's a test\n 10 There are orange apple\n# 或者使用内建变量\nawk 'BEGIN{FS=\",\"} {print $1,$2}'     log.txt\n ---------------------------------------------\n 2 this is a test\n 3 Are you like awk\n This's a test\n 10 There are orange apple\n# 使用多个分隔符.先使用空格分割，然后对分割结果再使用\",\"分割\nawk -F '[ ,]'  '{print $1,$2,$5}'   log.txt\n ---------------------------------------------\n 2 this test\n 3 Are awk\n This's a\n 10 There apple\n```\n\n```bash\n#用法三：\nawk -v  # 设置变量\n#实例：\nawk -va=1 '{print $1,$1+a}' log.txt\n ---------------------------------------------\n 2 3\n 3 4\n This's 1\n 10 11\nawk -va=1 -vb=s '{print $1,$1+a,$1b}' log.txt\n ---------------------------------------------\n 2 3 2s\n 3 4 3s\n This's 1 This'ss\n 10 11 10s\n```\n```bash\n#用法四：\nawk -f {awk脚本} {文件名}\n#实例：\nawk -f cal.awk log.txt\n```\n\n#### 运算符\n\n|运算符|描述|\n|----------|----------|\n|= += -= *= /= %= ^= **=|赋值|\n|?:\t|C条件表达式|\n||\t逻辑或|\n|&&\t|逻辑与|\n|~ ~!|匹配正则表达式和不匹配正则表达式|\n|< <= > >= != ==|关系运算符|\n|空格|连接|\n|+ -|加，减|\n|* / %|乘，除与求余|\n|+ - !|一元加，减和逻辑非|\n|^ ***|求幂|\n|++ --|增加或减少，作为前缀或后缀|\n|$|字段引用|\n|in|数组成员|\n\n```bash\n#过滤第一列大于2的行\nawk '$1>2' log.txt    #命令\n#输出\n3 Are you like awk\nThis's a test\n10 There are orange,apple,mongo\n#过滤第一列等于2的行\nawk '$1==2 {print $1,$3}' log.txt    #命令\n#输出\n2 is\n#过滤第一列大于2并且第二列等于'Are'的行\nawk '$1>2 && $2==\"Are\" {print $1,$2,$3}' log.txt    #命令\n#输出\n3 Are you\n```\n\n#### 内建变量\n\n|变量|描述|\n|-------|-------|\n|\\$n|当前记录的第n个字段，字段间由FS分隔|\n|\\$0|完整的输入记录|\n|ARGC|命令行参数的数目|\n|ARGIND|命令行中当前文件的位置(从0开始算)|\n|ARGV|包含命令行参数的数组|\n|CONVFMT|数字转换格式(默认值为%.6g)ENVIRON环境变量关联数组|\n|ERRNO|最后一个系统错误的描述|\n|FIELDWIDTHS|字段宽度列表(用空格键分隔)|\n|FILENAME|当前文件名|\n|FNR|各文件分别计数的行号|\n|FS|字段分隔符(默认是任何空格)|\n|IGNORECASE|如果为真，则进行忽略大小写的匹配|\n|NF|一条记录的字段的数目|\n|NR|已经读出的记录数，就是行号，从1开始|\n|OFMT|数字的输出格式(默认值是%.6g)|\n|OFS|输出记录分隔符（输出换行符），输出时用指定的符号代替换行符|\n|ORS|输出记录分隔符(默认值是一个换行符)|\n|RLENGTH|由match函数所匹配的字符串的长度|\n|RS\t|记录分隔符(默认是一个换行符)|\n|RSTART|由match函数所匹配的字符串的第一个位置|\n|SUBSEP|数组下标分隔符(默认值是/034)|\n\n```bash\nawk 'BEGIN{printf \"%4s %4s %4s %4s %4s %4s %4s %4s %4s\\n\",\"FILENAME\",\"ARGC\",\"FNR\",\"FS\",\"NF\",\"NR\",\"OFS\",\"ORS\",\"RS\";printf \"---------------------------------------------\\n\"} {printf \"%4s %4s %4s %4s %4s %4s %4s %4s %4s\\n\",FILENAME,ARGC,FNR,FS,NF,NR,OFS,ORS,RS}'  log.txt\nFILENAME ARGC  FNR   FS   NF   NR  OFS  ORS   RS\n---------------------------------------------\nlog.txt    2    1         5    1\nlog.txt    2    2         5    2\nlog.txt    2    3         3    3\nlog.txt    2    4         4    4\nawk -F\\' 'BEGIN{printf \"%4s %4s %4s %4s %4s %4s %4s %4s %4s\\n\",\"FILENAME\",\"ARGC\",\"FNR\",\"FS\",\"NF\",\"NR\",\"OFS\",\"ORS\",\"RS\";printf \"---------------------------------------------\\n\"} {printf \"%4s %4s %4s %4s %4s %4s %4s %4s %4s\\n\",FILENAME,ARGC,FNR,FS,NF,NR,OFS,ORS,RS}'  log.txt\nFILENAME ARGC  FNR   FS   NF   NR  OFS  ORS   RS\n---------------------------------------------\nlog.txt    2    1    '    1    1\nlog.txt    2    2    '    1    2\nlog.txt    2    3    '    2    3\nlog.txt    2    4    '    1    4\n# 输出顺序号 NR, 匹配文本行号\nawk '{print NR,FNR,$1,$2,$3}' log.txt\n---------------------------------------------\n1 1 2 this is\n2 2 3 Are you\n3 3 This's a test\n4 4 10 There are\n# 指定输出分割符\nawk '{print $1,$2,$5}' OFS=\" $ \"  log.txt\n---------------------------------------------\n2 $ this $ test\n3 $ Are $ awk\nThis's $ a $\n10 $ There $\n```\n\n#### 使用正则，字符串匹配\n\n```bash\n# 输出第二列包含 \"th\"，并打印第二列与第四列\nawk '$2 ~ /th/ {print $2,$4}' log.txt\n---------------------------------------------\nthis a\n#~ 表示模式开始。// 中是模式。\n\n# 输出包含\"re\" 的行\nawk '/re/ ' log.txt\n---------------------------------------------\n3 Are you like awk\n10 There are orange,apple,mongo\n\n#忽略大小写\nawk 'BEGIN{IGNORECASE=1} /this/' log.txt\n---------------------------------------------\n2 this is a test\nThis's a test\n\n#模式取反\nawk '$2 !~ /th/ {print $2,$4}' log.txt\n---------------------------------------------\nAre like\na\nThere orange,apple,mongo\nawk '!/th/ {print $2,$4}' log.txt\n---------------------------------------------\nAre like\na\nThere orange,apple,mongo\n```\n\n#### awk脚本\n\n```bash\n#关于awk脚本，我们需要注意两个关键词BEGIN和END。\n#BEGIN{ 这里面放的是执行前的语句 }\n#END {这里面放的是处理完所有的行后要执行的语句 }\n#{这里面放的是处理每一行时要执行的语句}\n#假设有这么一个文件（学生成绩表）：\ncat score.txt\nMarry   2143 78 84 77\nJack    2321 66 78 45\nTom     2122 48 77 71\nMike    2537 87 97 95\nBob     2415 40 57 62\n\n\n\n#我们的awk脚本如下：\ncat cal.awk\n#!/bin/awk -f\n#运行前\nBEGIN {\n    math = 0\n    english = 0\n    computer = 0\n \n    printf \"NAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL\\n\"\n    printf \"---------------------------------------------\\n\"\n}\n#运行中\n{\n    math+=$3\n    english+=$4\n    computer+=$5\n    printf \"%-6s %-6s %4d %8d %8d %8d\\n\", $1, $2, $3,$4,$5, $3+$4+$5\n}\n#运行后\nEND {\n    printf \"---------------------------------------------\\n\"\n    printf \"  TOTAL:%10d %8d %8d \\n\", math, english, computer\n    printf \"AVERAGE:%10.2f %8.2f %8.2f\\n\", math/NR, english/NR, computer/NR\n}\n\n\n#我们来看一下执行结果\nawk -f cal.awk score.txt\nNAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL\n---------------------------------------------\nMarry  2143     78       84       77      239\nJack   2321     66       78       45      189\nTom    2122     48       77       71      196\nMike   2537     87       97       95      279\nBob    2415     40       57       62      159\n---------------------------------------------\n  TOTAL:       319      393      350\nAVERAGE:     63.80    78.60    70.00\n```\n\n","tags":["awk"],"categories":["linux"]},{"title":"Ansible实现批量化管理","url":"%2F2015%2F08%2F11%2FAnsible%E5%AE%9E%E7%8E%B0%E6%89%B9%E9%87%8F%E5%8C%96%E7%AE%A1%E7%90%86%2F","content":"\n\n#### 简介\nansible是一个基于python开发的自动化运维工具！（saltstack）\n其功能的实现是基础SSH远程连接服务的\nansible可以实现批量系统配置、批量软件部署、批量文件拷贝、批量运行命令等功能\n不需要单独安装客户端，基于ssh服务\n不需要安装服务端\n需要依靠大量的模块实现批量部署\n配置文件/etc/ansible/ansible.cfg\n<!--more-->\n\n#### 安装\n\n```bash\n#使用yum安装\nyum install epel-release -y\nyum install ansible –y\n\n#使用pip（python的包管理模块）安装\npip install ansible\n#如果没pip,需先安装pip.yum可直接安装：\nyum install python-pip\npip install ansible\n\n#源码安装\ngit clone git://github.com/ansible/ansible.git --recursive\ncd ./ansible\nsource ./hacking/env-setup\n```\n#### ansible命令集\n\n```bash\nansible                      # 定义ansible 单任务\nansible-config               # 查看、编辑、管理Ansible配置\nansible-doc                  # 文档查看工具\nansible-galaxy               # 共享、下载roles的工具\nansible-inventory       　　  # 查看Inventory主机信息\nansible-playbook        　　　# 执行playbook\nansible-pull                 # 仓库中拉去playbook\nansible-vault                # 文件加密、解密工具\nansible-console              # ansible 控制台\n```\n#### 主要配置文件\n\n```bash\n#Ansible 配置文件\n/etc/ansible/ansible.cfg\n#主机清单\n/etc/ansible/hosts\n#角色路径\n/etc/ansible/roles/\n```\n#### Ansible Inventory\n\n```bash\n#实际过程中我们需要管理不同业务，不同环境中的各种服务器资源，这些服务器的信息主要存储在Inventory 组件里面，ansible.cfg中默认定义配置文件的路径/etc/ansible/hosts;\n#下面我们来/etc/ansible/hosts 文件中定义主机和主机组\n# Ex 1: 定义主机\n192.168.100.10\n# Ex 2:定义 'WebServers' 主机组\n[WebServers]\n10.172.139.53\n10.30.49.72\n10.30.49.[1:10]    # 一组类似IP地址简写模式\n#说明：方括号[]中表示的组名字，主要用于不同类别的系统进行分类，便于对同一类的服务器资源进行管理；\n\n#主机和主机组变量\n# 定义主机变量\n#定义ssh远程端口\n10.30.49.72  ansible_port='61821'\n\n# 定义主机组变量\n# 下面的变量属于整个WebServers组\n[WebServers:vars]\nansible_ssh_pass='ansible'\nansible_ssh_port='61821'\n\n#组的包含于组内变量\n[shenzhen]\nhost1\nhost2\n[guangzhou]\nhost3\nhost4\n[guangdong:children]\nshenzhen\nguangzhou\n[guangdong:vars]\ntomcat=192.168.8.8\nnginx=192.168.8.66\napache=192.168.8.77\nzabbix=192.168.8.88\n[china:children]\nguangdong\nbeijing\nshanghai\n#说明：上面我指定了深圳组有host1、host2；广州组有host3、host4，我又指定了广东组，同时包含深圳和广州；同时为该组内的所有主机指定了四个vars变量。后面我又设定了一个中国组，包含广东、北京、上海\n\n#Inventory 常用参数说明\nansible_ssh_host  # 连接的远程主机名.\nansible_ssh_port  # SSH远程连接端口,非标准端口设置.\nansible_ssh_user  # SSH远程连接用户名\nansible_ssh_pass  # SSH远程连接账号对应密码 (这种方式并容易泄露密码信息，建议使用 --ask-pass或者SSH认证)\nansible_sudo_pass # sudo用户密码(这种方式并容易泄露密码信息,烈建议使用 --ask-sudo-pass)\n```\n#### 配置公私钥\n\n```bash\n#配置这个的原因是为了方便ansible可以实现无秘访问控制其他机器，是实现自动化的前提。这一步可以再配置好ansible.cfg文件以及hosts主机清单后执行。\n\n#首先生成秘钥\n##执行下条指令后一路回车即可！\n[root@CentOS7-master ~]# ssh-keygen -t rsa\n#然后向主机分发秘钥：\n#所有添加到主机清单中的IP地址或者主机名，全部都要用下条指令执行一遍。\n[root@CentOS7-master ~]# ssh-copy-id root@主机名或IP地址\n\n#如果出现以下情况：\nssh-copy-id -i ~/.ssh/id_rsa.pub root@10.1.6.72\nbash: ssh-copy-id: command not found\n#请尝试：\nyum -y install openssh-clients\n```\n\n#### 命令详解\n\n```bash\n#命令格式：\nansible <host-pattern> [-f forks] [-m module_name] [-a args]\n\n#本段中所有以“**”开头的参数，均表示是重要的\n\n#模块的参数,如果执行默认COMMAND的模块，即是命令参数,如：“date”,“pwd”等等 module arguments 模块参数\n** -a MODULE_ARGS, --args=MODULE_ARGS\n#登录密码，提示输入SSH密码而不是假设基于密钥的验证\n-k, --ask-pas\n#su切换密码\n--ask-su-pass\n#提示密码使用sudo,sudo表示提权操作\n-K, --ask-sudo-pass \n--ask-vault-pass \n    ask for vault password\n#后台运行超时时间\n-B SECONDS, --background=SECONDS \n#只是测试一下会改变什么内容，不会真正去执行;相反,试图预测一些可能发生的变化\n** -C, --check\n#连接类型使用\n-c CONNECTION, --connection=CONNECTION\n#并行任务数。NUM被指定为一个整数,默认是5 \n** -f FORKS, --forks=FORKS\n-h, --help \n#指定库存主机文件的路径,默认为/etc/ansible/hosts\n** -i INVENTORY, --inventory-file=INVENTORY\n** --list-hosts\n#执行模块的名字，默认使用 command 模块，所以如果是只执行单一命令可以不用 -m参数\n** -m MODULE_NAME, --module-name=MODULE_NAME\n#要执行的模块的路径，默认为/usr/share/ansible/\n-M MODULE_PATH, --module-path=MODULE_PATH\n#压缩输出，摘要输出.尝试一切都在一行上输出。\n-o, --one-line\n#调查背景工作每隔数秒。需要- b\n-P POLL_INTERVAL, --poll=POLL_INTERVAL\n#私钥路径，使用这个文件来验证连接\n--private-key=PRIVATE_KEY_FILE\n#用 su 命令\n** -S, --su\n#指定SU的用户，默认是root用户\n** -R SU_USER, --su-user=SU_USER\n** -s, --sudo\n    run operations with sudo (nopasswd)\n#sudo到哪个用户，默认为 root\n** -U SUDO_USER, --sudo-user=SUDO_USER\n#指定SSH默认超时时间， 默认是10S\n** -T TIMEOUT, --timeout=TIMEOUT\n#将日志内容保存在该输出目录,结果保存在一个文件中在每台主机上。\n-t TREE, --tree=TREE\n#远程用户， 默认是root用户\n** -u REMOTE_USER, --user=REMOTE_USER\n--vault-password-file=VAULT_PASSWORD_FILE\n#输出ansible的版本\n** -v, --verbose\n--version\n```\n#### 常用模块命令\n\n```bash\n#command模块实践：（默认模块）\n\nansible george -m command -a \"ifconfig\"\n#批量显示远程主机的网卡信息\nansible george -m commadn -a \"chair=/tmp touch kai.txt\"\n#批量切换到远程主机的/tmp目录下，创建kai.txt这个文件\nansible george -m command -a \"creates=/tmp/kai touch /tmp/kai\"\n#批量判断远程主机/tmp下有没有kai这个文件，如果有就skip，没有就执行后面的命令\nansible george -m command -a \"removes=/tmp/kai.txt touch /tmp/123.txt\"\n#批量判断远程主机/tmp下有没有kai这个文件，如果有就执行后面的命令， 没有就skip\nansible george -m command -a \"ls -l\"\n#free_from（默认参数）可以输入任何系统命令信息，但是不包含一些特殊环境变量和特殊符号信息,如：<>,|;&\n\n#ping模块实践：\nansible george -m ping\n#返回pong，说明可以登录SSH连接，这里ping但不是测试网络连通性的,用于验证能否登录SSH连接，在查  看是否满足python的支持, 属于system模块\n\n\n#copy模块实践\n#1）copy参数src\n\nansible george -m copy -a \"src=/etc/hosts dest=/tmp/\"\n#将本机/etc/hosts文件复制到远程主机的/tmp目录下（如果/tmp下已有同名hosts，那么会被覆盖）\nansible george -m copy -a \"src=/etc/hosts dest=/tmp/dir/\"\n#如果远程主机没有dir目录，那么会创建dir目录\nansible george -m copy -a \"src=/etc/hosts dest=/tmp/1/2/3/4/\"\n#但传输文件时，如果上级目录不存在，则不会创  建，传输就无法成功\nansible george -m copy -a \"src=/tmp dest=/tmp/1/2/3/4\"\n#传输目录时，如果远程主机目录不存在，传输时可以创建多层目录，\n#如果传输的是目录本身及下面内容，后面不要加/\nansible george -m copy -a \"src=/tmp dest=/tmp/1/2/3/4\"\n#如果传输的是目录下面的内容，后面必须加/\nansible george -m copy -a \"remote_src=true src=/etc/hosts dest=/tmp/1/2/\"\n#批量操作远程主机，对他们本机上的文件进行本地操作\n#设置为true时（默认为flase），不支持递归复制\n\n#2）copy参数backup=yes  \n ansible george -m copy -a \"src=/etc/hosts dest=/etc/ backup=yes\"\n# 分发文件时，如果与远程主机下hosts文件内容不一致，那么会备份源文件为\"hosts.5714...以时间戳命名   \"，   在修改hosts源文件的内容\n#不输入默认backup=no，就是不备份，会覆盖源文件\n \n#3）copy参数mode、owner、group\nansible george -m copy -a \"src=/etc/hosts dest=/tmp/ mode=0600 owner=george group=george\"\n#改变文件的权限为0600，所有者和属组为george\n\n#4） copy参数force\nansible george -m copy -a \"src=/etc/hosts dest=/tmp/ force=yes\"\n#默认为forec=yes，如果和远程主机信息不一致，会覆盖\n#如果force=no，那么远程主机同名文件不会做改变\n \n#5）copy参数content  \nansible george -m copy -a \"content=123123 dest=/tmp/hosts\"\n#写入信息到/tmp/ hosts中会把源内容覆盖掉，谨慎操作，只能添加少量的信息\n#添加多量的，可以用template模块\n\n#shell模块实践  \nansible george -m shell -a \"hostname;hostname -i\"\n# 支持特殊符号，-a里面可接多个名，用分号分割\n#测试:用shell执行一个脚本很麻烦的，用script执行\n#1）推送脚本过去，并授权\nansible george -m copy -a \"src=/tmp/test.sh dest=/tmp mode=+x\"\n#2）运行脚本\nansible george -m shell -a \"/tmp/test.sh\"\n\n#script模块实践  \nansible george -m script -a \"/server/scritps/keepalived.sh\"\n#将本地脚本中的信息，在远程主机上执行\n\n#setup模块实践  \nansible george -m setup\n#显示远程主机的所有信息（后面加-v显示详细信息）\n#提取IP、或架构信息等，X86来判断主机架构，安装合适软件\nansible georhe -m setup -v   \n#主要用于解决一些错误：如远程主机hang住了，ansible会输出少量信息（最多-vvvv）\n\n#yum模块实践\nansible george -m yum -a \"name=iotop state=installed\"\n#批量使用yum安装软件iotop\n\n#service模块实践\nansible george -m service -a \"name=crond state=stopped enable=no\" #stopped是2个p\n#临时停止crond服务，取消开机自启动（相反：state=started enable=yes）\n\n#file模块实践\n#修改文件或目录属性信息，用于创建文件或目录，也可以用mode、owner、group定义文件或目录的权限信息\n#1)path参数\nansible george -m file \"path=/tmp/ state=directory mode=0644\"\n#指定路径,是dest,name的别名，作用一样\n#2）state参数\nansible george -m file -a \"dest=/opt/dir_01/ state=directory\"\n#创建目录为dir_01\nansible george -m file -a \"dest=/opt/file_01 state=touch\"\n#创建文件为file_01\nansible george -m file -a \"dest=/opt/file_01 state=absent\"\n#删除文件file_01\nansible george -m file -a \"src=/opt/hosts dest=/opt/hosts_link state=link\"\n#创建符号链接，基于本机有源文件\n\n#定时任务cron模块\n* * * * *  /bin/sh /server/scripts/test.sh &>/dev/null\nminute                 # Minute when the job should run ( 0-59, *, */2, etc )\nhour                   # Hour when the job should run ( 0-23, *, */2, etc )\nday                    # Day of the month the job should run ( 1-31, *, */2, etc )\nmonth                  # Month of the year the job should run ( 1-12, *, */2, etc )\nweekday                # Day of the week that the job should run ( 0-6 for Sunday-Saturday, *, etc )\njob                    # 定义定时任务与要做什么事\nname       # 给定时任务加一个备注，避免创建出多个重复的定时任务(根据定时任务备份判断是否生成一个新的定时任务)\nstat       #若设置为present，表示创建定时任务，若设置为absent，表示删除指定定时任务\n#只能管理自己创建的定时任务，本来有的管理不了\ndisabled      #disable=yes注释掉定时任务（不生效），disable=no解除注释定时任务（生效）\nansible george -m cron -a \"name='backup servcie' minute=*/5 job='/usr/sbin/ntpdate  time.nist.gov >/dev/null 2>&1'\"\n#创建定时任务\nansible george -m cron -a \"name=`backup service` state=absent\"\n#删除定时任务\nansible george -m cron -a \"name=dancy01 minute=*/5 job='/usr/sbin/ntpdate time.nist.gov >/dev/null 2>&1' disabled=yes\"              \n#注释掉定时任务，反之取消注释\n\n#mount模块实践\nansible george -m mount -a \"state=mounted src=172.16.1.31:/data path=/data fstype=nfs\"\n#src   要被挂载的目录或文件\n#path  指定挂载点的路径\n#fstype  指定挂载时的文件系统类型\n#opts  在挂载时，指定挂载参数信息\n#state  state=mounted，在fstab文件中的备份将被激活挂载或适当配置，如果指定mounted的挂载挂载点不存在，会创建    #state=unmounted，设备将被卸载不会改变fstab文件中的信息\n#state=absent和state=present，只处理fatab，但不影响目录的挂载\n\n```","tags":["Ansible"],"categories":["linux"]},{"title":"TCP三次握手与Tcpdump抓包分析过程","url":"%2F2015%2F07%2F19%2FTCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E4%B8%8ETcpdump%E6%8A%93%E5%8C%85%E5%88%86%E6%9E%90%E8%BF%87%E7%A8%8B%2F","content":"\n#### TCP连接建立（三次握手）\n\n过程\n客户端A，服务器B，初始序号seq，确认号ack\n初始状态：B处于监听状态，A处于打开状态\nA -> B : seq = x （A向B发送连接请求报文段，A进入同步发送状态SYN-SENT）\nB -> A : ack = x + 1,seq = y （B收到报文段，向A发送确认，B进入同步收到状态SYN-RCVD）\nA -> B : ack = y+1 （A收到B的确认后，再次确认，A进入连接状态ESTABLISHED）\n连接后的状态：B收到A的确认后，进入连接状态ESTABLISHED\n<!--more-->\n#### 为什么要握手要三次\n防止失效的连接请求突然传到服务器端，让服务器端误认为要建立连接。\n\n#### TCP连接释放（四次挥手）\n\n过程\nA -> B : seq = u （A发出连接释放报文段，进入终止等待1状态FIN-WAIT-1）\nB -> A : ack = u + 1,seq = v （B收到报文段，发出确认，TCP处于半关闭，B还可向A发数据，B进入关闭等待状态WAIT）\nB -> A : ack = u + 1,seq = w （B重复发送确认号，进入最后确认状态LAST-ACK）\nA -> B : ack = w + 1,seq = u + 1 （A发出确认，进入时间等待状态TIME-WAIT）\n经过时间等待计时器设置的时间2MSL后，A才进入CLOSED状态\n为什么A进入TIME-WAIT后必须等待2MSL\n保证A发送的最后一个ACK报文段能达到B\n防止失效的报文段出现在连接中\n\n#### Tcpdump使用\n\ntcpdump是对网络上的数据包进行截获的包分析工具，它支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来去掉无用的信息。\n\n监视指定主机的数据包\ntcpdump host <IP地址>：截获该IP的主机收到的和发出的所有的数据包\ntcpdump host <IP地址> and <IP地址>：截获两个IP对应主机之间的通信\n\n监视指定端口的数据包\ntcpdump port <端口号>：截获本机80端口的数据包\n\n#### 抓包分析握手过程\n抓包方法：首先使用tcpdump命令截获本机与某远程主机的数据包，然后打开某远程主机对应的网站，这里用我的域名www.fonxian.cn来做试验。\n\nping www.fonxian.cn\n得到域名对应的ip：151.101.100.133\nifconfg\n得到本机内网ip：192.168.0.108\n-S 参数的目的是获得ack的绝对值，不加该参数，第三次握手的ack为相对值1\nsudo tcpdump -S host 192.168.0.108 and 151.101.100.133\n得到下图\n![](http://111.230.96.161/server/../Public/Uploads/2018-05-24/5b0651c4e27bb.png)","tags":["抓包"],"categories":["linux"]},{"title":"网络管理工具之netstat","url":"%2F2015%2F07%2F13%2F%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7%E4%B9%8Bnetstat%2F","content":"\n#### 简介\n\tLinux netstat命令用于显示网络状态。利用netstat指令可让你得知整个Linux系统的网络情况\n\n#### 语法\n\n```bash\nnetstat [-acCeFghilMnNoprstuvVwx][-A<网络类型>][--ip]\n```\n<!--more-->\n#### 参数说明\n\n```bash\n-a或--all 显示所有连线中的Socket。\n-A<网络类型>或--<网络类型> 列出该网络类型连线中的相关地址。\n-c或--continuous 持续列出网络状态。\n-C或--cache 显示路由器配置的快取信息。\n-e或--extend 显示网络其他相关信息。\n-F或--fib 显示FIB。\n-g或--groups 显示多重广播功能群组组员名单。\n-h或--help 在线帮助。\n-i或--interfaces 显示网络界面信息表单。\n-l或--listening 显示监控中的服务器的Socket。\n-M或--masquerade 显示伪装的网络连线。\n-n或--numeric 直接使用IP地址，而不通过域名服务器。\n-N或--netlink或--symbolic 显示网络硬件外围设备的符号连接名称。\n-o或--timers 显示计时器。\n-p或--programs 显示正在使用Socket的程序识别码和程序名称。\n-r或--route 显示Routing Table。\n-s或--statistice 显示网络工作信息统计表。\n-t或--tcp 显示TCP传输协议的连线状况。\n-u或--udp 显示UDP传输协议的连线状况。\n-v或--verbose 显示指令执行过程。\n-V或--version 显示版本信息。\n-w或--raw 显示RAW传输协议的连线状况。\n-x或--unix 此参数的效果和指定\"-A unix\"参数相同。\n--ip或--inet 此参数的效果和指定\"-A inet\"参数相同。\n```\n\n#### 用例\n\n```bash\n#显示详细的网络状况\nnetstat -a\n#显示当前户籍UDP连接状况\nnetstat -nu\n#显示UDP端口号的使用情况\nnetstat -apu\nActive Internet connections (servers and established)\nProto Recv-Q Send-Q Local Address        Foreign Address       State    PID/Program name  \nudp    0   0 *:32768           *:*                   -          \nudp    0   0 *:nfs            *:*                   -          \nudp    0   0 *:641            *:*                   3006/rpc.statd   \nudp    0   0 192.168.0.3:netbios-ns   *:*                   3537/nmbd      \nudp    0   0 *:netbios-ns        *:*                   3537/nmbd      \nudp    0   0 192.168.0.3:netbios-dgm   *:*                   3537/nmbd      \nudp    0   0 *:netbios-dgm        *:*                   3537/nmbd      \nudp    0   0 *:tftp           *:*                   3346/xinetd     \nudp    0   0 *:999            *:*                   3366/rpc.rquotad  \nudp    0   0 *:sunrpc       *:*                   2986/portmap    \nudp    0   0 *:ipp            *:*                   6938/cupsd     \nudp    0   0 *:1022           *:*                   3392/rpc.mountd   \nudp    0   0 *:638            *:*                   3006/rpc.statd\n#显示网卡列表\nnetstat -i\nKernel Interface table\nIface    MTU Met  RX-OK RX-ERR RX-DRP RX-OVR  TX-OK TX-ERR TX-DRP TX-OVR Flg\neth0    1500  0  181864   0   0   0  141278   0   0   0 BMRU\nlo    16436  0   3362   0   0   0   3362   0   0   0 LRU\n\n#显示组播组的关系\nnetstat -g\nIPv6/IPv4 Group Memberships\nInterface    RefCnt Group\n--------------- ------ ---------------------\nlo       1   ALL-SYSTEMS.MCAST.NET\neth0      1   ALL-SYSTEMS.MCAST.NET\nlo       1   ff02::1\neth0      1   ff02::1:ff0a:b0c\neth0      1   ff02::1\n\n#显示网络统计信息\nnetstat -s\nIp:\n  184695 total packets received\n  0 forwarded\n  0 incoming packets discarded\n  184687 incoming packets delivered\n  143917 requests sent out\n  32 outgoing packets dropped\n  30 dropped because of missing route\nIcmp:\n  676 ICMP messages received\n  5 input ICMP message failed.\n  ICMP input histogram:\n    destination unreachable: 44\n    echo requests: 287\n    echo replies: 345\n  304 ICMP messages sent\n  0 ICMP messages failed\n  ICMP output histogram:\n    destination unreachable: 17\n    echo replies: 287\nTcp:\n  473 active connections openings\n  28 passive connection openings\n  4 failed connection attempts\n  11 connection resets received\n  1 connections established\n  178253 segments received\n  137936 segments send out\n  29 segments retransmited\n  0 bad segments received.\n  336 resets sent\nUdp:\n  5714 packets received\n  8 packets to unknown port received.\n  0 packet receive errors\n  5419 packets sent\nTcpExt:\n  1 resets received for embryonic SYN_RECV sockets\n  ArpFilter: 0\n  12 TCP sockets finished time wait in fast timer\n  572 delayed acks sent\n  3 delayed acks further delayed because of locked socket\n  13766 packets directly queued to recvmsg prequeue.\n  1101482 packets directly received from backlog\n  19599861 packets directly received from prequeue\n  46860 packets header predicted\n  14541 packets header predicted and directly queued to user\n  TCPPureAcks: 12259\n  TCPHPAcks: 9119\n  TCPRenoRecovery: 0\n  TCPSackRecovery: 0\n  TCPSACKReneging: 0\n  TCPFACKReorder: 0\n  TCPSACKReorder: 0\n  TCPRenoReorder: 0\n  TCPTSReorder: 0\n  TCPFullUndo: 0\n  TCPPartialUndo: 0\n  TCPDSACKUndo: 0\n  TCPLossUndo: 0\n  TCPLoss: 0\n  TCPLostRetransmit: 0\n  TCPRenoFailures: 0\n  TCPSackFailures: 0\n  TCPLossFailures: 0\n  TCPFastRetrans: 0\n  TCPForwardRetrans: 0\n  TCPSlowStartRetrans: 0\n  TCPTimeouts: 29\n  TCPRenoRecoveryFail: 0\n  TCPSackRecoveryFail: 0\n  TCPSchedulerFailed: 0\n  TCPRcvCollapsed: 0\n  TCPDSACKOldSent: 0\n  TCPDSACKOfoSent: 0\n  TCPDSACKRecv: 0\n  TCPDSACKOfoRecv: 0\n  TCPAbortOnSyn: 0\n  TCPAbortOnData: 1\n  TCPAbortOnClose: 0\n  TCPAbortOnMemory: 0\n  TCPAbortOnTimeout: 3\n  TCPAbortOnLinger: 0\n  TCPAbortFailed: 3\n  TCPMemoryPressures: 0\n\n#显示监听的套接口\nnetstat -l\nActive Internet connections (only servers)\nProto Recv-Q Send-Q Local Address        Foreign Address       State   \ntcp    0   0 *:32769           *:*             LISTEN   \ntcp    0   0 *:nfs            *:*             LISTEN   \ntcp    0   0 *:644            *:*             LISTEN   \ntcp    0   0 *:1002           *:*             LISTEN   \ntcp    0   0 *:netbios-ssn        *:*             LISTEN   \ntcp    0   0 *:sunrpc          *:*             LISTEN   \ntcp    0   0 vm-dev:ipp         *:*             LISTEN   \ntcp    0   0 *:telnet          *:*             LISTEN   \ntcp    0   0 *:601            *:*             LISTEN   \ntcp    0   0 *:microsoft-ds       *:*             LISTEN   \ntcp    0   0 *:http           *:*             LISTEN   \ntcp    0   0 *:ssh            *:*             LISTEN   \ntcp    0   0 *:https           *:*             LISTEN   \nudp    0   0 *:32768           *:*                   \nudp    0   0 *:nfs            *:*                   \nudp    0   0 *:641            *:*                   \nudp    0   0 192.168.0.3:netbios-ns   *:*                   \nudp    0   0 *:netbios-ns        *:*                   \nudp    0   0 192.168.0.3:netbios-dgm   *:*                   \nudp    0   0 *:netbios-dgm        *:*                   \nudp    0   0 *:tftp           *:*                   \nudp    0   0 *:999            *:*                   \nudp    0   0 *:sunrpc          *:*                   \nudp    0   0 *:ipp            *:*                   \nudp    0   0 *:1022           *:*                   \nudp    0   0 *:638            *:*                   \nActive UNIX domain sockets (only servers)\nProto RefCnt Flags    Type    State     I-Node Path\nunix 2   [ ACC ]   STREAM   LISTENING   10621 @/tmp/fam-root-\nunix 2   [ ACC ]   STREAM   LISTENING   7096  /var/run/acpid.socket\nunix 2   [ ACC ]   STREAM   LISTENING   9792  /tmp/.gdm_socket\nunix 2   [ ACC ]   STREAM   LISTENING   9927  /tmp/.X11-unix/X0\nunix 2   [ ACC ]   STREAM   LISTENING   10489 /tmp/ssh-lbUnUf4552/agent.4552\nunix 2   [ ACC ]   STREAM   LISTENING   10558 /tmp/ksocket-root/kdeinit__0\nunix 2   [ ACC ]   STREAM   LISTENING   10560 /tmp/ksocket-root/kdeinit-:0\nunix 2   [ ACC ]   STREAM   LISTENING   10570 /tmp/.ICE-unix/dcop4664-1270815442\nunix 2   [ ACC ]   STREAM   LISTENING   10843 /tmp/.ICE-unix/4735\nunix 2   [ ACC ]   STREAM   LISTENING   10591 /tmp/ksocket-root/klauncherah3arc.slave-socket\nunix 2   [ ACC ]   STREAM   LISTENING   7763  /var/run/iiim/.iiimp-unix/9010\nunix 2   [ ACC ]   STREAM   LISTENING   11047 /tmp/orbit-root/linc-1291-0-1e92c8082411\nunix 2   [ ACC ]   STREAM   LISTENING   11053 /tmp/orbit-root/linc-128e-0-dc070659cbb3\nunix 2   [ ACC ]   STREAM   LISTENING   8020  /var/run/dbus/system_bus_socket\nunix 2   [ ACC ]   STREAM   LISTENING   58927 /tmp/mcop-root/vm-dev-2c28-4beba75f\nunix 2   [ ACC ]   STREAM   LISTENING   7860  /tmp/.font-unix/fs7100\nunix 2   [ ACC ]   STREAM   LISTENING   7658  /dev/gpmctl\nunix 2   [ ACC ]   STREAM   LISTENING   10498 @/tmp/dbus-s2MLJGO5Ci\n```","tags":["netstat"],"categories":["linux"]},{"title":"Shell脚本及编程","url":"%2F2015%2F07%2F13%2FShell%E8%84%9A%E6%9C%AC%E5%8F%8A%E7%BC%96%E7%A8%8B%2F","content":"\n#### shell调试\n\n```bash\n#!/bin/bash -xv \n#不用任何其他选项就可以启用调试功能了\n#sh -n sh16.sh 不执行script，仅查询语法\n#sh -x sh16.sh 将script执行过程全部列出来\n```\n<!--more-->\n#### 特殊变量\n    $$       Shell本身的PID（ProcessID）\n    $!       Shell最后运行的后台Process的PID\n    $?       最后运行的命令的结束代码（返回值） 0 表示成功  ，非0 不成功\n    $-       使用Set命令设定的Flag一览\n    $*       所有参数列表。如\"$*\"用「\"」括起来的情况、以\"$1 $2 … $n\"的形式输出所有参数。\n    $@       所有参数列表。如\"$@\"用「\"」括起来的情况、以\"$1\" \"$2\" … \"$n\" 的形式输出所有参数。\n    $#       添加到Shell的参数个数\n    $0       Shell本身的文件名\n    $1～$n   添加到Shell的各参数值。$1是第1参数、$2是第2参数…。\n\n\n    #将命令的输出读入一个变量中，可以将它放入双引号中，即可保留空格和换行符(\\n)\n    out=$(cat text.txt)\n    输出1 2 3\n    out=\"$(cat text.txt)\"\n    输出：\n    1\n    2\n    3\n\n    #获取名称.扩展名\n    file_jpg=\"sample.jpg\"\n    name=${file_jpg%.*}\n    #输出sample\n    file_jpg=\"sample.jpg\"\n    extension=${file_jpg#*.}\n    #输出jpg\n\n#### 常用运算符\n\n| 操作符  | 说明 |  示例 |\n| ------------ | ------------ | ------------ |\n|-eq|检测两个数是否相等，相等返回 true。|[ $a -eq $b ] 返回 false。|\n|-ne|检测两个数是否相等，不相等返回 true。|[ $a -ne $b ] 返回 true。|\n|-gt|检测左边的数是否大于右边的，如果是，则返回 true。|[ $a -gt $b ] 返回 false。|\n|-lt|检测左边的数是否小于右边的，如果是，则返回 true。|[ $a -lt $b ] 返回 true。|\n|-ge|检测左边的数是否大于等于右边的，如果是，则返回 true。|[ $a -ge $b ] 返回 false。|\n|-le|检测左边的数是否小于等于右边的，如果是，则返回 true。|[ $a -le $b ] 返回 true。|\n|-z|检测字符串长度是否为0，为0返回 true。|[ -z $a ] 返回 false。|\n|-n|检测字符串长度是否为0，不为0返回 true。|[ -n $a ] 返回 true。|\n|str|检测字符串是否为空，不为空返回 true。|[ $a ] 返回 true|\n|-b file|检测文件是否是块设备文件，如果是，则返回 true。|[ -b $file ] 返回 false。|\n|-c file|检测文件是否是字符设备文件，如果是，则返回 true。|[ -c $file ] 返回 false。|\n|-S file|侦测是否为一个socket 标签档案|[ -S $file ] 返回 false。|\n|-d file|检测文件是否是目录，如果是，则返回 true。|[ -d $file ] 返回 false。|\n|-f file|检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。|[ -f $file ] 返回 true|\n|-g file|检测文件是否设置了 SGID 位，如果是，则返回 true。|[ -g $file ] 返回 false|\n|-k file|检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。|[ -k $file ] 返回 false|\n|-p file|检测文件是否是有名管道，如果是，则返回 true。|[ -p $file ] 返回 false|\n|-u file|检测文件是否设置了 SUID 位，如果是，则返回 true。|[ -u $file ] 返回 false|\n|-r file|检测文件是否可读，如果是，则返回 true。|[ -r $file ] 返回 true|\n|-w file|检测文件是否可写，如果是，则返回 true。|[ -w $file ] 返回 true|\n|-x file|检测文件是否可执行，如果是，则返回 true。|[ -x $file ] 返回 true|\n|-s file|检测文件是否为空（文件大小是否大于0），不为空返回 true。|[ -s $file ] 返回 true|\n|-e file|检测文件（包括目录）是否存在，如果是，则返回 true。|[ -e $file ] 返回 true|\n|!|非运算，表达式为 true 则返回 false，否则返回 true|[ ! false ] 返回 true|\n|-o|或运算，有一个表达式为 true 则返回 true|[ $a -lt 20 -o $b -gt 100 ] 返回 true|\n|-a|与运算，两个表达式都为 true 才返回 true|[ $a -lt 20 -a $b -gt 100 ] 返回 false|\n\n#### 逻辑表达式\n\n```bash\n#使用方法：test EXPRESSION如：\n[root@localhost ~]# test 1 = 1 && echo 'ok'\nok\n[root@localhost ~]# test -d /etc/ && echo 'ok' \nok\n[root@localhost ~]# test 1 -eq 1 && echo 'ok'\nok\n[root@localhost ~]# if test 1 = 1 ; then echo 'ok'; fi\nok\n#注意：所有字符 与逻辑运算符直接用“空格”分开，不能连到一起。\n```\n\n```bash\n#[] 表达式\n[root@localhost ~]# [ 1 -eq 1 ] && echo 'ok'           \nok\n[root@localhost ~]# [ 2 < 1 ] && echo 'ok'                  \n-bash: 2: No such file or directory\n[root@localhost ~]# [ 2 \\< 1 ] && echo 'ok'\n[root@localhost ~]# [ 2 -gt 1 -a 3 -lt 4 ] && echo 'ok'\nok    \n[root@localhost ~]# [ 2 -gt 1 && 3 -lt 4 ] && echo 'ok'   \n-bash: [: missing `]`\n\n#意：在[] 表达式中，常见的>,<需要加转义字符，表示字符串大小比较，以acill码 位置作为比较。 不直接支持<>运算符，还有逻辑运算符|| && 它需要用-a[and] –o[or]表示\n```\n\n```bash\n#[[]] 表达式\n[root@localhost ~]# [ 1 -eq 1 ] && echo 'ok'           \nok\n[root@localhost ~]$ [[ 2 < 3 ]] && echo 'ok' \nok\n[root@localhost ~]$ [[ 2 < 3 && 4 > 5 ]] && echo 'ok' \nok\n\n#注意：[[]] 运算符只是[]运算符的扩充。能够支持<,>符号运算不需要转义符，它还是以字符串比较大小。里面支持逻辑运算符：|| &&\n```\n```bash\n    type [\n    [ is a shell builtin\n    $ type [[\n    [[ is a shell keyword\n    #也就是说[处理里面的字串是当作参数来处理的，而[[对待其中的字串是当作表达式来处理的那么当作参数和表达式有什么不同呢？\n    #表达式中不会有wordsplitting 或者glob expansion，而参数处理会有 \n```\n\n```bash\n#性能比较\n[root@localhost ~]$ time (for m in {1..100000}; do test -d .;done;)\nreal    0m0.658s\nuser    0m0.558s\nsys     0m0.100s\n\n[root@localhost ~]$ time (for m in {1..100000}; do [ -d . ];done;)\nreal    0m0.609s\nuser    0m0.524s\nsys     0m0.085s\n\n[root@localhost ~]$ time (for m in {1..100000}; do [[ -d . ]];done;)\nreal    0m0.311s\nuser    0m0.275s\nsys     0m0.036s\n```\n\n#### 循环遍历\n\n```bash\n#for循环\n#!/bin/bash\nfor i in 1 2 3 4 5\ndo\n    echo $i\ndone\n\n#注：ls会将当前目录下的所有文件列出来，然后逐个赋值给file，就可以逐个输出了\nfor file in $(ls) \ndo\n    echo $file\ndone\n\n#(( 初始值;循环控制条件;变量变化 ))\nsum=0\nfor ((i=1;i<=100;i=i+1))\ndo\n    #同样可以使用，sum=$[$sum+$i]\n    sum=$(($sum+$i)) \ndone\necho $sum\n\n```\n\n```bash\n#while循环\n#说明：当条件判断式成立时，才会执行程序，直到条件判断式不成立时，才退出循环。\n#!/bin/bash\ni=1\nsum=0\n\nwhile [ $i -le 100 ]\ndo\n    sum=$(( sum+i ))\n    i=$(( i+1 ))\ndone\n\necho $sum\n```\n\n```bash\n#until循环\n#说明：until循环和while循环是相反的，当条件判断式不成立时，才会执行程序，直到条件判断式成立，才退出循环\n#!/bin/bash\ni=1\nsum=0\n\nuntil [ $i -gt 100 ]\ndo\n    sum=$(( sum+i ))\n    i=$(( i+1 ))\ndone\n\necho $sum\n```\n\n#### 数组的遍历\n\n```bash\n#在Linux下使用shell的时候，为方便起见，偶尔会用到一下数组。数组的申明方式是：array=(element1 element2 element3 .... elementN)  也就是直接用圆括号包数组元素包起来，数组元素之间用空格隔开就行了。\n数据的读取如下\necho ${array[0]}  \necho ${array[index]}  \n\n#数组的遍历用到一个取全部\n${array[@]}  \n\n#完整示例如下：\nfor data in ${array[@]}  \ndo  \n\techo ${data}  \ndone  \n```\n","tags":["脚本"],"categories":["linux"]},{"title":"网络统计分析脚本","url":"%2F2015%2F07%2F11%2F%E7%BD%91%E7%BB%9C%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E8%84%9A%E6%9C%AC%2F","content":"\n创建脚本文件，将原文内容写入文件，赋予可执行权限即可使用。此脚本内容来源于网络，内容中已附出处。\n<!--more-->\n```bash\n#!/bin/bash\n\n#write by zhumaohai(admin#centos.bz)\n#author blog: www.centos.bz\n\n#显示菜单(单选)\ndisplay_menu(){\nlocal soft=$1\nlocal prompt=\"which ${soft} you'd select: \"\neval local arr=(\\${${soft}_arr[@]})\nwhile true\ndo\n    echo -e \"#################### ${soft} setting ####################\\n\\n\"\n    for ((i=1;i<=${#arr[@]};i++ )); do echo -e \"$i) ${arr[$i-1]}\"; done\n    echo\n    read -p \"${prompt}\" $soft\n    eval local select=\\$$soft\n    if [ \"$select\" == \"\" ] || [ \"${arr[$soft-1]}\" == \"\"  ];then\n        prompt=\"input errors,please input a number: \"\n    else\n        eval $soft=${arr[$soft-1]}\n        eval echo \"your selection: \\$$soft\"             \n        break\n    fi\ndone\n}\n\n#把带宽bit单位转换为人类可读单位\nbit_to_human_readable(){\n    #input bit value\n    local trafficValue=$1\n\n    if [[ ${trafficValue%.*} -gt 922 ]];then\n        #conv to Kb\n        trafficValue=`awk -v value=$trafficValue 'BEGIN{printf \"%0.1f\",value/1024}'`\n        if [[ ${trafficValue%.*} -gt 922 ]];then\n            #conv to Mb\n            trafficValue=`awk -v value=$trafficValue 'BEGIN{printf \"%0.1f\",value/1024}'`\n            echo \"${trafficValue}Mb\"\n        else\n            echo \"${trafficValue}Kb\"\n        fi\n    else\n        echo \"${trafficValue}b\"\n    fi\n}\n\n#判断包管理工具\ncheck_package_manager(){\n    local manager=$1\n    local systemPackage=''\n    if cat /etc/issue | grep -q -E -i \"ubuntu|debian\";then\n        systemPackage='apt'\n    elif cat /etc/issue | grep -q -E -i \"centos|red hat|redhat\";then\n        systemPackage='yum'\n    elif cat /proc/version | grep -q -E -i \"ubuntu|debian\";then\n        systemPackage='apt'\n    elif cat /proc/version | grep -q -E -i \"centos|red hat|redhat\";then\n        systemPackage='yum'\n    else\n        echo \"unkonw\"\n    fi\n\n    if [ \"$manager\" == \"$systemPackage\" ];then\n        return 0\n    else\n        return 1\n    fi\n}\n\n\n#实时流量\nrealTimeTraffic(){\n    local eth=\"\"\n    local nic_arr=(`ifconfig | grep -E -o \"^[a-z0-9]+\" | grep -v \"lo\" | uniq`)\n    local nicLen=${#nic_arr[@]}\n    if [[ $nicLen -eq 0 ]]; then\n        echo \"sorry,I can not detect any network device,please report this issue to author.\"\n        exit 1\n    elif [[ $nicLen -eq 1 ]]; then\n        eth=$nic_arr\n    else\n        display_menu nic\n        eth=$nic\n    fi\n\n    local clear=true\n    local eth_in_peak=0\n    local eth_out_peak=0\n    local eth_in=0\n    local eth_out=0\n\n    while true;do\n        #移动光标到0:0位置\n        printf \"\\033[0;0H\"\n        #清屏并打印Now Peak\n        [[ $clear == true ]] && printf \"\\033[2J\" && echo \"$eth--------Now--------Peak-----------\"\n        traffic_be=(`awk -v eth=$eth -F'[: ]+' '{if ($0 ~eth){print $3,$11}}' /proc/net/dev`)\n        sleep 2\n        traffic_af=(`awk -v eth=$eth -F'[: ]+' '{if ($0 ~eth){print $3,$11}}' /proc/net/dev`)\n        #计算速率\n        eth_in=$(( (${traffic_af[0]}-${traffic_be[0]})*8/2 ))\n        eth_out=$(( (${traffic_af[1]}-${traffic_be[1]})*8/2 ))\n        #计算流量峰值\n        [[ $eth_in -gt $eth_in_peak ]] && eth_in_peak=$eth_in\n        [[ $eth_out -gt $eth_out_peak ]] && eth_out_peak=$eth_out\n        #移动光标到2:1\n        printf \"\\033[2;1H\"\n        #清除当前行\n        printf \"\\033[K\"\n        printf \"%-20s %-20s\\n\" \"Receive:  $(bit_to_human_readable $eth_in)\" \"$(bit_to_human_readable $eth_in_peak)\"\n        #清除当前行\n        printf \"\\033[K\"\n        printf \"%-20s %-20s\\n\" \"Transmit: $(bit_to_human_readable $eth_out)\" \"$(bit_to_human_readable $eth_out_peak)\"\n        [[ $clear == true ]] && clear=false\n    done\n}\n \n#流量和连接概览\ntrafficAndConnectionOverview(){\n    if ! which tcpdump > /dev/null;then\n        echo \"tcpdump not found,going to install it.\"\n        if check_package_manager apt;then\n            apt-get -y install tcpdump\n        elif check_package_manager yum;then\n            yum -y install tcpdump\n        fi\n    fi\n \n    local reg=\"\"\n    local eth=\"\"\n    local nic_arr=(`ifconfig | grep -E -o \"^[a-z0-9]+\" | grep -v \"lo\" | uniq`)\n    local nicLen=${#nic_arr[@]}\n    if [[ $nicLen -eq 0 ]]; then\n        echo \"sorry,I can not detect any network device,please report this issue to author.\"\n        exit 1\n    elif [[ $nicLen -eq 1 ]]; then\n        eth=$nic_arr\n    else\n        display_menu nic\n        eth=$nic\n    fi\n \n    echo \"please wait for 10s to generate network data...\"\n    echo\n    #当前流量值\n    local traffic_be=(`awk -v eth=$eth -F'[: ]+' '{if ($0 ~eth){print $3,$11}}' /proc/net/dev`)\n    #tcpdump监听网络\n    tcpdump -v -i $eth -tnn > /tmp/tcpdump_temp 2>&1 &\n    sleep 10\n    clear\n    kill `ps aux | grep tcpdump | grep -v grep | awk '{print $2}'`\n\n    #10s后流量值\n    local traffic_af=(`awk -v eth=$eth -F'[: ]+' '{if ($0 ~eth){print $3,$11}}' /proc/net/dev`)\n    #打印10s平均速率\n    local eth_in=$(( (${traffic_af[0]}-${traffic_be[0]})*8/10 ))\n    local eth_out=$(( (${traffic_af[1]}-${traffic_be[1]})*8/10 ))\n    echo -e \"\\033[32mnetwork device $eth average traffic in 10s: \\033[0m\"\n    echo \"$eth Receive: $(bit_to_human_readable $eth_in)/s\"\n    echo \"$eth Transmit: $(bit_to_human_readable $eth_out)/s\"\n    echo\n\n    local regTcpdump=$(ifconfig | grep -A 1 $eth | awk -F'[: ]+' '$0~/inet addr:/{printf $4\"|\"}' | sed -e 's/|$//' -e 's/^/(/' -e 's/$/)\\\\\\\\\\.[0-9]+:/')\n  \n    #新旧版本tcpdump输出格式不一样,分别处理\n    if awk '/^IP/{print;exit}' /tmp/tcpdump_temp | grep -q \")$\";then\n        #处理tcpdump文件\n        awk '/^IP/{print;getline;print}' /tmp/tcpdump_temp > /tmp/tcpdump_temp2\n    else\n        #处理tcpdump文件\n        awk '/^IP/{print}' /tmp/tcpdump_temp > /tmp/tcpdump_temp2\n        sed -i -r 's#(.*: [0-9]+\\))(.*)#\\1\\n    \\2#' /tmp/tcpdump_temp2\n    fi\n\n    awk '{len=$NF;sub(/\\)/,\"\",len);getline;print $0,len}' /tmp/tcpdump_temp2 > /tmp/tcpdump\n\n    #统计每个端口在10s内的平均流量\n    echo -e \"\\033[32maverage traffic in 10s base on server port: \\033[0m\"\n    awk -F'[ .:]+' -v regTcpdump=$regTcpdump '{if ($0 ~ regTcpdump){line=\"clients > \"$8\".\"$9\".\"$10\".\"$11\":\"$12}else{line=$2\".\"$3\".\"$4\".\"$5\":\"$6\" > clients\"};sum[line]+=$NF*8/10}END{for (line in sum){printf \"%s %d\\n\",line,sum[line]}}' /tmp/tcpdump | \\\n    sort -k 4 -nr | head -n 10 | while read a b c d;do\n        echo \"$a $b $c $(bit_to_human_readable $d)/s\"\n    done\n    echo -ne \"\\033[11A\"\n    echo -ne \"\\033[50C\"\n    echo -e \"\\033[32maverage traffic in 10s base on client port: \\033[0m\"\n    awk -F'[ .:]+' -v regTcpdump=$regTcpdump '{if ($0 ~ regTcpdump){line=$2\".\"$3\".\"$4\".\"$5\":\"$6\" > server\"}else{line=\"server > \"$8\".\"$9\".\"$10\".\"$11\":\"$12};sum[line]+=$NF*8/10}END{for (line in sum){printf \"%s %d\\n\",line,sum[line]}}' /tmp/tcpdump | \\\n    sort -k 4 -nr | head -n 10 | while read a b c d;do\n            echo -ne \"\\033[50C\"\n            echo \"$a $b $c $(bit_to_human_readable $d)/s\"\n    done\n\n    echo\n\n    #统计在10s内占用带宽最大的前10个ip\n    echo -e \"\\033[32mtop 10 ip average traffic in 10s base on server: \\033[0m\"\n    awk -F'[ .:]+' -v regTcpdump=$regTcpdump '{if ($0 ~ regTcpdump){line=$2\".\"$3\".\"$4\".\"$5\" > \"$8\".\"$9\".\"$10\".\"$11\":\"$12}else{line=$2\".\"$3\".\"$4\".\"$5\":\"$6\" > \"$8\".\"$9\".\"$10\".\"$11};sum[line]+=$NF*8/10}END{for (line in sum){printf \"%s %d\\n\",line,sum[line]}}' /tmp/tcpdump | \\\n    sort -k 4 -nr | head -n 10 | while read a b c d;do\n        echo \"$a $b $c $(bit_to_human_readable $d)/s\"\n    done\n    echo -ne \"\\033[11A\"\n    echo -ne \"\\033[50C\"\n    echo -e \"\\033[32mtop 10 ip average traffic in 10s base on client: \\033[0m\"\n    awk -F'[ .:]+' -v regTcpdump=$regTcpdump '{if ($0 ~ regTcpdump){line=$2\".\"$3\".\"$4\".\"$5\":\"$6\" > \"$8\".\"$9\".\"$10\".\"$11}else{line=$2\".\"$3\".\"$4\".\"$5\" > \"$8\".\"$9\".\"$10\".\"$11\":\"$12};sum[line]+=$NF*8/10}END{for (line in sum){printf \"%s %d\\n\",line,sum[line]}}' /tmp/tcpdump | \\\n    sort -k 4 -nr | head -n 10 | while read a b c d;do\n        echo -ne \"\\033[50C\"\n        echo \"$a $b $c $(bit_to_human_readable $d)/s\"\n    done\n\n    echo\n    #统计连接状态\n    local regSS=$(ifconfig | grep -A 1 $eth | awk -F'[: ]+' '$0~/inet addr:/{printf $4\"|\"}' | sed -e 's/|$//')\n    ss -an | grep -v -E \"LISTEN|UNCONN\" | grep -E \"$regSS\" > /tmp/ss\n    echo -e \"\\033[32mconnection state count: \\033[0m\"\n    awk 'NR>1{sum[$(NF-4)]+=1}END{for (state in sum){print state,sum[state]}}' /tmp/ss | sort -k 2 -nr\n    echo\n    #统计各端口连接状态\n    echo -e \"\\033[32mconnection state count by port base on server: \\033[0m\"\n    awk 'NR>1{sum[$(NF-4),$(NF-1)]+=1}END{for (key in sum){split(key,subkey,SUBSEP);print subkey[1],subkey[2],sum[subkey[1],subkey[2]]}}' /tmp/ss | sort -k 3 -nr | head -n 10\n    echo -ne \"\\033[11A\"\n    echo -ne \"\\033[50C\"\n    echo -e \"\\033[32mconnection state count by port base on client: \\033[0m\"\n    awk 'NR>1{sum[$(NF-4),$(NF)]+=1}END{for (key in sum){split(key,subkey,SUBSEP);print subkey[1],subkey[2],sum[subkey[1],subkey[2]]}}' /tmp/ss | sort -k 3 -nr | head -n 10 | awk '{print \"\\033[50C\"$0}'\n    echo\n    #统计端口为80且状态为ESTAB连接数最多的前10个IP\n    echo -e \"\\033[32mtop 10 ip ESTAB state count at port 80: \\033[0m\"\n    cat /tmp/ss | grep ESTAB | awk -F'[: ]+' '{sum[$(NF-2)]+=1}END{for (ip in sum){print ip,sum[ip]}}' | sort -k 2 -nr | head -n 10\n    echo\n    #统计端口为80且状态为SYN-RECV连接数最多的前10个IP\n    echo -e \"\\033[32mtop 10 ip SYN-RECV state count at port 80: \\033[0m\"\n    cat /tmp/ss | grep -E \"$regSS\" | grep SYN-RECV | awk -F'[: ]+' '{sum[$(NF-2)]+=1}END{for (ip in sum){print ip,sum[ip]}}' | sort -k 2 -nr | head -n 10\n}\n\nmain(){\n    while true; do\n        echo -e \"1) real time traffic.\\n2) traffic and connection overview.\\n\"\n        read -p \"please input your select(ie 1): \" select\n        case  $select in\n            1) realTimeTraffic;break;;\n            2) trafficAndConnectionOverview;break;;\n            *) echo \"input error,please input a number.\";;\n        esac\n    done\n}\n\nmain\n\n\n```","tags":["script"],"categories":["linux"]},{"title":"http服务日志的统计分析","url":"%2F2015%2F07%2F10%2Fhttp%E6%9C%8D%E5%8A%A1%E6%97%A5%E5%BF%97%E7%9A%84%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%2F","content":"\n\n#### 获得访问前10位的ip地址\n\n```bash\ncat access.log|awk '{print $1}'|sort|uniq -c|sort -nr|head -10\ncat access.log|awk '{counts[$(11)]+=1}; END {for(url in counts) print counts[url], url}'\n```\n#### 访问次数最多的文件或页面,取前20\n\n```bash\ncat access.log|awk '{print $11}'|sort|uniq -c|sort -nr|head -20\n```\n<!--more-->\n#### 列出传输最大的几个exe文件(分析下载站的时候常用)\n\n```bash\ncat access.log |awk '($7~/.exe/){print $10 \" \" $1 \" \" $4 \" \" $7}'|sort -nr|head -20\n```\n\n#### 列出输出大于200000byte(约200kb)的exe文件以及对应文件发生次数\n\n```bash\ncat access.log |awk '($10 > 200000 && $7~/.exe/){print $7}'|sort -n|uniq -c|sort -nr|head -100\n```\n\n#### 如果日志最后一列记录的是页面文件传输时间，则有列出到客户端最耗时的页面\n\n```bash\ncat access.log |awk '($7~/.php/){print $NF \" \" $1 \" \" $4 \" \" $7}'|sort -nr|head -100\n```\n#### 列出最最耗时的页面(超过60秒的)的以及对应页面发生次数\n\n```bash\ncat access.log |awk '($NF > 60 && $7~/.php/){print $7}'|sort -n|uniq -c|sort -nr|head -100\n```\n#### 列出传输时间超过30秒的文件\n\n```bash\ncat access.log |awk '($NF > 30){print $7}'|sort -n|uniq -c|sort -nr|head -20\n```\n\n#### 统计网站流量(G）\n\n```bash\ncat access.log |awk '{sum+=$10} END {print sum/1024/1024/1024}'\n```\n\n#### 统计404的连接\n\n```bash\nawk '($9 ~/404/)' access.log | awk '{print $9,$7}' | sort\n```\n\n#### 统计http status\n\n```bash\ncat access.log |awk '{counts[$(9)]+=1}; END {for(code in counts) print code, counts[code]}'\ncat access.log |awk '{print $9}'|sort|uniq -c|sort -rn\n```\n\n#### 蜘蛛分析，查看是哪些蜘蛛在抓取内容\n\n```bash\n/usr/sbin/tcpdump -i eth0 -l -s 0 -w - dst port 80 | strings | grep -i user-agent | grep -i -E 'bot|crawler|slurp|spider'\n```\n\n#### 网站日分析2(Squid篇)按域统计流量\n\n```bash\nzcat squid_access.log.tar.gz| awk '{print $10,$7}' |awk 'BEGIN{FS=\"[ /]\"}{trfc[$4]+=$1}END{for(domain in trfc){printf \"%st%dn\",domain,trfc[domain]}}'\n```","tags":["统计分析"],"categories":["linux"]},{"title":"网络管理工具之route","url":"%2F2015%2F07%2F09%2F%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7%E4%B9%8Broute%2F","content":"#### 简介\n\tLinux系统的route命令用于显示和操作IP路由表（show / manipulate the IP routing table）。要实现两个不同的子网之间的通信，需要一台连接两个网络的路由器，或者同时位于两个网络的网关来实现。在Linux系统中，设置路由通常是为了解决以下问题：该Linux系统在一个局域网中，局域网中有一个网关，能够让机器访问Internet，那么就需要将这台机器的IP地址设置为Linux机器的默认路由。要注意的是，直接在命令行下执行route命令来添加路由，不会永久保存，当网卡重启或者机器重启之后，该路由就失效了；可以在/etc/rc.local中添加route命令来保证该路由设置永久有效\n\n#### 命令格式\n\n```bash\nroute [-f] [-p] [Command [Destination] [mask Netmask] [Gateway] [metric Metric]] [if Interface]] \n```\n#### 命令功能\n\nRoute命令是用于操作基于内核ip路由表，它的主要作用是创建一个静态路由让指定一个主机或者一个网络通过一个网络接口，如eth0。当使用”add”或者”del”参数时，路由表被修改，如果没有参数，则显示路由表当前的内容。\n<!--more-->\n#### 命令参数\n\n```bash\n-c 显示更多信息\n-n 不解析名字\n-v 显示详细的处理信息\n-F 显示发送信息\n-C 显示路由缓存\n-f 清除所有网关入口的路由表。\n-p 与 add 命令一起使用时使路由具有永久性。\nadd:添加一条新路由。\ndel:删除一条路由。\n-net:目标地址是一个网络。\n-host:目标地址是一个主机。\nnetmask:当添加一个网络路由时，需要使用网络掩码。\ngw:路由数据包通过网关。注意，你指定的网关必须能够达到。\nmetric：设置路由跳数\n\nCommand 指定您想运行的命令 (Add/Change/Delete/Print)。 \nDestination 指定该路由的网络目标。 \nmask Netmask 指定与网络目标相关的网络掩码（也被称作子网掩码）。 \nGateway 指定网络目标定义的地址集和子网掩码可以到达的前进或下一跃点 IP 地址。 \nmetric Metric 为路由指定一个整数成本值标（从 1 至 9999），当在路由表(与转发的数据包目标地址最匹配)的多个路由中进行选择时可以使用。 \nif Interface 为可以访问目标的接口指定接口索引。若要获得一个接口列表和它们相应的接口索引，使用 route print 命令的显示功能。可以使用十进制或十六进制值进行接口索引。\n```\n\n#### 用例\n\n```bash\n#显示当前路由 \nroute\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n192.168.120.0   *               255.255.255.0   U     0      0        0 eth0\ne192.168.0.0     192.168.120.1   255.255.0.0     UG    0      0        0 eth0\n10.0.0.0        192.168.120.1   255.0.0.0       UG    0      0        0 eth0\ndefault         192.168.120.240 0.0.0.0         UG    0      0        0 eth0\n#或者\nroute -n\n#route -n (-n 表示不解析名字,列出速度会比route 快)\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n192.168.120.0   0.0.0.0         255.255.255.0   U     0      0        0 eth0\n192.168.0.0     192.168.120.1   255.255.0.0     UG    0      0        0 eth0\n10.0.0.0        192.168.120.1   255.0.0.0       UG    0      0        0 eth0\n0.0.0.0         192.168.120.240 0.0.0.0         UG    0      0        0 eth0\n\n#一行表示主机所在网络的地址为192.168.120.0，若数据传送目标是在本局域网内通信，则可直接通过eth0转发数据包; \n#第四行表示数据传送目的是访问Internet，则由接口eth0，将数据包发送到网关192.168.120.240 \n#其中Flags为路由标志，标记当前网络节点的状态。\n```\n```bash\n#Flags标志说明：\n\nU Up表示此路由当前为启动状态\nH Host，表示此网关为一主机\nG Gateway，表示此网关为一路由器\nR Reinstate Route，使用动态路由重新初始化的路由\nD Dynamically,此路由是动态性地写入\nM Modified，此路由是由路由守护程序或导向器动态修改\n! 表示此路由当前为关闭状态\n\n```\n```bash\n#添加网关/设置网关\nroute add -net 224.0.0.0 netmask 240.0.0.0 dev eth0\n输出：\n[root@localhost ~]# route add -net 224.0.0.0 netmask 240.0.0.0 dev eth0\n[root@localhost ~]# route\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n192.168.120.0   *               255.255.255.0   U     0      0        0 eth0\n192.168.0.0     192.168.120.1   255.255.0.0     UG    0      0        0 eth0\n10.0.0.0        192.168.120.1   255.0.0.0       UG    0      0        0 eth0\n224.0.0.0       *               240.0.0.0       U     0      0        0 eth0\ndefault         192.168.120.240 0.0.0.0         UG    0      0        0 eth0\n#增加一条 到达244.0.0.0的路由\n```\n```bash\n#屏蔽一条路由\nroute add -net 224.0.0.0 netmask 240.0.0.0 reject\n输出：\n[root@localhost ~]# route add -net 224.0.0.0 netmask 240.0.0.0 reject\n[root@localhost ~]# route\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n192.168.120.0   *               255.255.255.0   U     0      0        0 eth0\n192.168.0.0     192.168.120.1   255.255.0.0     UG    0      0        0 eth0\n10.0.0.0        192.168.120.1   255.0.0.0       UG    0      0        0 eth0\n224.0.0.0       -               240.0.0.0       !     0      -        0 -\n224.0.0.0       *               240.0.0.0       U     0      0        0 eth0\ndefault         192.168.120.240 0.0.0.0         UG    0      0        0 eth0\n#增加一条屏蔽的路由，目的地址为 224.x.x.x 将被拒绝\n```\n```bash\n#删除路由记录 \nroute del -net 224.0.0.0 netmask 240.0.0.0\nroute del -net 224.0.0.0 netmask 240.0.0.0 reject\n输出：\n[root@localhost ~]# route\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n192.168.120.0   *               255.255.255.0   U     0      0        0 eth0\n192.168.0.0     192.168.120.1   255.255.0.0     UG    0      0        0 eth0\n10.0.0.0        192.168.120.1   255.0.0.0       UG    0      0        0 eth0\n224.0.0.0       -               240.0.0.0       !     0      -        0 -\n224.0.0.0       *               240.0.0.0       U     0      0        0 eth0\ndefault         192.168.120.240 0.0.0.0         UG    0      0        0 eth0\n[root@localhost ~]# route del -net 224.0.0.0 netmask 240.0.0.0\n[root@localhost ~]# route\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n192.168.120.0   *               255.255.255.0   U     0      0        0 eth0\n192.168.0.0     192.168.120.1   255.255.0.0     UG    0      0        0 eth0\n10.0.0.0        192.168.120.1   255.0.0.0       UG    0      0        0 eth0\n224.0.0.0       -               240.0.0.0       !     0      -        0 -\ndefault         192.168.120.240 0.0.0.0         UG    0      0        0 eth0\n[root@localhost ~]# route del -net 224.0.0.0 netmask 240.0.0.0 reject\n[root@localhost ~]# route\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n192.168.120.0   *               255.255.255.0   U     0      0        0 eth0\n192.168.0.0     192.168.120.1   255.255.0.0     UG    0      0        0 eth0\n10.0.0.0        192.168.120.1   255.0.0.0       UG    0      0        0 eth0\ndefault         192.168.120.240 0.0.0.0         UG    0      0        0 eth0\n[root@localhost ~]# \n```\n```bash\n#删除和添加设置默认网关\nroute del default gw 192.168.120.240\nroute add default gw 192.168.120.240\n输出：\n[root@localhost ~]# route del default gw 192.168.120.240\n[root@localhost ~]# route\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n192.168.120.0   *               255.255.255.0   U     0      0        0 eth0\n192.168.0.0     192.168.120.1   255.255.0.0     UG    0      0        0 eth0\n10.0.0.0        192.168.120.1   255.0.0.0       UG    0      0        0 eth0\n[root@localhost ~]# route add default gw 192.168.120.240\n[root@localhost ~]# route\nKernel IP routing table\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n192.168.120.0   *               255.255.255.0   U     0      0        0 eth0\n192.168.0.0     192.168.120.1   255.255.0.0     UG    0      0        0 eth0\n10.0.0.0        192.168.120.1   255.0.0.0       UG    0      0        0 eth0\ndefault         192.168.120.240 0.0.0.0         UG    0      0        0 eth0\n[root@localhost ~]# \n```","tags":["路由"],"categories":["linux"]},{"title":"网络管理工具之tcpdump","url":"%2F2015%2F07%2F09%2F%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7%E4%B9%8Btcpdump%2F","content":"\n#### 简介\n\ntcpdump是一个用于截取网络分组，并输出分组内容的工具，简单说就是数据包抓包工具。tcpdump凭借强大的功能和灵活的截取策略，使其成为Linux系统下用于网络分析和问题排查的首选工具。\ntcpdump提供了源代码，公开了接口，因此具备很强的可扩展性，对于网络维护和入侵者都是非常有用的工具。tcpdump存在于基本的Linux系统中，由于它需要将网络界面设置为混杂模式，普通用户不能正常执行，但具备root权限的用户可以直接执行它来获取网络上的信息。因此系统中存在网络分析工具主要不是对本机安全的威胁，而是对网络上的其他计算机的安全存在威胁。\n顾名思义，tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。它支持针对网络层、协议、主机、网络或端口的过滤，并提供and、or、not等逻辑语句来帮助你去掉无用的信息。\n\n#### 语法\n\n```bash\ntcpdump [ -AdDeflLnNOpqRStuUvxX ] [ -c count ]\n[ -C file_size ] [ -F file ]\n[ -i interface ] [ -m module ] [ -M secret ]\n[ -r file ] [ -s snaplen ] [ -T type ] [ -w file ]\n[ -W filecount ]\n[ -E spi@ipaddr algo:secret,... ]\n[ -y datalinktype ] [ -Z user ]\n[ expression ]\n\n```\n<!--more-->\n#### 参数\n\n```bash\n-A 以ASCII格式打印出所有分组，并将链路层的头最小化。\n-c 在收到指定的数量的分组后，tcpdump就会停止。\n-C 在将一个原始分组写入文件之前，检查文件当前的大小是否超过了参数file_size\n中指定的大小。如果超过了指定大小，则关闭当前文件，然后在打开一个新的文件。参数 file_size\n的单位是兆字节（是1,000,000字节，而不是1,048,576字节）。\n-d 将匹配信息包的代码以人们能够理解的汇编格式给出。\n-dd 将匹配信息包的代码以c语言程序段的格式给出。\n-ddd 将匹配信息包的代码以十进制的形式给出。\n-D 打印出系统中所有可以用tcpdump截包的网络接口。\n-e 在输出行打印出数据链路层的头部信息。\n-E 用spi@ipaddr algo:secret解密那些以addr作为地址，并且包含了安全参数索引值spi的IPsec ESP分组。\n-f 将外部的Internet地址以数字的形式打印出来。\n-F 从指定的文件中读取表达式，忽略命令行中给出的表达式。\n-i 指定监听的网络接口。\n-l 使标准输出变为缓冲行形式。\n-L 列出网络接口的已知数据链路。\n-m 从文件module中导入SMI MIB模块定义。该参数可以被使用多次，以导入多个MIB模块。\n-M 如果tcp报文中存在TCP-MD5选项，则需要用secret作为共享的验证码用于验证TCP-MD5选选项摘要（详情可参考RFC 2385）。\n-n 不把网络地址转换成名字。\n-N 不输出主机名中的域名部分。例如，‘nic.ddn.mil‘只输出’nic‘。\n-t 在输出的每一行不打印时间戳。\n-O 不运行分组分组匹配（packet-matching）代码优化程序。\n-P 不将网络接口设置成混杂模式。\n-q 快速输出。只输出较少的协议信息。\n-r 从指定的文件中读取包(这些包一般通过-w选项产生)。\n-S 将tcp的序列号以绝对值形式输出，而不是相对值。\n-s 从每个分组中读取最开始的snaplen个字节，而不是默认的68个字节。\n-T 将监听到的包直接解释为指定的类型的报文，常见的类型有rpc远程过程调用）和snmp（简单网络管理协议；）。\n-t 不在每一行中输出时间戳。\n-tt 在每一行中输出非格式化的时间戳。\n-ttt 输出本行和前面一行之间的时间差。\n-tttt 在每一行中输出由date处理的默认格式的时间戳。\n-u 输出未解码的NFS句柄。\n-v 输出一个稍微详细的信息，例如在ip包中可以包括ttl和服务类型的信息。\n-vv 输出详细的报文信息。\n-w 直接将分组写入文件中，而不是不分析并打印出来。\n-x 以16进制数形式显示每一个报文 (去掉链路层报头) . 可以显示较小的完整报文, 否则只显示snaplen个字节.\n-xx 以16进制数形式显示每一个报文（包含链路层包头）。\n-X 以16进制和ASCII码形式显示每个报文（去掉链路层报头）。\n-XX 以16进制和ASCII吗形式显示每个报文（包含链路层报头）。\n-y 设置tcpdump 捕获数据链路层协议类型\n-Z 使tcpdump 放弃自己的超级权限(如果以root用户启动tcpdump, tcpdump将会有超级用户权限), 并把当前tcpdump的用户ID设置为user, 组ID设置为user首要所属组的ID\n```\n#### 表达式介绍\n\n\t表达式是一个正则表达式，tcpdump利用它作为过滤报文的条件，如果一个报文满足表 达式的条件，则这个报文将会被捕获。如果没有给出任何条件，则网络上所有的信息包 将会被截获。\n\n\t在表达式中一般如下几种类型的关键字：\n\n\t第一种是关于类型的关键字，主要包括host，net，port，例如 host 210.27.48.2， 指明 210.27.48.2是一台主机，net 202.0.0.0指明202.0.0.0是一个网络地址，port 23 指明端口号是23。如果没有指定类型，缺省的类型是host。\n\n\t第二种是确定传输方向的关键字，主要包括src，dst，dst or src，dst and src， 这些关键字指明了传输的方向。举例说明，src 210.27.48.2 ，指明ip包中源地址是 210.27.48.2 ， dst net 202.0.0.0 指明目的网络地址是202.0.0.0。如果没有指明 方向关键字，则缺省是src or dst关键字。\n\n\t第三种是协议的关键字，主要包括fddi，ip，arp，rarp，tcp，udp等类型。Fddi指明是在FDDI (分布式光纤数据接口网络)上的特定的网络协议，实际上它是”ether”的别名，fddi和ether 具有类似的源地址和目的地址，所以可以将fddi协议包当作ether的包进行处理和分析。 其他的几个关键字就是指明了监听的包的协议内容。如果没有指定任何协议，则tcpdump 将会 监听所有协议的信息包。\n\n\t除了这三种类型的关键字之外，其他重要的关键字如下：gateway， broadcast，less， greater， 还有三种逻辑运算，取非运算是 ‘not ‘ ‘! ‘， 与运算是’and’，’&&’;或运算是’or’ ，’&#124;&#124;’； 这些关键字可以组合起来构成强大的组合条件来满足人们的需要。\n\n#### 用例\n\n```bash\n#默认启动，普通情况下，直接启动tcpdump将监视第一个网络接口上所有流过的数据包。\ntcpdump\n#监视指定网络接口的数据包\ntcpdump -i eth1\n#如果不指定网卡，默认tcpdump只会监视第一个网络接口，一般是eth0，下面的例子都没有指定网络接口。\n```\n```bash\n#监视指定主机的数据包，打印所有进入或离开sundown的数据包.\ntcpdump host sundown\n\n#也可以指定ip,例如截获所有210.27.48.1 的主机收到的和发出的所有的数据包\ntcpdump host 210.27.48.1\n#打印helios 与 hot 或者与 ace 之间通信的数据包\ntcpdump host helios and \\( hot or ace \\)\n#截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信\n#tcpdump host 210.27.48.1 and \\ (210.27.48.2 or 210.27.48.3 \\)\n#打印ace与任何其他主机之间通信的IP 数据包, 但不包括与helios之间的数据包.\ntcpdump ip host ace and not helios\n#如果想要获取主机210.27.48.1除了和主机210.27.48.2之外所有主机通信的ip包，使用命令：\ntcpdump ip host 210.27.48.1 and ! 210.27.48.2\n#截获主机hostname发送的所有数据\ntcpdump -i eth0 src host hostname\n#监视所有送到主机hostname的数据包\ntcpdump -i eth0 dst host hostname\n```\n```bash\n#监视指定主机和端口的数据包\n\n#如果想要获取主机210.27.48.1接收或发出的telnet包，使用如下命令\ntcpdump tcp port 23 and host 210.27.48.1\n#对本机的udp 123 端口进行监视 123 为ntp的服务端口\ntcpdump udp port 123 \n```\n```bash\n#监视指定网络的数据包\n#打印本地主机与Berkeley网络上的主机之间的所有通信数据包(nt: ucb-ether, 此处可理解为’Berkeley网络’的网络地址,此表达式最原始的含义可表达为: 打印网络地址为ucb-ether的所有数据包)\ntcpdump net ucb-ether\n#打印所有通过网关snup的ftp数据包(注意, 表达式被单引号括起来了, 这可以防止shell对其中的括号进行错误解析)\ntcpdump 'gateway snup and (port ftp or ftp-data)'\n#打印所有源地址或目标地址是本地主机的IP数据包\n#(如果本地网络通过网关连到了另一网络, 则另一网络并不能算作本地网络.(nt: 此句翻译曲折,需补充).localnet 实际使用时要真正替换成本地网络的名字)\ntcpdump ip and not net localnet\n```\n```bash\n#监视指定协议的数据包\n#打印TCP会话中的的开始和结束数据包, 并且数据包的源或目的不是本地网络上的主机.(nt: localnet, 实际使用时要真正替换成本地网络的名字))\ntcpdump 'tcp[tcpflags] & (tcp-syn|tcp-fin) != 0 and not src and dst net localnet'\n#打印所有源或目的端口是80, 网络层协议为IPv4, 并且含有数据,而不是SYN,FIN以及ACK-only等不含数据的数据包.(ipv6的版本的表达式可做练习)\ntcpdump 'tcp port 80 and (((ip[2:2] - ((ip[0]&0xf)<<2)) - ((tcp[12]&0xf0)>>2)) != 0)'\n#(nt: 可理解为, ip[2:2]表示整个ip数据包的长度, (ip[0]&0xf)<<2)表示ip数据包包头的长度(ip[0]&0xf代表包中的IHL域, 而此域的单位为32bit, 要换算\n#成字节数需要乘以4,　即左移2.　(tcp[12]&0xf0)>>4 表示tcp头的长度, 此域的单位也是32bit,　换算成比特数为 ((tcp[12]&0xf0) >> 4)　<<　２,　 \n#即 ((tcp[12]&0xf0)>>2).　((ip[2:2] - ((ip[0]&0xf)<<2)) - ((tcp[12]&0xf0)>>2)) != 0　表示: 整个ip数据包的长度减去ip头的长度,再减去 \n#tcp头的长度不为0, 这就意味着, ip数据包中确实是有数据.对于ipv6版本只需考虑ipv6头中的’Payload Length’ 与 ‘tcp头的长度’的差值, 并且其中表达方式’ip[]’需换成’ip6[]’.)\n#打印长度超过576字节, 并且网关地址是snup的IP数据包\ntcpdump 'gateway snup and ip[2:2] > 576'\n#打印所有IP层广播或多播的数据包， 但不是物理以太网层的广播或多播数据报\n#tcpdump 'ether[0] & 1 = 0 and ip[16] >= 224'\n#打印除’echo request’或者’echo reply’类型以外的ICMP数据包( 比如,需要打印所有非ping 程序产生的数据包时可用到此表达式 . \n#(nt: ‘echo reuqest’ 与 ‘echo reply’ 这两种类型的ICMP数据包通常由ping程序产生))\ntcpdump 'icmp[icmptype] != icmp-echo and icmp[icmptype] != icmp-echoreply'\n```\n#### tcpdump 与wireshark\n\n```bash\n#Wireshark(以前是ethereal)是Windows下非常简单易用的抓包工具。但在Linux下很难找到一个好用的图形化抓包工具。 还好有Tcpdump。我们可以用Tcpdump + Wireshark 的完美组合实现：在 Linux 里抓包，然后在Windows 里分析包。\n\ntcpdump tcp -i eth1 -t -s 0 -c 100 and dst port ! 22 and src net 192.168.1.0/24 -w ./target.cap\n\n#tcp: ip icmp arp rarp 和 tcp、udp、icmp这些选项等都要放到第一个参数的位置，用来过滤数据报的类型\n#-i eth1 : 只抓经过接口eth1的包\n#-t : 不显示时间戳\n#-s 0 : 抓取数据包时默认抓取长度为68字节。加上-S 0 后可以抓到完整的数据包\n#-c 100 : 只抓取100个数据包\n#dst port ! 22 : 不抓取目标端口是22的数据包\n#src net 192.168.1.0/24 : 数据包的源网络地址为192.168.1.0/24\n#-w ./target.cap : 保存成cap文件，方便用ethereal(即wireshark)分析\n```\n\n#### tcpdump抓取HTTP包\n\n```bash\ntcpdump  -XvvennSs 0 -i eth0 tcp[20:2]=0x4745 or tcp[20:2]=0x4854\n#0x4745 为”GET”前两个字母”GE”,0x4854 为”HTTP”前两个字母”HT”。\n#tcpdump 对截获的数据并没有进行彻底解码，数据包内的大部分内容是使用十六进制的形式直接打印输出的。显然这不利于分析网络故障，通常的解决办法是先使用带-w参数的tcpdump 截获数据并保存到文件中，然后再使用其他程序(如Wireshark)进行解码分析。当然也应该定义过滤规则，以避免捕获的数据包填满整个硬盘。\n\n#输出信息含义\n#首先我们注意一下，基本上tcpdump总的的输出格式为：系统时间 来源主机.端口 > 目标主机.端口 数据包参数\n#tcpdump 的输出格式与协议有关.以下简要描述了大部分常用的格式及相关例子. \n\n链路层头\n#对于FDDI网络, ‘-e’ 使tcpdump打印出指定数据包的’frame control’ 域, 源和目的地址, 以及包的长度.(frame control域 \n#控制对包中其他域的解析). 一般的包(比如那些IP datagrams)都是带有’async’(异步标志)的数据包，并且有取值0到7的优先级; \n#比如 ‘async4’就代表此包为异步数据包，并且优先级别为4. 通常认为,这些包们会内含一个 LLC包(逻辑链路控制包); 这时,如果此包 \n#不是一个ISO datagram或所谓的SNAP包，其LLC头部将会被打印(nt:应该是指此包内含的 LLC包的包头).\n#对于Token Ring网络(令牌环网络), ‘-e’ 使tcpdump打印出指定数据包的’frame control’和’access control’域, 以及源和目的地址, \n#外加包的长度. 与FDDI网络类似, 此数据包通常内含LLC数据包. 不管 是否有’-e’选项.对于此网络上的’source-routed’类型数据包(nt: \n#意译为:源地址被追踪的数据包,具体含义未知,需补充), 其包的源路由信息总会被打印.\n\n#对于802.11网络(WLAN,即wireless local area network), ‘-e’ 使tcpdump打印出指定数据包的’frame control域, \n#包头中包含的所有地址, 以及包的长度.与FDDI网络类似, 此数据包通常内含LLC数据包.\n\n#(注意: 以下的描述会假设你熟悉SLIP压缩算法 (nt:SLIP为Serial Line Internet Protocol.), 这个算法可以在 \nRFC-1144中找到相关的蛛丝马迹.)\n\n#对于SLIP网络(nt:SLIP links, 可理解为一个网络, 即通过串行线路建立的连接, 而一个简单的连接也可看成一个网络), \n#数据包的’direction indicator’(‘方向指示标志’)(“I”表示入, “O”表示出), 类型以及压缩信息将会被打印. 包类型会被首先打印.\n\n#类型分为ip, utcp以及ctcp(nt:未知, 需补充). 对于ip包,连接信息将不被打印(nt:SLIP连接上,ip包的连接信息可能无用或没有定义. \n#reconfirm).对于TCP数据包, 连接标识紧接着类型表示被打印. 如果此包被压缩, 其被编码过的头部将被打印. \n#此时对于特殊的压缩包,会如下显示: \n#*S+n 或者 *SA+n, 其中n代表包的(顺序号或(顺序号和应答号))增加或减少的数目(nt | rt:S,SA拗口, 需再译). \n#对于非特殊的压缩包,0个或更多的’改变’将会被打印.’改变’被打印时格式如下: \n#‘标志’+/-/=n 包数据的长度 压缩的头部长度. \n#其中’标志’可以取以下值: \n#U(代表紧急指针), W(指缓冲窗口), A(应答), S(序列号), I(包ID),而增量表达’=n’表示被赋予新的值, +/-表示增加或减少.\n\n#比如, 以下显示了对一个外发压缩TCP数据包的打印, 这个数据包隐含一个连接标识(connection identifier); 应答号增加了6, \n#顺序号增加了49, 包ID号增加了6; 包数据长度为3字节(octect), 压缩头部为6字节.(nt:如此看来这应该不是一个特殊的压缩数据包).\n\n\n```","tags":["网络工具"],"categories":["linux"]},{"title":"Linux更改系统时区是日期时间","url":"%2F2015%2F06%2F10%2FLinux%E6%9B%B4%E6%94%B9%E7%B3%BB%E7%BB%9F%E6%97%B6%E5%8C%BA%E6%98%AF%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%2F","content":"\n#### 查看时区\n\n\t命令 ： \"date -R\" 或者 more /etc/sysconfig/clock\n\n#### 修改设置时区\n\t方法 A\n\t命令 ： \"tzselect\"\n\n\t方法 B 仅限于RedHat Linux 和 CentOS\n\t命令 ： \"timeconfig\"\n\n\t方法 C 适用于Debian\n\t命令 ： \"dpkg-reconfigure tzdata\"\n<!--more-->\n\n#### 复制相应的时区文件，替换系统时区文件\n\tcp /usr/share/zoneinfo/$主时区/$次时区 /etc/localtime\n\t例如：在设置中国时区使用亚洲/上海（+8）\n\tcp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime\n\n\n#### 查看Linux的时间\n\t命令 ： \"date\"\n\n#### 设置时间和日期\n\t例如：将系统日期设定成2009年11月3日的命令\n\t命令 ： \"date -s 11/03/2009\"\n\n\t将系统时间设定成下午5点55分55秒的命令\n\t命令 ： \"date -s 17:55:55\"\n\n\tdate\n\t显示当前时间 Fri Aug  3 14:15:16 CST 2007\n\n\tdate -s \n\t按字符串方式修改时间\n\t可以只修改日期,不修改时间,输入: date -s 2007-08-03\n\t只修改时间,输入:date -s 14:15:00\n\t同时修改日期时间,注意要加双引号,日期与时间之间有一空格,输入:date -s \"2007-08-03 14:15:00\"\n\n\t修改完后,需要的话可以输入:clock -w \n\t把系统时间写入CMOS\n\n#### 将当前时间写入BIOS永久生效\n\thwclock\n\n#### 时区与UTC的偏移量描述 \n\tNZDT +13:00 新西兰白昼时间（夏时制） \n\tIDLE +12:00 国际日期变更线，东边 \n\tNZST +12:00 新西兰标准时间 \n\tNZT +12:00 新西兰时间 \n\tAESST +11:00 澳大利亚东部标准夏时制 \n\tACSST +10:30 中澳大利亚标准夏时制 \n\tCADT +10:30 中澳大利亚夏时制 \n\tSADT +10:30 南澳大利亚夏时制 \n\tAEST +10:00 澳大利亚东部标准时间 \n\tEAST +10:00 东澳大利亚标准时间 \n\tGST +10:00 关岛标准时间，（USSR Zone 9？） \n\tLIGT +10:00 澳大利亚墨尔本 \n\tACST +09:30 中澳大利亚标准时间 \n\tCAST +09:30 中澳大利亚标准时间 \n\tSAT +9:30 南澳大利亚标准时间 \n\tAWSST +9:00 澳大利亚西部标准夏时制 \n\tJST +9:00 日本标准时间，（USSR Zone 8） \n\tKST +9:00 韩国标准时间 \n\tWDT +9:00 西澳大利亚夏时制 \n\tMT +8:30 毛里求斯时间（？） \n\tAWST +8:00 澳大利亚西部标准时间 \n\tCCT +8:00 中国沿海时间 \n\tWADT +8:00 西澳大利亚夏时制 \n\tWST +8:00 西澳大利亚时间 \n\tJT +7:30 爪哇时间（译注：这里的 Java 可不是语言） \n\tWAST +7:00 西澳大利亚标准时间 \n\tIT +3:30 伊朗时间 \n\tBT +3:00 巴格达时间 \n\tEETDST +3:00 东欧夏时制 \n\tCETDST +2:00 中欧夏时制 \n\tEET +2:00 东欧，（USSR Zone 1） \n\tFWT +2:00 法国冬时制 \n\tIST +2:00 以色列标准时间 \n\tMEST +2:00 中欧夏时制 \n\tMETDST +2:00 中欧白昼时间 \n\tSST +2:00 瑞典夏时制 \n\tBST +1:00 英国夏时制 \n\tCET +1:00 中欧时间 \n\tDNT +1:00 Dansk Normal Tid（？） \n\tDST +1:00 Dansk Standard Time （？） \n\tFST +1:00 法国夏时制 \n\tMET +1:00 中欧时间 \n\tMEWT +1:00 中欧冬时制 \n\tMEZ +1:00 中欧时区 \n\tNOR +1:00 挪威标准时间 \n\tSET +1:00 Seychelles Time（？） \n\tSWT +1:00 瑞典冬时制 \n\tWETDST +1:00 西欧光照利用时间（夏时制） \n\tGMT 0:00 格林威治平均时间 \n\tWET 0:00 西欧 \n\tWAT -1:00 西非时间 \n\tNDT -2:30 纽芬兰（新大陆）白昼时间 \n\tADT -03:00 大西洋白昼时间 \n\tNFT -3:30 纽芬兰（新大陆）标准时间 \n\tNST -3:30 纽芬兰（新大陆）标准时间 \n\tAST -4:00 大西洋标准时间（加拿大） \n\tEDT -4:00 东部白昼时间 \n\tZP4 -4:00 GMT +4 小时 \n\tCDT -5:00 中部白昼时间 \n\tEST -5:00 东部标准时间 \n\tZP5 -5:00 GMT +5 小时 \n\tCST -6:00 中部标准时间 \n\tMDT -6:00 山区白昼时间（译注：Mountain Daylight Time那位知道怎么译？） \n\tZP6 -6:00 GMT +6 小时 \n\tMST -7:00 山区标准时间 \n\tPDT -7:00 太平洋白昼时间 \n\tPST -8:00 太平洋标准时间 \n\tYDT -8:00 Yukon 白昼时间 \n\tHDT -9:00 夏威仪/阿拉斯加白昼时间 \n\tYST -9:00 Yukon 标准时间 \n\tAHST -10:00 夏威仪-阿拉斯加标准时间 \n\tCAT -10:00 中阿拉斯加时间 \n\tNT -11:00 州时间（Nome Time） \n\tIDLW -12:00 国际日期变更线，西边","tags":["时区"],"categories":["linux"]},{"title":"linux常用的解压缩命令","url":"%2F2015%2F06%2F09%2Flinux%E5%B8%B8%E7%94%A8%E7%9A%84%E8%A7%A3%E5%8E%8B%E7%BC%A9%E5%91%BD%E4%BB%A4%2F","content":"\n#### .tar\n\n```bash\n#解包：\ntar xvf FileName.tar\n#打包：\ntar cvf FileName.tar DirName\n#（注：tar是打包，不是压缩！）\n```\n\n#### .gz\n\n```bash\n#解压1：\ngunzip FileName.gz\n#解压2：\ngzip -d FileName.gz\n#压缩：gzip FileName\n```\n<!--more-->\n#### .tar.gz 和 .tgz\n\n```bash\n#解压：\ntar zxvf FileName.tar.gz\n#压缩：\ntar zcvf FileName.tar.gz DirName\n```\n\n#### .bz2\n\n```bash\n#解压1：\nbzip2 -d FileName.bz2\n#解压2：\nbunzip2 FileName.bz2\n#压缩： \nbzip2 -z FileName\n```\n#### .tar.bz2\n\n```bash\n#解压：\ntar jxvf FileName.tar.bz2        \n#或\ntar --bzip xvf FileName.tar.bz2\n#压缩：\ntar jcvf FileName.tar.bz2 DirName\n```\n\n#### .bz\n\n```bash\n#解压1：\nbzip2 -d FileName.bz\n#解压2：\nbunzip2 FileName.bz\n#压缩：未知\n```\n#### .tar.bz\n\n```bash\n#解压：\ntar jxvf FileName.tar.bz\n#压缩：未知\n```\n\n#### .Z\n\n```bash\n#解压：\nuncompress FileName.Z\n#压缩：\ncompress FileName\n```\n#### .tar.Z\n\n```bash\n#解压：\ntar Zxvf FileName.tar.Z\n#压缩：\ntar Zcvf FileName.tar.Z DirName\n```\n\n#### .zip\n\n```bash\n#解压：\nunzip FileName.zip\n#压缩：\nzip FileName.zip DirName\n#压缩一个目录使用 -r 参数，-r 递归。\n#例： $ zip -r FileName.zip DirName\n```\n\n#### .rar\n\n```bash\n#解压：\nrar x FileName.rar\n#压缩：\nrar a FileName.rar DirName\n\n#rar请到：http://www.rarsoft.com/download.htm 下载！\n#解压后请将rar_static拷贝到/usr/bin目录（其他由$PATH环境变量指定的目录也可以）：\ncp rar_static /usr/bin/rar\n```\n\n#### .lha\n\n```bash\n#解压：\nlha -e FileName.lha\n#压缩：\nlha -a FileName.lha FileName\n\n#lha请到：http://www.infor.kanazawa-it.ac.jp/~ishii/lhaunix/下载！\n#解压后请将lha拷贝到/usr/bin目录（其他由$PATH环境变量指定的目录也可以）：\ncp lha /usr/bin/\n```\n\n#### .rpm\n\n```bash\n#解包：\nrpm2cpio FileName.rpm | cpio -div\n```\n\n#### .deb\n\n```bash\n#解包：\nar p FileName.deb data.tar.gz | tar zxf -\n```\n\n#### .tar .tgz .tar.gz .tar.Z .tar.bz .tar.bz2 .zip .cpio .rpm .deb .slp .arj .rar .ace .lha .lzh .lzx .lzs .arc .sda .sfx .lnx .zoo .cab .kar .cpt .pit .sit .sea\n\n```bash\n#解压：\nsEx x FileName.*\n#压缩：\nsEx a FileName.* FileName\n\n#sEx只是调用相关程序，本身并无压缩、解压功能，请注意！\n#sEx请到： http://sourceforge.net/projects/sex 下载！\n#解压后请将sEx拷贝到/usr/bin目录（其他由$PATH环境变量指定的目录也可以）：\ncp sEx /usr/bin/\n```\n\n\n","tags":["解压缩"],"categories":["linux"]},{"title":"VIM快捷操作键盘图","url":"%2F2015%2F05%2F09%2FVIM%20%E5%BF%AB%E6%8D%B7%E6%93%8D%E4%BD%9C%E9%94%AE%E7%9B%98%E5%9B%BE%2F","content":"![vim](http://pezelc0cd.bkt.clouddn.com/image/vim.pngvim.png)\n","tags":["vim"],"categories":["linux"]},{"title":"windows下ddos攻击的现象分析及解决方案","url":"%2F2015%2F05%2F09%2Fwindows%E4%B8%8Bddos%E6%94%BB%E5%87%BB%E7%9A%84%E7%8E%B0%E8%B1%A1%E5%88%86%E6%9E%90%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F","content":"\n#### 现象分析\n\t网站服务器运营商的互联网接入形式主要有两种： 一种是主机托管，另外一种是自拉网络专线，但基于接入费用的考虑，绝大多数采用前者，但也有不少网吧主会采用后者。无论是前者还是后者接入，在正常情况下，用户都可以正常访问网站，浏览网页、在线听音乐看电影或者是参与论坛发帖，假定可排除线路和硬件故障的情况下，突然发现网页打不开或打开连接服务器困难，正在游戏的用户掉线等现象，则说明很有可能是遭受了DDOS攻击，具体判定方法如下：\n<!--more-->\n\t1、服务器端分析方法\n\n\t（1）SYNFlood攻击判定\n\t A：网上邻居->右键选“属性”->双击网卡，每秒收到的包数量大于500。\n\t B：开始->程序->附件->命令提示符->C:\\>netstat –na，观察到大量的SYN_RECEIVED的连接状态。\n\t C：网线插上后，服务器立即凝固无法操作，拔出后有时可以恢复，有时候需要重新启动机器才可恢复。\n\n\t（2）TCP多连接攻击判定\n\t 开始->程序->附件->命令提示符->C:\\>netstat –na，若观察到多个IP地址与本机的服务端口建立了几十个以上的ESTABLISHED状态的连接。\n\n\t2、客户端现象\n\t（1）用户无法访问网站页面或打开过程非常缓慢。\n\t（2）正在访问的用户突然变得非常缓慢甚至中断。\n\n#### 解决方案\n\t多年的统计数据表明，想彻底解决DDOS是几乎不可能的，就好比治疗感冒一样，我们可以治疗，也可以预防，但却无法根治，但我们若采取积极有效的防御方法，则可在很大程度上降低或减缓生病的机率，防治DDOS攻击也是如此，拥有充足的带宽和配置足够高的主机硬件是必需的，那么什么算是充足的带宽呢？一般来说至少应该是100M共享，那么什么算配置足够高的主机硬件呢？一般来说至少应该是P4 2.4G的CPU、512M内存和Intel等品牌网卡。拥有此配置的带宽和主机理论上可应对每秒20万以上的SYN攻击，但这需要借助于专业配置和专用软件才可实现，默认情况下，绝大多数服务器难以抵御每秒1000个以上SYN的攻击。\n\n \t1、免费DDOS解决方案\n\n\t通过优化Windows 2000或2003系统的注册表，可有效对抗每秒约1万个左右的SYN攻击，方法是把以下文本内容存盘为antiddos.reg然后导入注册表并重新启动即可，当然也可从地址 http://www.bingdun.com/tools/antiddos.reg 直接下载antiddos.reg文件。\n\n\tWindows Registry Editor Version 5.00\n\t[HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters]\n\n\t\"SynAttackProtect\"=dword:00000002\n\n\t\"TcpMaxHalfOpen\"=dword:000001f4\n\n\t\"TcpMaxHalfOpenRetried\"=dword:00000190\n\n     此方案的优点是，采用系统自身的能力来解决问题，而无需任何花费，缺点是只能抵御每秒少于10000的SYN攻击，并且无法解决TCP多连接攻击。\n\n \t2、商用DDOS解决方案\n\n\t在面对每秒多于10000的SYN攻击或是TCP多连接攻击的情况下，就必需采用商用解决方案了，\n\t商业解决方案一般是寻求第三方的产品如各种防护盾或者请专业的公司来解决。","tags":["攻击"],"categories":["网络安全"]},{"title":"Shell的时间的获取与格式化输出","url":"%2F2015%2F05%2F09%2Fshell%E7%9A%84%E6%97%B6%E9%97%B4%E8%8E%B7%E5%8F%96%E4%B8%8E%E6%A0%BC%E5%BC%8F%E5%8C%96%E8%BE%93%E5%87%BA%2F","content":"\n#### 获取当天日期\n\n```bash\ndate +%Y-%m-%d\n#输出： 2011-07-28\n```\n#### 将当前日期赋值给DATE变量\n\n```bash\nDATE=$(date +%Y%m%d)\n\n```\n<!--more-->\n#### 使用今天之前或者往后的日期\n\n```bash\n#获取明天的日期\ndate -d next-day +%Y%m%d\n#获取昨天的日期\ndate -d last-day +%Y%m%d\n#获取上个月的年和月\ndate -d last-month +%Y%m\n#获取下个月的年和月\ndate -d next-month +%Y%m\n#获取明年的年份\ndate -d next-year +%Y\n#获取7天前\ndata -d \"7 days ago\" +%Y%m%d\n```\n#### 格式化详细说明\n\n```bash\n#date 能用来显示或设定系统的日期和时间，在显示方面，使用者能设定欲显示的格式，格式设定为一个加号后接数个标记，其中可用的标记列表如下 : \n\n#时间方面 : \n% : 印出 \n% %n : 下一行 \n%t : 跳格 \n%H : 小时(00..23) \n%I : 小时(01..12) \n%k : 小时(0..23) \n%l : 小时(1..12) \n%M : 分钟(00..59) \n%p : 显示本地 AM 或 PM \n%r : 直接显示时间 (12 小时制，格式为 hh:mm:ss [AP]M) \n%s : 从 1970 年 1 月 1 日 00:00:00 UTC 到目前为止的秒数 %S : 秒(00..61) \n%T : 直接显示时间 (24 小时制) \n%X : 相当于 %H:%M:%S \n%Z : 显示时区 \n\n#日期方面 : \n%a : 星期几 (Sun..Sat) \n%A : 星期几 (Sunday..Saturday) \n%b : 月份 (Jan..Dec) \n%B : 月份 (January..December) \n%c : 直接显示日期和时间 \n%d : 日 (01..31) \n%D : 直接显示日期 (mm/dd/yy) \n%h : 同 %b \n%j : 一年中的第几天 (001..366) \n%m : 月份 (01..12) \n%U : 一年中的第几周 (00..53) (以 Sunday 为一周的第一天的情形) \n%w : 一周中的第几天 (0..6) \n%W : 一年中的第几周 (00..53) (以 Monday 为一周的第一天的情形) \n%x : 直接显示日期 (mm/dd/yy) \n%y : 年份的最后两位数字 (00.99) \n%Y : 完整年份 (0000..9999) \n\n#若是不以加号作为开头，则表示要设定时间，而时间格式为 MMDDhhmm[[CC]YY][.ss]， \n#其中 MM 为月份， \nDD 为日， \nhh 为小时， \nmm 为分钟， \nCC 为年份前两位数字， \nYY 为年份后两位数字， \nss 为秒数 \n\n#把计 : \n-d datestr : 显示 datestr 中所设定的时间 (非系统时间) \n--help : 显示辅助讯息 \n-s datestr : 将系统时间设为 datestr 中所设定的时间 \n-u : 显示目前的格林威治时间 \n--version : 显示版本编号 \n\n#例子 : \n#显示时间后跳行，再显示目前日期 : \ndate +%T%n%D \n#显示月份和日数 : \ndate +%B %d \n#显示日期和设定时间(12:34:56) : \ndate --date 12:34:56 \n#设置系统当前时间（12:34:56）：\ndate --s 12:34:56 \n#注意 : 当你不希望出现无意义的 0 时(比如说 1999/03/07)，则能在标记中插入 - 符号，比如说 date +%-H:%-M:%-S 会把时分秒中无意义的 0 给去掉，像是原本的 08:09:04 会变为 8:9:4。另外，只有取得权限者(比如说 root)才能设定系统时间。 当你以 root 身分更改了系统时间之后，请记得以 clock -w 来将系统时间写入 CMOS 中，这样下次重新开机时系统时间才会持续抱持最新的正确值。 \n\n#ntp时间同步 \n#linux系统下默认安装了ntp服务，手动进行ntp同步如下 \nntpdate ntp1.nl.net \n#当然，也能指定其他的ntp服务器 \n```\n","tags":["shell"],"categories":["linux"]},{"title":"shell 常用的操作技巧","url":"%2F2015%2F05%2F09%2Fshell%20%E5%B8%B8%E7%94%A8%E7%9A%84%E6%93%8D%E4%BD%9C%E6%8A%80%E5%B7%A7%2F","content":"\n#### 重定向操作\n    #0 stdin标准输入\n    #1 stdout标准输出   \n    #2 stderr标准错误\n\n    #文件打开模式：\n    #> 等同于1> 截断模式\n    #>>等同于1>> 追加模式\n    #<用于从文件中读取至stdin 只读模式\n\n    #stdout不会有任何输出，因为错误已经重定向到out.txt中了\n    ls + 2> out.txt\n    #可以将stderr单独重定向到一个文件，将stdout重定向到另一个文件：\n    cmd 2>stderr.txt 1>stdout.txt\n    #将stderr转换成stdout，使得stderr和stdout都被重定向到同一个文件：\n    cmd 2>&1 output.txt\n    #或者\n    cmd &> output.txt\n<!--more-->\n    #将stderr输出丢弃\n    some_command 2> /dev/null\n\n    #将文件重定向到命令\n    cmd < file\n\n    #向log文件中写入头部数据\n    #!/bin/bash\n    cat <<EOF>log..tt\n    LOG FILE HEADER\n    this is a test log file\n    EOF\n\n    #cmd >a 2>a 和 cmd >a 2>&1 为什么不同？\n    #cmd >a 2>a ：stdout和stderr都直接送往文件a ，a文件会被打开两遍 ，由此导致stdout和stderr互相覆盖。\n    #cmd >a 2>&1 ：stdout直接送往文件a ，stderr是继承了FD1的管道之后，再被送往文件a 。a文件只被打开一遍，就是FD1将其打开\n    #他们的不同点在于：\n    #cmd >a 2>a 相当于使用了FD1、FD2两个互相竞争使用文件 a 的管道； \n    #而cmd >a 2>&1 只使用了一个管道FD1， 但已经包括了stdout和stderr。\n    #从IO效率上来讲，cmd >a 2>&1的效率更高。\n\n#### History\n\n    |命令 | 说明  |\n    | ------------ | ------------ |\n    |^foo| 删除上一条命令中的foo|\n    |^foo^bar|将上一条命令的第一个foo改为bar|\n    |!!|重新执行上一条命令|\n    |!N|重新执行第N条命令|\n    |!-N|重新执行倒数第N条命令|\n    |!string|重新执行以字符串开头的命令|\n    |!?string?|重新执行包含字符串的命令|\n    | !$|上一条命令的最后一个参数|\n    |!^|上一条命令的第一个参数|\n    |!cmd:n|上一条命令的第n个参数|\n    |!*|上一条命令的所有参数|\n    |!*:x|x表示修饰符|\n\n    实例演示：\n    ```bash\n    root@ADT:~# rm /usr/lib/libtpn_http.so \n    root@ADT:~# cd !:$:h #切换到/usr/lib目录下\n```\n#### 移动类\n\n    移到命令行首：`Ctrl + a(head)`\n    移到命令行尾：`Ctrl + e(nd) `\n    在命令行首和光标之间位置切换：`Ctrl + x + x `\n    右向按字符前移：`Ctrl + f(orward) `\n    左向按字符后移：`Ctrl + b(ackward) `\n\n#### 删除类\n    注释当前行：`Alt + # `\n    从光标处删除至命令行首：`Ctrl + u `\n    从光标处删除至命令行尾：`Ctrl + k `\n    从光标处删除至字首(以空格作为word边界)：`Ctrl + w `\n    从光标处删除至字首(以空格，斜线，点号作为word边界)：`ESC + Backspace `\n    从光标处删除至字尾：`Alt + d `\n    删除光标处的字符：`Ctrl + d `\n    删除光标前的字符：`Ctrl + h `\n    粘贴至光标后：`Ctrl + y `\n    重新调用前一个命令中的参数,非常有用!：`Esc+.`\n\n#### 大小写快速转换\n    从光标处更改为首字母大写的单词：`Alt + c `\n    从光标处更改为全部大写的单词：`Alt + u `\n    从光标处更改为全部小写的单词：`Alt + l `\n\n#### 顺序快速调换\n    交换光标处和之前的单词：`Alt + t `\n    交换光标处和之前的字符：`Ctrl + t `\n\n#### 撤销修改\n    C-/ 或 C-_\n    撤销当前行的所有内容：`Alt+r`\n\n#### 清屏\n    清屏：`Ctrl + l`\n    clear\n\n#### 查找历史命令\n    逆向搜索历史命令行和当前命令行：`Ctrl + r`\n    TIPS　: 在当前行中搜索,可以快速定位到需要修改的字符:Ｐ\n    终止搜索并还原原始命令行：`Ctrl + g`\n    终止搜索并停留在查找的位置，直接使用ESC也可以实现该功能：`Ctrl + j`\n    历史中的上一条命令：`Ctrl + p`\n    历史中的下一条命令：`Ctrl + n`\n    非增量搜索：`alt + n\\p`\n    执行当前命令，并选择上一条命令：`Ctrl + o`\n","tags":["技巧"],"categories":["linux"]},{"title":"Cobbler安装部署","url":"%2F2015%2F04%2F16%2FCobbler%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%2F","content":"\n#### 关闭Selinux和防火墙\n\n```bash\nsed -i '/SELINUX/s/enforcing/disabled/' /etc/selinux/config\nsystemctl stop firewalld\nsystemctl disable firewalld\n```\n\n#### 安装 epel 包\n\n```bash\nrpm -ivh http://dl.fedoraproject.org/pub/epel/7/x86_64/Packages/e/epel-release-7-11.noarch.rpm\n```\n\n#### 安装cobbler、cobbler-web 以及相关依赖软件\n\n```bash\nyum install cobbler cobbler-web xinetd pykickstart cman dhcp debmirror fence-agents -y\nsed -i  's|@dists=.*|#@dists=|'  /etc/debmirror.conf\nsed -i  's|@arches=.*|#@arches=|'  /etc/debmirror.conf\n```\n<!--more-->\n#### TFTP配置\n\n```bash\nsed -i '/disable/s/yes/no/' /etc/xinetd.d/tftp\ncat /etc/xinetd.d/tftp\n{\n        disable                 = no\n        socket_type             = dgram\n        protocol                = udp\n        wait                    = yes\n        user                    = root\n        server                  = /usr/sbin/in.tftpd\n        server_args             = -B 1380 -v -s /var/lib/tftpboot\n        per_source              = 11\n        cps                     = 100 2\n        flags                   = IPv4\n}\n```\n\n#### 配置/etc/cobbler/settings\n\n```bash\nsed -i 's/manage_dhcp: 0/manage_dhcp: 1/g' /etc/cobbler/settings\nsed -i 's/manage_rsync: 0/manage_rsync: 1/g' /etc/cobbler/settings\nsed -i 's/manage_tftpd: 0/manage_tftpd: 1/g' /etc/cobbler/settings\nsed -i 's/pxe_just_once: 0/pxe_just_once: 1/g' /etc/cobbler/settings\nsed -i 's/allow_dynamic_settings: 0/allow_dynamic_settings: 1/g' /etc/cobbler/settings\nsed -i '/next_server/s/127.0.0.1/192.168.3.70/' /etc/cobbler/settings\nsed -i '/server/s/127.0.0.1/192.168.3.70/' /etc/cobbler/settings\n#修改为以下内容\nmanage_dhcp: 1\nmanage_rsync: 1\nmanage_tftpd: 1\npxe_just_once: 1\nallow_dynamic_settings: 1\nnext_server: 192.168.11.252\nserver: 192.168.11.252 #本机ip地址\n```\n\n#### 修改/etc/cobbler/dhcp.template\n\n```bash\nddns-update-style interim;\nallow booting;\nallow bootp;\nignore client-updates;\nset vendorclass = option vendor-class-identifier;\noption pxe-system-type code 93 = unsigned integer 16;\nsubnet 192.168.11.0 netmask 255.255.255.0 {\n     option routers             192.168.11.252;\n     option domain-name-servers 192.168.11.252;\n     option subnet-mask         255.255.255.0;\n     range dynamic-bootp        192.168.11.100 192.168.11.200;\n     default-lease-time         21600;\n     max-lease-time             43200;\n     next-server                $next_server;\n     class \"pxeclients\" {\n          match if substring (option vendor-class-identifier, 0, 9) = \"PXEClient\";\n          if option pxe-system-type = 00:02 {\n                  filename \"ia64/elilo.efi\";\n          } else if option pxe-system-type = 00:06 {\n                  filename \"grub/grub-x86.efi\";\n          } else if option pxe-system-type = 00:07 {\n                  filename \"grub/grub-x86_64.efi\";\n          } else {\n                  filename \"pxelinux.0\";\n          }\n     }\n}\n    ## group could be subnet if your dhcp tags line up with your subnets\n    ## or really any valid dhcpd.conf construct ... if you only use the\n    ## default dhcp tag in cobbler, the group block can be deleted for a\n    ## flat configuration\ngroup {\n        #for mac in $dhcp_tags[$dhcp_tag].keys():\n            #set iface = $dhcp_tags[$dhcp_tag][$mac]\n    host $iface.name {\n        hardware ethernet $mac;\n        #if $iface.ip_address:\n        fixed-address $iface.ip_address;\n        #end if\n        #if $iface.hostname:\n        option host-name \"$iface.hostname\";\n        #end if\n        #if $iface.netmask:\n        option subnet-mask $iface.netmask;\n        #end if\n        #if $iface.gateway:\n        option routers $iface.gateway;\n        #end if\n        #if $iface.enable_gpxe:\n        if exists user-class and option user-class = \"gPXE\" {\n            filename \"http://$cobbler_server/cblr/svc/op/gpxe/system/$iface.owner\";\n        } else if exists user-class and option user-class = \"iPXE\" {\n            filename \"http://$cobbler_server/cblr/svc/op/gpxe/system/$iface.owner\";\n        } else {\n            filename \"undionly.kpxe\";\n        }\n        #else\n        filename \"$iface.filename\";\n        #end if\n        ## Cobbler defaults to $next_server, but some users\n        ## may like to use $iface.system.server for proxied setups\n        next-server $next_server;\n        ## next-server $iface.next_server;\n    }\n        #end for\n}\n```\n#### 设置密码\n\n```bash\nopenssl passwd -1 -salt 'dachen@123' 'dachen@123'\n$1$dachen@1$jmVIcCglAimHTBe5voHPU0\n#将生成的结果替换掉default_password_crypted: \"$1$mF86/UHC$WvcIcX2t6crBz2onWxyac.\"，默认密码是cobbler\n```\n- 启动相关服务，并设置开机启动\n\n```bash\ncobbler sync\n\nsystemctl start httpd\nsystemctl start dhcpd\nsystemctl start cobblerd\nsystemctl start xinetd\nsystemctl start rsyncd\n\nsystemctl enable httpd\nsystemctl enable dhcpd\nsystemctl enable cobblerd\nsystemctl enable xinetd\nsystemctl enable rsyncd\n```\n\n#### 检查\n\n```bash\ncobbler get-loaders\ncobbler check\n#检查后解决问题\n```\n\n#### 导入系统镜像\n\n```bash\nmkdir -p /system/centos72\nmount -o loop ~/centos.iso /system/centos72/\ncobbler import --path=/system/centos72/ --name=centos72 --arch=x86_64\n\ncobbler sync\n```\n\n#### 常用操作\n\n```bash\n#重新指定ks文件\ncobbler profile edit --name=centos72-x86_64 --kickstart=/var/lib/cobbler/kickstarts/centos72.ks\n```\n\n\nhttps://blog.csdn.net/kissing_hu/article/details/42239111","tags":["自动化"],"categories":["linux"]},{"title":"DOS与DDOS攻击的原理","url":"%2F2015%2F04%2F16%2FDOS%E4%B8%8EDDOS%E6%94%BB%E5%87%BB%E7%9A%84%E5%8E%9F%E7%90%86%2F","content":"\n在了解分布式拒绝服务攻击的原理之前，先要了解以下两个关键的基础原理\n\n#### TCP饿死：\n\tUDP这种传输方式不会控制自己在通信通道里的流量，可理解为不讲道理的人。他们来到了一个热闹地区的KFC中，但是他们不买东西只排队将所有食物的价格都问一遍，占满所有的座位和过道。而常规的TCP服务通过自己的弹窗机制来控制流量，好比讲道理的人，座位被占满了，TCP自然会离开KFC导致正常的服务不能进行。最终的结果就是UDP将整个通道打满堵死。\n\n\n\n#### TCP三次握手和四次断开连接：\n<!--more-->\n\t文字说不清楚，见下图：\n![](http://111.230.96.161/server/../Public/Uploads/2018-05-24/5b0625b563f7c.png)\n![](http://111.230.96.161/server/../Public/Uploads/2018-05-24/5b0625d4afbad.png)\n![](http://111.230.96.161/server/../Public/Uploads/2018-05-24/5b0625f7ec313.png)\n\tseq:序列号；ack:确认序列号,双方均需要确认才可断开连接\n\n#### 关于双方在整个过程中每个时间段的状态名称\n![](http://111.230.96.161/server/../Public/Uploads/2018-05-24/5b062641ba51a.png)\n\n\t分析完以上的两个原理便可继续\n\tDOS攻击：一台或多台计算机对受攻击服务器的某一个端口发送大量无关的UDP报文，导致整个通道内的正常服务无法进行。\n\tDDOS攻击：大量的肉鸡对服务器的不同端口发送巨型流量的UDP报文，无法通关关闭端口的方式来进行隔离，破坏力极强，严重会造成服务器当机。\n\t根据攻击的时间和方式又可分将DDOS为以下几种\n\n1.SYN Flood\n![](http://111.230.96.161/server/../Public/Uploads/2018-05-24/5b06265760586.png)\n\n\n2.ACK Flood\n![](http://111.230.96.161/server/../Public/Uploads/2018-05-24/5b06265f45e5a.png)\n\n\n3.Connection Flood\n![](http://111.230.96.161/server/../Public/Uploads/2018-05-24/5b06266ab92ae.png)\n\n\n4.HTTP Get Flood\n![](http://111.230.96.161/server/../Public/Uploads/2018-05-24/5b06266f12b20.png)\n\n\n#### 对TCP饿死的应对方案\n\t1.增加带宽，堵死了再买\n\t2.CDN，各地部署子服务器，当子服务遭受到攻击时，其他地区的服务器和主服务器不会受到影响。\n\t3.BGP流量清洗，通过BGP将通道内的无用UDP报文清洗干净再转给服务器\n\n","tags":["攻击"],"categories":["网络安全"]},{"title":"DDOS原理概述及其防御","url":"%2F2015%2F04%2F16%2FDDOS%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0%E5%8F%8A%E5%85%B6%E9%98%B2%E5%BE%A1%2F","content":"\n#### 拒绝服务攻击概述\n\nDoS（Denial of Service,拒绝服务）攻击\n广义而言，凡是利用网络安全防护措施不足导致用户不能或不敢继续使用正常服务的攻击手段，都称之为拒绝服务攻击。其目的是通过消耗网络带宽或系统资源，使网络或计算机不能提供正常的服务。\nDDoS（Distributed Denial of Service, DDoS）\n指攻击者通过控制在网络各处的数百甚至数千傀儡主机（又称为肉鸡），发动它们同时向目标进行拒绝服务攻击。\n\n#### 拒绝服务攻击原理\n\nDDoS攻击原理\n借助客户/服务器技术，将多个计算机联合起来作为攻击平台，对一个或多个目标发动DoS攻击。\n<!--more-->\n![](http://111.230.96.161/server/../Public/Uploads/2018-05-24/5b062804bac3e.png)\n\n#### 拒绝服务攻击手段\n\t死亡之ping(ping of death)\n\t如ping –l65535 192.168.1.1\n  \t系统会提示Badvalue for option –l, valid range is from 0 to 65500\n\t现在绝大多数操作系统进行了漏洞修补。\n\t中美黑客大战用过，8万人对美国白宫官方网站使用ping\n\n\n#### SYN泛洪(SYNflood)\n\t专门针对TCP的3次握手过程中两台主机间初始化连接握手进行攻击。\n\t攻击方利用虚假源地址向服务器发送TCP连接请求，服务器回复SYN+ACK数据包。由于发送请求的源地址是假地址，服务器不会得到确认，服务器一般会重试发送SYN+ACK，并等待一段时间（大约30秒-2分钟）后丢弃这个连接，在等待的时间内服务器处于半连接状态，会消耗调资源。当大量的虚假SYN请求到来，会占用服务器的大量资源从而使得目标主机不能向正常请求提供服务。\n\n#### UDP泛洪\n\t攻击者发送大量伪造源IP地址的小UDP数据包。只要用户开一个UDP端口提供相关服务，就可以针对该服务进行攻击。\n\n#### Land攻击\n\t由黑客组织Rootshell发现的，攻击目标是TCP三次握手。\n\t利用一个特别打造的SYN包--它的原地址和目标地址（相同）都被设置成某一个服务器地址进行攻击。这将导致接受服务器向它自己的地址发送SYN+ACK消息，结果这个地址又发回ACK消息并创建一个空连接，每一个这样的连接都将保留直到超时，在Land攻击下，许多UNIX将崩溃，NT变得极其缓慢（大约持续五分钟）。\n\n#### Smurf攻击\n\t攻击者向一个子网的广播地址发送一个带有特定请求（如ping ）的包，并且将源地址伪装成要攻击的主机地址。子网上所有主机都回应广播包的请求，向被攻击主机发送应答，使得网络的带宽下降，严重情况会导致受害主机崩溃。\n实施：ping请求 源地址：受害方，目的地址：广播地址\n\n\n#### SYN变种攻击\n\t发送伪造源IP的SYN数据包，但数据报不是64字节而是上千字节，这种攻击造成防火墙错误锁死，消耗服务器资源，阻塞网络。\n\n#### TCP混乱数据包攻击\n\t发送伪造源IP的TCP数据包，TCP头部的TCPFlags部分混乱（如syn,ack,syn+ack,syn+rst），会造成防火墙错误锁死，消耗服务器资源，阻塞网络\n\n#### 泪滴攻击（分片攻击）\n\t泪滴（Teardrop）攻击是利用TCP/IP协议的漏洞进行DoS攻击的方式。\n\t攻击者向目的主机发送有重叠偏移量的伪造IP分片数据包，目的主机在重组含有偏移量重叠的数据包时会引起协议栈崩溃。\n\n#### IP欺骗DoS\n\t攻击者向目的主机发送大量伪造源IP地址（合法用户，已经建立连接）、RST置位的数据包，致使目的主机清空已经建好的连接，从而实现DoS。\n\n#### 针对Web Server的多连接攻击\n\t通过控制大量“肉鸡”同时访问某网站，造成网站无法正常处理请求而瘫痪。\n\n#### 针对Web Server的变种攻击\n\t通过控制大量“肉鸡”同时连接网站，不发送GET请求而是发送乱七八糟的字符，绕过防火墙的检测，造成服务器瘫痪。\n\n#### 拒绝服务攻击的防范\n\n\tDoS特征：\n\t攻击流量的目的地过于集中，且无拥塞控制特性。\n\tDoS攻击流量不会考虑网络拥塞，攻击流量持续不断，出现网络拥塞仍然大量发包，大量无用的数据包加剧网络拥塞，数据包中的源地址一般为伪造。\n\tTCP/UDP流量流向目的端口太多或者目的端口过于集中。\n\t用随机端口攻击目标机，会出现同时向目标机的数千端口发送数据包；用固定端口攻击目标机，会出现同时向目标机的单一端口发送大量数据包。\n\n\tDoS检测：\n\t基于流量大小的检测\n\t在被保护网络边界（如边界路由器）上部署流量检测算法，根据流量的突发变化检测DoS/DDoS攻击的发生。\n\t基于源IP地址的检测\n\t在被保护网络的边界路由器上部署源IP检测算法，根据源IP个数的变化来判断DoS/DDoS攻击的发生。正常情况下，一个新的时间段的心IP地址基本呈均匀分布。\n\t基于包属性的检测\n\t在DoS攻击时，攻击数据包破坏了正常网络状况下进出数据包在IP数据包头字段的统计学稳定性，因此可以采用一定的算法在正常情况下进行包属性字段的学习，从而有效地判断进出数据包的危险度，进而检测DoS/DDoS攻击。\n\n\n\tDoS防范：\n\t增强系统自身的防御能力，防止僵死程序的植入\n\t关闭不必要的服务和端口\n\t及时更新系统补丁\n\t安装查杀病毒的软硬件产品，及时更新病毒库\n\t设置复杂口令，降低系统被控制的可能性\n\t经常检测网络和主机的脆弱性，查看网上漏洞数据库，以减少或避免主机成为“肉鸡”的可能性\n\t重要Web服务器，为一个域建立多个镜像实现负载均衡，在一定程度上减轻DDoS攻击的危害","tags":["攻击"],"categories":["网络安全"]},{"title":"DDoS攻击、CC攻击的攻击方式和防御方法","url":"%2F2015%2F04%2F16%2FDDoS%E6%94%BB%E5%87%BB%E3%80%81CC%E6%94%BB%E5%87%BB%E7%9A%84%E6%94%BB%E5%87%BB%E6%96%B9%E5%BC%8F%E5%92%8C%E9%98%B2%E5%BE%A1%E6%96%B9%E6%B3%95%2F","content":"\n#### DDoS介绍\n\tDDoS是英文Distributed Denial of Service的缩写，意即“分布式拒绝服务”，那么什么又是拒绝服务（Denial of Service）呢？可以这么理解，凡是能导致合法用户不能够访问正常网络服务的行为都算是拒绝服务攻击。也就是说拒绝服务攻击的目的非常明确，就是要阻止合法用户对正常网络资源的访问，从而达成攻击者不可告人的目的。分布式拒绝服务攻击一旦被实施，攻击网络包就会从很多DOS攻击源(俗称肉鸡)犹如洪水般涌向受害主机，从而把合法用户的网络包淹没，导致合法用户无法正常访问服务器的网络资源，因此，拒绝服务攻击又被称之为“洪水式攻击”，常见的DDOS攻击手段有SYN Flood、ACK Flood、UDP Flood、ICMP Flood、TCP Flood、Connections Flood、Script Flood、Proxy Flood等。\n\n\t目前而言，黑客甚至对攻击进行明码标价，打1G的流量到一个网站一小时，只需50块钱。DDoS的成本如此之低，而且攻击了也没人管。\n<!--more-->\n \n\n#### 关于DDos攻击的常见方法\n\t1. SYN Flood：利用TCP协议的原理，这种攻击方法是经典最有效的DDOS方法，可通杀各种系统的网络服务，主要是通过向受害主机发送大量伪造源IP和源端口的SYN或ACK 包，导致主机的缓存资源被耗尽或忙于发送回应包而造成拒绝服务。TCP通道在建立以前，需要三次握手：\n\ta. 客户端发送一个包含SYN标志的TCP报文， 同步报文指明客户端所需要的端口号和TCP连接的初始序列号\n\tb. 服务器收到SYN报文之后，返回一个SYN+ ACK报文，表示客户端请求被接受，TCP初始序列号加1\n\tc.客户端也返回一个确认报文ACK给服务器，同样TCP序列号加1\n\td. 如果服务器端没有收到客户端的确认报文ACK，则处于等待状态，将该客户IP加入等待队列，然后轮训发送SYN+ACK报文\n\t所以攻击者可以通过伪造大量的TCP握手请求，耗尽服务器端的资源。\n\n\t2. HTTP Flood：针对系统的每个Web页面，或者资源，或者Rest API，用大量肉鸡，发送大量http request。这种攻击主要是针对存在ASP、JSP、PHP、CGI等脚本程序，并调用MSSQLServer、MySQLServer、Oracle等数据库的网站系统而设计的，特征是和服务器建立正常的TCP连接，并不断的向脚本程序提交查询、列表等大量耗费数据库资源的调用，典型的以小博大的攻击方法。缺点是对付只有静态页面的网站效果会大打折扣。\n\n\t3. 慢速攻击：Http协议中规定，HttpRequest以\\r\\n\\r\\n结尾来表示客户端发送结束。攻击者打开一个Http 1.1的连接，将Connection设置为Keep-Alive， 保持和服务器的TCP长连接。然后始终不发送\\r\\n\\r\\n， 每隔几分钟写入一些无意义的数据流， 拖死机器。\n\n\t4. P2P攻击：每当网络上出现一个热门事件，比如XX门， 精心制作一个种子， 里面包含正确的文件下载， 同时也包括攻击目标服务器的IP。这样，当很多人下载的时候， 会无意中发起对目标服务器的TCP连接。\n\n \n\n#### DDOS攻击现象判定方法\n\t1.SYN类攻击判断：A.CPU占用很高；B.网络连接状态：netstat –na,若观察到大量的SYN_RECEIVED的连接状态；C.网线插上后，服务器立即凝固无法操作，拔出后有时可以恢复，有时候需要重新启动机器才可恢复。\n\t2.CC类攻击判断：A.网站出现service unavailable提示；B.CPU占用率很高；C.网络连接状态：netstat –na,若观察到大量的ESTABLISHED的连接状态 单个IP高达几十条甚至上百条；D.用户无法访问网站页面或打开过程非常缓慢,软重启后短期内恢复正常,几分钟后又无法访问。\n\t3.UDP类攻击判断：A.观察网卡状况 每秒接受大量的数据包；B.网络状态：netstat –na TCP信息正常。\n\t4.TCP洪水攻击判断：A.CPU占用很高；B.netstat –na,若观察到大量的ESTABLISHED的连接状态 单个IP高达几十条甚至上百条\n\n \n\n#### DDoS攻击防御方法：\n\t1. 过滤不必要的服务和端口：可以使用Inexpress、Express、Forwarding等工具来过滤不必要的服务和端口，即在路由器上过滤假IP。比如Cisco公司的CEF(Cisco Express Forwarding)可以针对封包Source IP和Routing Table做比较，并加以过滤。只开放服务端口成为目前很多服务器的流行做法，例如WWW服务器那么只开放80而将其他所有端口关闭或在防火墙上做阻止策略。\n\t2. 异常流量的清洗过滤：通过DDOS硬件防火墙对异常流量的清洗过滤，通过数据包的规则过滤、数据流指纹检测过滤、及数据包内容定制过滤等顶尖技术能准确判断外来访问流量是否正常，进一步将异常流量禁止过滤。单台负载每秒可防御800-927万个syn攻击包。\n\t3. 分布式集群防御：这是目前网络安全界防御大规模DDOS攻击的最有效办法。分布式集群防御的特点是在每个节点服务器配置多个IP地址（负载均衡），并且每个节点能承受不低于10G的DDOS攻击，如一个节点受攻击无法提供服务，系统将会根据优先级设置自动切换另一个节点，并将攻击者的数据包全部返回发送点，使攻击源成为瘫痪状态，从更为深度的安全防护角度去影响企业的安全执行决策。\n\t4. 高防智能DNS解析：高智能DNS解析系统与DDOS防御系统的完美结合，为企业提供对抗新兴安全威胁的超级检测功能。它颠覆了传统一个域名对应一个镜像的做法，智能根据用户的上网路线将DNS解析请求解析到用户所属网络的服务器。同时智能DNS解析系统还有宕机检测功能，随时可将瘫痪的服务器IP智能更换成正常服务器IP，为企业的网络保持一个永不宕机的服务状态。\n\n#### DDoS攻击的网络流量清洗\n\n\t当发生DDOS攻击时，网络监控系统会侦测到网络流量的异常变化并发出报警。在系统自动检测或人工判断之后，可以识别出被攻击的虚拟机公网IP地址。这时，可调用系统的防DDOS攻击功能接口，启动对相关被攻击IP的流量清洗。流量清洗设备会立即接管对该IP地址的所有数据包，并将攻击数据包清洗掉，仅将正常的数据包转发给随后的网络设备。这样，就能保证整个网络正常的流量通行，而将DDOS流量拒之门外。\n\t采用云DDoS清洗方式，可以为企业用户带来诸多好处。其表现在不仅可以提升综合防护能力，用户能够按需付费，可弹性扩展，而且还能够基于大数据来分析预测攻击，同时能够免费升级。对于企业用户来说，则可实现零运维、零改造。\n\n\n#### CC攻击介绍\nCC攻击（Challenge Collapsar）是DDOS（分布式拒绝服务）的一种，前身名为Fatboy攻击，也是一种常见的网站攻击方法。攻击者通过代理服务器或者肉鸡向向受害主机不停地发大量数据包，造成对方服务器资源耗尽，一直到宕机崩溃。相比其它的DDOS攻击CC似乎更有技术含量一些。这种攻击你见不到真实源IP，见不到特别大的异常流量，但造成服务器无法进行正常连接。最让站长们忧虑的是这种攻击技术含量低，利用更换IP代理工具和一些IP代理一个初、中级的电脑水平的用户就能够实施攻击。\n\n\n#### CC攻击防御方法\n\t1. 利用Session做访问计数器：利用Session针对每个IP做页面访问计数器或文件下载计数器，防止用户对某个页面频繁刷新导致数据库频繁读取或频繁下载某个文件而产生大额流量。（文件下载不要直接使用下载地址，才能在服务端代码中做CC攻击的过滤处理）\n\t2. 把网站做成静态页面：大量事实证明，把网站尽可能做成静态页面，不仅能大大提高抗攻击能力，而且还给骇客入侵带来不少麻烦，至少到现在为止关于HTML的溢出还没出现，看看吧！新浪、搜狐、网易等门户网站主要都是静态页面，若你非需要动态脚本调用，那就把它弄到另外一台单独主机去，免的遭受攻击时连累主服务器。\n\t3. 增强操作系统的TCP/IP栈\n\tWin2000和Win2003作为服务器操作系统，本身就具备一定的抵抗DDOS攻击的能力，只是默认状态下没有开启而已，若开启的话可抵挡约10000个SYN攻击包，若没有开启则仅能抵御数百个，具体怎么开启，自己去看微软的文章吧！《强化 TCP/IP 堆栈安全》。也许有的人会问，那我用的是Linux和FreeBSD怎么办？很简单，按照这篇文章去做吧！《SYN Cookies》。\n\t4. 在存在多站的服务器上，严格限制每一个站允许的IP连接数和CPU使用时间，这是一个很有效的方法。CC的防御要从代码做起，其实一个好的页面代码都应该注意这些东西，还有SQL注入，不光是一个入侵工具，更是一个DDOS缺口，大家都应该在代码中注意。举个例子吧，某服务器，开动了5000线的CC攻击，没有一点反应，因为它所有的访问数据库请求都必须一个随机参数在Session里面，全是静态页面，没有效果。突然发现它有一个请求会和外面的服务器联系获得，需要较长的时间，而且没有什么认证，开800线攻击，服务器马上满负荷了。代码层的防御需要从点点滴滴做起，一个脚本代码的错误，可能带来的是整个站的影响，甚至是整个服务器的影响!\n\t5. 服务器前端加CDN中转(免费的有百度云加速、360网站卫士、加速乐、安全宝等)，如果资金充裕的话，可以购买高防的盾机，用于隐藏服务器真实IP，域名解析使用CDN的IP，所有解析的子域名都使用CDN的IP地址。此外，服务器上部署的其他域名也不能使用真实IP解析，全部都使用CDN来解析。 \n\t另外，防止服务器对外传送信息泄漏IP地址，最常见的情况是，服务器不要使用发送邮件功能，因为邮件头会泄漏服务器的IP地址。如果非要发送邮件，可以通过第三方代理(例如sendcloud)发送，这样对外显示的IP是代理的IP地址。 \n\t总之，只要服务器的真实IP不泄露，10G以下小流量DDOS的预防花不了多少钱，免费的CDN就可以应付得了。如果攻击流量超过20G，那么免费的CDN可能就顶不住了，需要购买一个高防的盾机来应付了，而服务器的真实IP同样需要隐藏\n\n \n\n#### WAF介绍\n\tWAF（Web Application Firewall）的中文名称叫做“Web应用防火墙”，利用国际上公认的一种说法，WAF的定义是这样的：Web应用防火墙是通过执行一系列针对HTTP/HTTPS的安全策略来专门为Web应用提供保护的一款产品。通过从上面对WAF的定义中，我们可以很清晰的了解到，WAF是一种工作在应用层的、通过特定的安全策略来专门为Web应用提供安全防护的产品。\n\n\t根据不同的分类方法，WAF可分为许多种。从产品形态上来划分，WAF主要分为以下三大类：\n\n\t1.硬件设备类：目前安全市场上，大多数的WAF都属于此类。它们以一个独立的硬件设备的形态存在，支持以多种方式（如透明桥接模式、旁路模式、反向代理等）部署到网络中为后端的Web应用提供安全防护。相对于软件产品类的WAF，这类产品的优点是性能好、功能全面、支持多种模式部署等，但它的价格通常比较贵。国内的绿盟、安恒、启明星辰等厂商生产的WAF都属于此类。\n\t2.软件产品类：这种类型的WAF采用纯软件的方式实现，特点是安装简单，容易使用，成本低。但它的缺点也是显而易见的，因为它必须安装在Web应用服务器上，除了性能受到限制外，还可能会存在兼容性、安全等问题。这类WAF的代表有ModSecurity、Naxsi、网站安全狗等。\n\t3.基于云的WAF：随着云计算技术的快速发展，使得其于云的WAF实现成为可能。国内创新工场旗下的安全宝、360的网站宝是这类WAF的典型代表。它的优点是快速部署、零维护、成本低。对于中、小型的企业和个人站长是很有吸引力的。\n\n \n\n#### DDoS攻击测试工具\n\t1. 卢瓦(LOIC) (Low Orbit Ion Canon)：LOTC是一个最受欢迎的DOS攻击工具。 这个工具被去年流行的黑客集团匿名者用于对许多大公司的网络攻击。它可以通过使用单个用户执行DOS攻击小型服务器，工具非常易于使用，即便你是一个初学者。 这个工具执行DOS攻击通过发送UDP,TCP或HTTP请求到受害者服务器。 你只需要知道服务器的IP地址或URL，其他的就交给这个工具吧。\n\t2. XOIC：XOIC是另一个不错的DOS攻击工具。它根据用户选择的端口与协议执行DOS攻击任何服务器。XOIC开发者还声称XOIC比上面的LOIC在很多方面更强大呢。\n\t3. R-U-Dead-Yet：R-U-Dead-Yet是一个HTTP post DOS攻击工具。它执行一个DOS攻击长表单字段，通过POST方法提交。这个工具提供了一个交互式控制台菜单，检测给定的URL,并允许用户选择哪些表格和字段应用于POST-based DOS攻击。\n\t4. OWASP DOS HTTP POST：这是另外一个很好的工具。您可以使用这个工具来检查您的web服务器能否够捍卫得住别人的DOS攻击。当然，不仅对防御，它也可以用来执行DOS攻击哦。\n\t5. DAVOSET：DAVOSET是另一个很好的执行DDOS攻击工具。 最新版本的工具新增支持cookie以及许多其他功能。","tags":["攻击"],"categories":["网络安全"]},{"title":"DDoS的攻击原理与防御方法","url":"%2F2015%2F04%2F16%2FDDoS%E7%9A%84%E6%94%BB%E5%87%BB%E5%8E%9F%E7%90%86%E4%B8%8E%E9%98%B2%E5%BE%A1%E6%96%B9%E6%B3%95%2F","content":"\n\tDoS是Denial of Service的简写就是拒绝服务,而DDoS就是Distributed Denial of Service的简写就是分布式拒绝服务,而DRDoS就是Distributed Reflection Denial of Service的简写,这是分布反射式拒绝服务的意思。\n\n\t　　不过这3中攻击方法最厉害的还是DDoS,那个DRDoS攻击虽然是新近出的一种攻击方法,但它只是DDoS攻击的变形,它的唯一不同就是不用占领大量的“肉鸡”。这三种方法都是利用TCP三次握手的漏洞进行攻击的,所以对它们的防御办法都是差不多的。\n<!--more-->\t\n\t　　DoS攻击是最早出现的,它的攻击方法说白了就是单挑,是比谁的机器性能好、速度快。但是现在的科技飞速发展,一般的网站主机都有十几台主机,而且各个主机的处理能力、内存大小和网络速度都有飞速的发展,有的网络带宽甚至超过了千兆级别。这样我们的一对一单挑式攻击就没有什么作用了,搞不好自己的机子就会死掉。举个这样的攻击例子,假如你的机器每秒能够发送10个攻击用的数据包,而被你攻击的机器(性能、网络带宽都是顶尖的)每秒能够接受并处理100攻击数据包,那样的话,你的攻击就什么用处都没有了,而且非常有死机的可能。要知道,你若是发送这种1Vs1的攻击,你的机器的CPU占用率是90%以上的,你的机器要是配置不够高的话,那你就死定了。\n\n\t　　不过,科技在发展,黑客的技术也在发展。正所谓道高一尺,魔高一仗。经过无数次当机,黑客们终于又找到一种新的DoS攻击方法,这就是DDoS攻击。它的原理说白了就是群殴,用好多的机器对目标机器一起发动DoS攻击,但这不是很多黑客一起参与的,这种攻击只是由一名黑客来操作的。这名黑客不是拥有很多机器,他是通过他的机器在网络上占领很多的“肉鸡”,并且控制这些“肉鸡”来发动DDoS攻击,要不然怎么叫做分布式呢。还是刚才的那个例子,你的机器每秒能发送10攻击数据包,而被攻击的机器每秒能够接受100的数据包,这样你的攻击肯定不会起作用,而你再用10台或更多的机器来对被攻击目标的机器进行攻击的话,嘿嘿!结果我就不说了。\n\n\t　DRDoS分布反射式拒绝服务攻击这是DDoS攻击的变形,它与DDoS的不同之处就是DrDoS不需要在攻击之前占领大量的“肉鸡”。它的攻击原理和Smurf攻击原理相近,不过DRDoS是可以在广域网上进行的,而Smurf攻击是在局域网进行的。它的作用原理是基于广播地址与回应请求的。一台计算机向另一台计算机发送一些特殊的数据包如ping请求时,会接到它的回应;如果向本网络的广播地址发送请求包,实际上会到达网络上所有的计算机,这时就会得到所有计算机的回应。这些回应是需要被接收的计算机处理的,每处理一个就要占用一份系统资源,如果同时接到网络上所有计算机的回应,接收方的系统是有可能吃不消的,就象遭到了DDoS攻击一样。不过是没有人笨到自己攻击自己,不过这种方法被黑客加以改进就具有很大的威力了。黑客向广播地址发送请求包,所有的计算机得到请求后,却不会把回应发到黑客那里,而是发到被攻击主机。这是因为黑客冒充了被攻击主机。黑客发送请求包所用的软件是可以伪造源地址的,接到伪造数据包的主机会根据源地址把回应发出去,这当然就是被攻击主机的地址。黑客同时还会把发送请求包的时间间隔减小,这样在短时间能发出大量的请求包,使被攻击主机接到从被欺骗计算机那里传来的洪水般的回应,就像遭到了DDoS攻击导致系统崩溃。骇客借助了网络中所有计算机来攻击受害者,而不需要事先去占领这些被欺骗的主机,这就是Smurf攻击。而DRDoS攻击正是这个原理,黑客同样利用特殊的发包工具,首先把伪造了源地址的SYN连接请求包发送到那些被欺骗的计算机上,根据TCP三次握手的规则,这些计算机会向源IP发出SYN+ACK或RST包来响应这个请求。同Smurf攻击一样,黑客所发送的请求包的源IP地址是被攻击主机的地址,这样受欺骗的主机就都会把回应发到被攻击主机处,造成被攻击主机忙于处理这些回应而瘫痪。\n\n　　解释:\n　　SYN:(Synchronize sequence numbers)用来建立连接,在连接请求中,SYN=1,ACK=0,连接响应时,SYN=1,ACK=1。即,SYN和ACK来区分Connection Request和Connection Accepted。\n　　RST:(Reset the connection)用于复位因某种原因引起出现的错误连接,也用来拒绝非法数据和请求。如果接收到RST位时候,通常发生了某些错误。\n　　ACK:(Acknowledgment field significant)置1时表示确认号(Acknowledgment Number)为合法,为0的时候表示数据段不包含确认信息,确认号被忽略。\n\n　　TCP三次握手:图略\n\n　　假设我们要准备建立连接,服务器正处于正常的接听状态。\n\n　　第一步:我们也就是客户端发送一个带SYN位的请求,向服务器表示需要连接,假设请求包的序列号为10,那么则为:SYN=10,ACK=0,然后等待服务器的回应。\n\n　　第二步:服务器接收到这样的请求包后,查看是否在接听的是指定的端口,如果不是就发送RST=1回应,拒绝建立连接。如果接收请求包,那么服务器发送确认回应,SYN为服务器的一个内码,假设为100,ACK位则是客户端的请求序号加1,本例中发送的数据是:SYN=100,ACK=11,用这样的数据回应给我们。向我们表示,服务器连接已经准备好了,等待我们的确认。这时我们接收到回应后,分析得到的信息,准备发送确认连接信号到服务器。\n\n　　第三步:我们发送确认建立连接的信息给服务器。确认信息的SYN位是服务器发送的ACK位,ACK位是服务器发送的SYN位加1。即:SYN=11,ACK=101。\n\n　　这样我们的连接就建立起来了。\n\n　　DDoS究竟如何攻击?目前最流行也是最好用的攻击方法就是使用SYN-Flood进行攻击,SYN-Flood也就是SYN洪水攻击。SYN-Flood不会完成TCP三次握手的第三步,也就是不发送确认连接的信息给服务器。这样,服务器无法完成第三次握手,但服务器不会立即放弃,服务器会不停的重试并等待一定的时间后放弃这个未完成的连接,这段时间叫做SYN timeout,这段时间大约30秒-2分钟左右。若是一个用户在连接时出现问题导致服务器的一个线程等待1分钟并不是什么大不了的问题,但是若有人用特殊的软件大量模拟这种情况,那后果就可想而知了。一个服务器若是处理这些大量的半连接信息而消耗大量的系统资源和网络带宽,这样服务器就不会再有空余去处理普通用户的正常请求(因为客户的正常请求比率很小)。这样这个服务器就无法工作了,这种攻击就叫做:SYN-Flood攻击。\n\n常规的一些防御方法\n　　到目前为止,进行DDoS攻击的防御还是比较困难的。首先,这种攻击的特点是它利用了TCP/IP协议的漏洞,除非你不用TCP/IP,才有可能完全抵御住DDoS攻击。不过这不等于我们就没有办法阻挡DDoS攻击,我们可以尽力来减少DDoS的攻击。下面就是一些防御方法:\n\n　　1。确保服务器的系统文件是最新的版本,并及时更新系统补丁。\n要定期扫描现有的网络主节点,清查可能存在的安全漏洞,对新出现的漏洞及时进行清理。骨干节点的计算机因为具有较高的带宽,是黑客利用的最佳位置,因此对这些主机本身加强主机安全是非常重要的。而且连接到网络主节点的都是服务器级别的计算机,所以定期扫描漏洞就变得更加重要了。\n\n　　2。关闭不必要的服务。\n过滤不必要的服务和端口.可以使用Inexpress、Express、Forwarding等工具来过滤不必要的服务和端口,即在路由器上过滤假IP。比如Cisco公司的 CEF(Cisco Express Forwarding)可以针对封包Source IP和Routing Table做比较,并加以过滤。只开放服务端口成为目前很多服务器的流行做法,例如WWW服务器那么只开放80而将其他所有端口关闭或在防火墙上做阻止策略。\n\n　　3。限制同时打开的SYN半连接数目,缩短SYN半连接的time out 时间,限制SYN/ICMP流量\n　　用户应在路由器上配置SYN/ICMP的最大流量来限制SYN/ICMP封包所能占有的最高频宽,这样,当出现大量的超过所限定的SYN/ICMP流量时,说明不是正常的网络访问,而是有黑客入侵。早期通过限制SYN/ICMP流量是最好的防范DOS的方法,虽然目前该方法对于Ddos效果不太明显了, 不过仍然能够起到一定的作用。\n　　\n4。正确设置防火墙\n\n　　禁止对主机的非开放服务的访问\n\n　　限制特定IP地址的访问\n过滤所有RFC1918 IP地址RFC1918 IP地址是内部网的IP地址,像10.0.0.0、192.168.0.0和172.16.0.0,它们不是某个网段的固定的IP地址,而是Internet内部保留的区域性IP地址,应该把它们过滤掉。此方法并不是过滤内部员工的访问,而是将攻击时伪造的大量虚假内部IP过滤,这样也可以减轻Ddos的攻击。 \n\n　　启用防火墙的防DDoS的属性\n\n　　严格限制对外开放的服务器的向外访问\n\n　　运行端口映射程序祸端口扫描程序,要认真检查特权端口和非特权端口。\n\n在骨干节点配置防火墙\n　　防火墙本身能抵御Ddos攻击和其他一些攻击。在发现受到攻击的时候,可以将攻击导向一些牺牲主机,这样可以保护真正的主机不被攻击。当然导向的这些牺牲主机可以选择不重要的,或者是linux以及unix等漏洞少和天生防范攻击优秀的系统。\n\n　　5。认真检查网络设备和主机/服务器系统的日志。只要日志出现漏洞或是时间变更,那这台机器就可能遭到了攻击。\n　　6。限制在防火墙外与网络文件共享。这样会给黑客截取系统文件的机会,主机的信息暴露给黑客,无疑是给了对方入侵的机会。\n　　7。充分利用网络设备保护网络资源\n　　所谓网络设备是指路由器、防火墙等负载均衡设备,它们可将网络有效地保护起来。当网络被攻击时最先死掉的是路由器,但其他机器没有死。死掉的路由器经重 启后会恢复正常,而且启动起来还很快,没有什么损失。若其他服务器死掉,其中的数据会丢失,而且重启服务器又是一个漫长的过程。特别是一个公司使用了负载 均衡设备,这样当一台路由器被攻击死机时,另一台将马上工作。从而最大程度的削减了Ddos的攻击。\n\n\n路由器\n\n\n　　以Cisco路由器为例\n\n　　Cisco Express Forwarding(CEF)\n\n　　使用 unicast reverse-path\n\n　　访问控制列表(ACL)过滤\n\n　　设置SYN数据包流量速率\n\n　　升级版本过低的ISO\n\n　　为路由器建立log server\n8。 用足够的机器承受黑客攻击\n　　这是一种较为理想的应对策略。如果用户拥有足够的容量和足够的资源给黑客攻击,在它不断访问用户、夺取用户资源之时,自己的能量也在逐渐耗失,或许未等用户被攻死,黑客已无力支招儿了。不过此方法需要投入的资金比较多,平时大多数设备处于空闲状态,和目前中小企业网络实际运行情况不相符。\n\n9。 检查访问者的来源\n　　使用Unicast Reverse Path Forwarding等通过反向路由器查询的方法检查访问者的IP地址是否是真,如果是假的,它将予以屏蔽。许多黑客攻击常采用假IP地址方式迷惑用户, 很难查出它来自何处。因此,利用Unicast Reverse Path Forwarding可减少假IP地址的出现,有助于提高网络安全性。\n\n能够了解DDoS攻击的原理,对我们防御的措施在加以改进,我们就可以挡住一部分的DDoS攻击,知己知彼,百战不殆嘛。\n\nlinux下防DDOS攻击软件及使用方法详解\n\n互联网如同现实社会一样充满钩心斗角,网站被DDOS也成为站长最头疼的事。在没有硬防的情况下,寻找软件代替是最直接的方法,比如用 iptables,但是iptables不能在自动屏蔽,只能手动屏蔽。\n一、什么是DDOS攻击？\nDDoS也就是分布式拒绝服务攻击。它使用与普通的拒绝服务攻击同样的方法,但是发起攻击的源是多个。通常攻击者使用下载的工具渗透无保护的主机,当获得该主机的适当的访问权限后,攻击者在主机中安装软件的服务或进程（以下简侈怔理）。这些代理保持睡眠状态,直到从它们的主控端得到指令,对指定的目标发起拒绝服务攻击。\n二、如何确认自己受到DDOS攻击？\n在系统上执行：\nnetstat -ntu | awk '{print $5}' | cut -d: -f1 | sort | uniq -c | sort -n\n执行后,将会显示服务器上所有的每个IP多少个连接数。\n以下是我自己用VPS测试的结果：\nli88-99:~# netstat -ntu | awk '{print $5}' | cut -d: -f1 | sort | uniq -c | sort -n\n1 114.226.9.132\n1 174.129.237.157\n1 58.60.118.142\n1 Address\n1 servers)\n2 118.26.131.78\n3 123.125.1.202\n3 220.248.43.119\n4 117.36.231.253\n4 119.162.46.124\n6 219.140.232.128\n8 220.181.61.31\n2311 67.215.242.196\n每个IP几个、十几个或几十个连接数都还算比较正常,如果像上面成百上千肯定就不正常了。\n三、防范DDOS攻击的方法:\n一些常用的防DDOS攻击的方法,罗列如下：\n1.增加硬件防火墙和增加硬件设备来承载和抵御DDOS攻击,最基本的方法,但成本比较高。\n2.修改SYN设置抵御SYN攻击：\nSYN攻击是利用TCP/IP协议3次握手的原理,发送大量的建立连接的网络包,但不实际建立连接,最终导致被攻击服务器的网络队列被占满,无法被正常用户访问。\nLinux内核提供了若干SYN相关设置,使用命令：\nsysctl -a | grep syn\n看到：\nnet.ipv4.tcp_max_syn_backlog = 1024\nnet.ipv4.tcp_syncookies = 0\nnet.ipv4.tcp_synack_retries = 5\nnet.ipv4.tcp_syn_retries = 5\ntcp_max_syn_backlog是SYN队列的长度,tcp_syncookies是一个开关,是否打开SYN Cookie\n功能,该功能可以防止部分SYN攻击。tcp_synack_retries和tcp_syn_retries定义SYN\n的重试次数。\n加大SYN队列长度可以容纳更多等待连接的网络连接数,打开SYN Cookie功能可以阻止部分\nSYN攻击,降低重试次数也有一定效果。\n调整上述设置的方法是：\n增加SYN队列长度到2048：\nsysctl -w net.ipv4.tcp_max_syn_backlog=2048\n打开SYN COOKIE功能：\nsysctl -w net.ipv4.tcp_syncookies=1\n降低重试次数：\nsysctl -w net.ipv4.tcp_synack_retries=3\nsysctl -w net.ipv4.tcp_syn_retries=3\n为了系统重启动时保持上述配置,可将上述命令加入到/etc/rc.d/rc.local文件中。\n3.安装iptables对特定ip进行屏蔽。\nA.安装iptables和系统内核版本对应的内核模块kernel-smp-modules-connlimit\nB. 配置相应的iptables规则\n示例如下：\n(1)控制单个IP的最大并发连接数\niptables -I INPUT -p tcp –dport 80 -m connlimit –connlimit-above 50 -j REJECT\n#允许单个IP的最大连接数为 30\n(2)控制单个IP在一定的时间（比如60秒）内允许新建立的连接数\niptables -A INPUT -p tcp –dport 80 -m recent –name BAD_HTTP_ACCESS –update –seconds 60 \\\n–hitcount 30 -j REJECT\niptables -A INPUT -p tcp –dport 80 -m recent –name BAD_HTTP_ACCESS –set -j ACCEPT\n#单个IP在60秒内只允许最多新建30个连接\n(3)用iptables屏蔽IP\niptables -I RH-Lokkit-0-50-INPUT 1 -p tcp -m tcp -s 213.8.166.227 --dport 80 --syn -j REJECT\n指定端口的参数是--dport 80;多了--syn参数,可以自动检测sync攻击\n(4)使用iptables禁止ping：\niptables -A INPUT -p icmp -m icmp --icmp-type 8 -m limit --limit 6/min --limit-burst 2 -j ACCEPT-A INPUT -p icmp -m icmp --icmp-type 8 -j REJECT --reject-with icmp-port-unreachable\n(5)允许某ip连接\niptables -I RH-Firewall-1-INPUT 1 -p tcp -m tcp -s 192.168.0.51 --syn -j ACCEPT\nC. 验证\n（1）工具：flood_connect.c（用来模拟攻击)\n（2）查看效果：\n使用\nwatch ‘netstat -an | grep:21 | \\ grep< 模拟攻击客户机的IP>| wc -l’\n实时查看模拟攻击客户机建立起来的连接数,\n使用\nwatch ‘iptables -L -n -v | \\grep< 模拟攻击客户机的IP>’\n查看模拟攻击客户机被 DROP 的数据包数。\nD．注意\n为了增强iptables防止CC攻击的能力,最好调整一下ipt_recent的参数如下：\n#cat/etc/modprobe.conf\noptions ipt_recent ip_list_tot=1000 ip_pkt_list_tot=60\n#记录1000个IP地址,每个地址记录60个数据包\n#modprobe ipt_recent\nE.可编写脚本自动提娶攻击ip然后自动屏蔽：\n*/2 * * * * /usr/local/nginx/var/log/drop.sh\n#!/bin/sh\ncd /usr/local/nginx/var/log\ntail access.log -n 1000 |grep vote.php | |sort |uniq -c |sort -nr |awk '{if ($2!=null && $1>50)}' > drop_ip.txt\nfor i in `cat drop_ip.txt`\ndo\n/sbin/iptables -I INPUT -s $i -j DROP;\ndone\n这shell 每几分钟执行一次,就可自动屏蔽那些不正常IP,相信大家都看的懂,下面是针对连接数屏蔽代码\n#!/bin/sh\n/bin/netstat -ant |grep 80 |awk '{print $5}' |awk -F : '{print $1}' |sort |uniq -c |sort -rn |grep -v -E '192.168|127.0' |awk '{if ($2!=null && $1>50)}' > drop_ip.txt\nfor i in `cat drop_ip.txt`\ndo\n/sbin/iptables -I INPUT -s $i -j DROP;\ndone\n说下,grep -v -E '192.168|127.0' 也就是排除内网IP,免得把自己给屏蔽了,当然还可以加些自己的IP。\n4.安装DDoS deflate自动抵御DDOS攻击：\nDDoS deflate是一款免费的用来防御和减轻DDoS攻击的脚本。它通过netstat监测跟踪创建大量网络连接的IP地址,在检测到某个结点超过预设的限制时,该程序会通过APF或IPTABLES禁止或阻挡这些IP.\nDDoS deflate官方网站：\n（1）安装DDoS deflate\nwget\nchmod 0700 install.sh //添加权限\n./install.sh //执行\n（2）配置DDoS deflate\n下面是DDoS deflate的默认配置位于/usr/local/ddos/ddos.conf ,内容如下：\n##### Paths of the script and other files\nPROGDIR=”/usr/local/ddos”\nPROG=”/usr/local/ddos/ddos.sh”\nIGNORE_IP_LIST=”/usr/local/ddos/ignore.ip.list” //IP地址白名单\nCRON=”/etc/cron.d/ddos.cron” //定时执行程序\nAPF=”/etc/apf/apf”\nIPT=”/sbin/iptables”\n##### frequency in minutes for running the script\n##### Caution: Every time this setting is changed run the script with –cron\n##### option so that the new frequency takes effect\nFREQ=1 //检查时间间隔,默认1分钟\n##### How many connections define a bad IP? Indicate that below.\nNO_OF_CONNECTIONS=150 //最大连接数,超过这个数IP就会被屏蔽,一般默认即可\n##### APF_BAN=1 (Make sure your APF version is atleast 0.96)\n##### APF_BAN=0 (Uses iptables for banning ips instead of APF)\nAPF_BAN=1 //使用APF还是iptables,推荐使用iptables\n##### KILL=0 (Bad IPs are’nt banned good for interactive execution of script)\n##### KILL=1 (Recommended setting)\nKILL=1 //是否屏蔽IP,默认即可\n#### An email is sent to the following address when an IP is banned.\n##### Blank would suppress sending of mails\nEMAIL_TO=”root” //当IP被屏蔽时给指定邮箱发送邮件,推荐使用,换成自己的邮箱即可\n##### Number of seconds the banned ip should remain in blacklist.\nBAN_PERIOD=600 //禁用IP时间,默认600秒,可根据情况调整\n用户可根据给默认配置文件加上的注释提示内容,修岗?置文件。\n喜欢折腾的可以用Web压力测试软件（《web服务器性能/压力测试工具http_load、webbench、ab、Siege使用教程》）测试一下效果,这东西只能防御小流量的攻击了,聊胜于无吧。\n5.APACHE上安装mod_evasive 组件增强抵御力\nmod_evasive是一个预防Apache 遭受DDos 攻击的模块,可以防止同一个IP 对相同URI 发出的大量请求,可设定的选项有：\n– 限制同一个IP 在一定秒数内请求一个页面或档案的次数。\n– 限制同一个IP 一秒内只可发出50 个请求。\n– 设定被禁止的 IP 封锁时间。\n\n\n以下是 mod_evasive 的安装方法：\nA. 先将原来的 httpd.conf 备份起来。\nB. 到\nC. 在指令模式解压及编译 mod_evasive：\ntar zxvf mod_evasive_1.10.1.tar.gz\ncd mod_evasive/\napxs -cia mod_evasive20.c\n以上的apxs 会放在Apache 的bin 目录内；如果Apache 版本是1.3 的话,指令要改为：\napxs -cia mod_evasive.c\n安装好mod_evasive 后,便要修改httpd.conf 内容。\nD. 开启 httpd.conf,加入以内容：\nDOSHashTableSize 3097\nDOSPageCount 5\nDOSSiteCount 100\nDOSPageInterval 2\nDOSSiteInterval 2\nDOSBlockingPeriod 10\nDOSBlockingPeriod 600\nDOSHashTableSize — 这是占用内存的大小,如果服务器比较繁忙,这个数值要设定大一点。\nDOSPageCount — 同一IP 在一个时段内可以存娶同一页面的次数,超过会被禁止。\nDOSSiteCount — 同一IP 在一个网站内可以占用多少object,超过会禁止。\nDOSPageInterval — DOSPageCount 内的时段设定。\nDOSSiteInterval — DOSSiteCount 的时间设定,以秒为单位。\nDOSBlockingPeriod — 当发现疑似攻击后,使用者会收到403 Forbidden,这是设定封锁的时间,以秒为单位。\nE. 最后重新启动 Apache 即可。\n","tags":["攻击"],"categories":["网络安全"]},{"title":"文件同步工具rsync","url":"%2F2015%2F03%2F19%2F%E6%96%87%E4%BB%B6%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7rsync%2F","content":"\n#### 简介\n\trsync是一个功能非常强大的工具，其命令也有很多功能特色选项，我们下面就对它的选项一一进行分析说明在对rsync服务器配置结束以后，下一步就需要在客户端发出rsync命令来实现将服务器端的文件备份到客户端来。rsync是一个功能非常强大的工具，其命令也有很多功能特色选项，我们下面就对它的选项一一进行分析说明\n\n#### Rsync的命令格式可以为以下六种：\n\n```bash\n#拷贝本地文件。当SRC和DES路径信息都不包含有单个冒号\":\"分隔符时就启动这种工作模式。如：rsync -a /data /backup\nrsync [OPTION]... SRC DEST\n#使用一个远程shell程序(如rsh、ssh)来实现将本地机器的内容拷贝到远程机器。当DST路径地址包含单个冒号\":\"分隔符时启动该模式。如：rsync -avz *.c foo:src\nrsync [OPTION]... SRC [USER@]HOST:DEST\n#使用一个远程shell程序(如rsh、ssh)来实现将远程机器的内容拷贝到本地机器。当SRC地址路径包含单个冒号\":\"分隔符时启动该模式。如：rsync -avz foo:src/bar /data\nrsync [OPTION]... [USER@]HOST:SRC DEST\n#从远程rsync服务器中拷贝文件到本地机。当SRC路径信息包含\"::\"分隔符时启动该模式。如：rsync -av root@172.16.78.192::www /databack\nrsync [OPTION]... [USER@]HOST::SRC DEST\n#从本地机器拷贝文件到远程rsync服务器中。当DST路径信息包含\"::\"分隔符时启动该模式。如：rsync -av /databack root@172.16.78.192::www\nrsync [OPTION]... SRC [USER@]HOST::DEST\n#列远程机的文件列表。这类似于rsync传输，不过只要在命令中省略掉本地机信息即可。如：rsync -v rsync://172.16.78.192/www\nrsync [OPTION]... rsync://[USER@]HOST[:PORT]/SRC [DEST]\n```\n<!--more-->\n#### rsync参数的具体解释如下\n\n```bash\n-v, --verbose 详细模式输出\n-q, --quiet 精简输出模式\n-c, --checksum 打开校验开关，强制对文件传输进行校验\n-a, --archive 归档模式，表示以递归方式传输文件，并保持所有文件属性，等于-rlptgoD\n-r, --recursive 对子目录以递归模式处理\n-R, --relative 使用相对路径信息\n-b, --backup 创建备份，也就是对于目的已经存在有同样的文件名时，将老的文件重新命名为~filename。可以使用--suffix选项来指定不同的备份文件前缀。\n--backup-dir 将备份文件(如~filename)存放在在目录下。\n-suffix=SUFFIX 定义备份文件前缀\n-u, --update 仅仅进行更新，也就是跳过所有已经存在于DST，并且文件时间晚于要备份的文件。(不覆盖更新的文件)\n-l, --links 保留软链结\n-L, --copy-links 想对待常规文件一样处理软链结\n--copy-unsafe-links 仅仅拷贝指向SRC路径目录树以外的链结\n--safe-links 忽略指向SRC路径目录树以外的链结\n-H, --hard-links 保留硬链结\n-p, --perms 保持文件权限\n-o, --owner 保持文件属主信息\n-g, --group 保持文件属组信息\n-D, --devices 保持设备文件信息\n-t, --times 保持文件时间信息\n-S, --sparse 对稀疏文件进行特殊处理以节省DST的空间\n-n, --dry-run现实哪些文件将被传输\n-W, --whole-file 拷贝文件，不进行增量检测\n-x, --one-file-system 不要跨越文件系统边界\n-B, --block-size=SIZE 检验算法使用的块尺寸，默认是700字节\n-e, --rsh=COMMAND 指定使用rsh、ssh方式进行数据同步\n--rsync-path=PATH 指定远程服务器上的rsync命令所在路径信息\n-C, --cvs-exclude 使用和CVS一样的方法自动忽略文件，用来排除那些不希望传输的文件\n--existing 仅仅更新那些已经存在于DST的文件，而不备份那些新创建的文件\n--delete 删除那些DST中SRC没有的文件\n--delete-excluded 同样删除接收端那些被该选项指定排除的文件\n--delete-after 传输结束以后再删除\n--ignore-errors 及时出现IO错误也进行删除\n--max-delete=NUM 最多删除NUM个文件\n--partial 保留那些因故没有完全传输的文件，以是加快随后的再次传输\n--force 强制删除目录，即使不为空\n--numeric-ids 不将数字的用户和组ID匹配为用户名和组名\n--timeout=TIME IP超时时间，单位为秒\n-I, --ignore-times 不跳过那些有同样的时间和长度的文件\n--size-only 当决定是否要备份文件时，仅仅察看文件大小而不考虑文件时间\n--modify-window=NUM 决定文件是否时间相同时使用的时间戳窗口，默认为0\n-T --temp-dir=DIR 在DIR中创建临时文件\n--compare-dest=DIR 同样比较DIR中的文件来决定是否需要备份\n-P 等同于 --partial\n--progress 显示备份过程\n-z, --compress 对备份的文件在传输时进行压缩处理\n--exclude=PATTERN 指定排除不需要传输的文件模式\n--include=PATTERN 指定不排除而需要传输的文件模式\n--exclude-from=FILE 排除FILE中指定模式的文件\n--include-from=FILE 不排除FILE指定模式匹配的文件\n--version 打印版本信息\n--address 绑定到特定的地址\n--config=FILE 指定其他的配置文件，不使用默认的rsyncd.conf文件\n--port=PORT 指定其他的rsync服务端口\n--blocking-io 对远程shell使用阻塞IO\n-stats 给出某些文件的传输状态\n--progress 在传输时现实传输过程\n--log-format=formAT 指定日志文件格式\n--password-file=FILE 从FILE中得到密码\n--bwlimit=KBPS 限制I/O带宽，KBytes per second\n-h, --help 显示帮助信息\n一般都使用azv选项（如果windows与linux同步不建议使用这个参数）\n```\n#### 以服务方式启动rsync\n\n```bash\n#守护进程的启动方式\nrsync --daemon &\n#如果配置文件没有在/etc下，加个--config参数\nrsync --daemon --config=/usr/local/rsyncd.conf\n#xinetd启动方式\n#编辑/etc/services文件添加如下两行：\nrsync　　873/tcp　　# rsync \nrsync　　873/udp　　# rsync\n#设定 /etc/xinetd.d/rsync，比如：\n# default: off\n# description: The rsync server is a good addition to am ftp server, as it \\\n#allows crc checksumming etc.\nservice rsync{\n    disable = no\n    socket_type     = stream\n    wait            = no\n    user            = root\n    server          = /usr/bin/rsync\n    server_args     = --daemon\n    log_on_failure  += USERID\n}\n#然后service xinetd restart\n```\n#### 配置文件\n\n```bash\n#主要有三个配置文件： \n- rsyncd.conf(主要的配置文件，默认是没有的，需要自己新建) \n- rsyncd.secrets(这是密码文件，后缀根据自己喜好定义，注意此文件权限属性一定是root，一定要是600，不然会报错的) \n- rsyncd.motd(服务器的提示信息) \n#下面说下各文件内容： \n#rsyncd.motd:定义的是服务器信息的，就是用户登录信息，比如写个：welcome to 192.168.1.35,此文件不是必须的，可有可无 \n#rsyncd.secrets：这里放的是同步的用户名和密码，格式为user:pass,这里的user不一定非得是系统的用户，可以是随意定义的虚拟用户 \n#rsyncd.conf：这是个主要的配置文件，配置项比较多\n\n\n\n#全局定义\n#pid文件目录\npid file = /var/run/rsyncd.pid\n#指定服务运行端口,默认端口是873\nport =874\n#指定服务器地址\naddress = 192.168.1.35\n#指定运行用户和组,\nuid = nobody\ngid = nobody\n注意：这里指定哪个目录，同步的目录就要给于这个用户的权限，不然会遇到权限的问题\n#注：用chroot，在传输文件之前，服务器守护程序在将chroot 到文件系统中的目录中，这样做的好处是可能保护系统被安装漏洞侵袭的可能。缺点是需要超级用户权限。另外对符号链接文件，将会排除在外。也就是说，你在 rsync服务器上，如果有符号链接，你在备份服务器上运行客户端的同步数据时，只会把符号链接名同步下来，并不会同步符号链接的内容；这个需要自己来尝 试\nuse chroot = yes\n# read only 是只读选择，也就是说，不让客户端上传文件到服务器上。还有一个 write only选项\nread only = yes \n#限制内网访问的ip或ip段\nhosts allow=192.168.1.0/255.255.255.0 10.0.1.0/255.255.255.0\n#客户端最多连接数\nmax connections = 5 \n#motd file 是定义服务器信息的，要自己写 rsyncd.motd 文件内容。当用户登录时会看到这个信息\nmotd file = /etc/rsyncd/rsyncd.motd\n#rsync 服务器的日志\nlog file = /var/log/rsync.log\n#传输文件的日志\ntransfer logging = yes\n#日志格式\nlog format = %t %a %m %f %b\n#日志等级\nsyslog facility = local3\n#超时时间\ntimeout = 300\n#模块定义\n[test_rsync]\npath = /data/test_rsync\ncomment = test_dir\nauth users = test_user\nexclude = test2/\nignore errors\nsecrets file = /etc/rsyncd.secrets\n#test_rsync:定义一个模块名字\n#path:指定这个模块的目录\n#comment:模块的描述，可以自己定义\n#auth users:认证的用户名(有说一定要是系统用户，但我试了下，好像不是也可以)\n#list = yes 反rsync服务器上的同步数据的目录在服务器的模块上是否显示列出来，默认是yes，但no是比较安全的，至少别人不知道你服务器上提供了哪些目录\n#ignore errors: 忽略IO的错误\n#scerets file:密码文件的路径\nexclude=test2/ test3/:排除目录，排队test2和test3两个目录不同步\n```","tags":["rsync"],"categories":["linux"]},{"title":"LVM常用操作","url":"%2F2015%2F02%2F18%2FLVM%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F","content":"\n#### 从物理磁盘到逻辑卷操作步骤\n\n```bash\n#硬盘分区 \nfdisk -cu /dev/sdb \n#建立物理卷 \npvcreate /dev/sdb1 /dev/sdb2\n#查看物理卷属性 \npvscan\n#建立卷组 \nvgcreate myvg /dev/sdb1 /dev/sdb2\n#查看卷组属性 \nvgscan\n#创建逻辑卷 \nlvccreate -L 1000M -n lv01 myvg\n#建立文件系统 \nmkfs.ext4 /dev/mapper/myvg-lv01\n#挂载文件系统 \nmount /dev/mapper/myvg-lv01 /home\n#写入分区表vi /etc/fstab，加入如下行：\n/dev/mapper/myvg-lv01   /home   ext4    default    0    0\n#使用文件系统\n```\n<!--more-->\n#### 扩大卷组\n\n```bash\nvgextend myvg /dev/sdb\nvgextend myvg /dev/sdc1 /dev/sdc2\n#pv可以是分区也可以是物理设备\n#vgs 可以查看vg的情况，pvs可以查看pv的情况，lvs可以查看逻辑卷的情况\n```\n#### 扩大逻辑卷\n\n```bash\nlvextend -L +1000M /dev/mapper/myvg-lv01  \n#不带“+”说明是增加至1000M，带上说明是在原有的基础上增加1000M\nresize2fs /dev/mapper/myvg-lv01（重新加载卷，是操作生效,Centos7使用下面方法）\nxfs_growfs /dev/mapper/cl-data(centos7.x)\n```\n\n#### 缩小逻辑卷\n\n```bash\ne2fsck -f /dev/mapper/myvg-lvhome  \nresize2fs /dev/mapper/myvg-lvhome 800M   #缩小文件系统\nlvreduce -L -200M /dev/mapper/myvg-lvhome  #缩小逻辑卷\n```\n\n#### 缩小卷组\n\n```bash\nvgreduce vg_gechong /dev/sdb1     #其实就是删除pv物理卷\npvremove /dev/sdb1\n```","tags":["lvm"],"categories":["linux"]},{"title":"Hello World","url":"%2F2013%2F07%2F13%2Fhello-world%2F","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n\n","tags":["test"]}]